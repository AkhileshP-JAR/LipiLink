import {
  AIMessage,
  AIMessageChunk,
  AsyncCaller,
  CallbackManager,
  ChatGenerationChunk,
  ChatMessage,
  ChatMessageChunk,
  FunctionMessageChunk,
  GenerationChunk,
  HumanMessage,
  HumanMessageChunk,
  RUN_KEY,
  Runnable,
  RunnableAssign,
  RunnableBinding,
  RunnableEach,
  RunnableLambda,
  RunnableMap,
  RunnableParallel,
  RunnablePick,
  RunnableRetry,
  RunnableSequence,
  RunnableToolLike,
  RunnableWithFallbacks,
  Serializable,
  SystemMessageChunk,
  ToolMessageChunk,
  __export,
  _coerceToDict,
  _coerceToRunnable,
  addLangChainErrorFields,
  applyPatch,
  callbackHandlerPrefersStreaming,
  coerceMessageLikeToMessage,
  compare,
  concat,
  convertToChunk,
  convertToOpenAIImageBlock,
  deepCompareStrict,
  ensureConfig,
  extendInteropZodObject,
  external_exports,
  getBufferString,
  getCallbackManagerForConfig,
  getEnvironmentVariable,
  getInteropZodDefaultGetter,
  getInteropZodObjectShape,
  getSchemaDescription,
  interopParse,
  interopParseAsync,
  interopSafeParse,
  interopSafeParseAsync,
  interopZodObjectMakeFieldsOptional,
  interopZodObjectPartial,
  interopZodObjectPassthrough,
  interopZodObjectStrict,
  interopZodTransformInputSchema,
  isAIMessage,
  isAIMessageChunk,
  isBase64ContentBlock,
  isBaseMessage,
  isBaseMessageChunk,
  isInteropZodError,
  isInteropZodLiteral,
  isInteropZodObject,
  isInteropZodSchema,
  isShapelessZodSchema,
  isSimpleStringZodSchema,
  isURLContentBlock,
  isZodArrayV4,
  isZodLiteralV3,
  isZodLiteralV4,
  isZodNullableV4,
  isZodObjectV3,
  isZodObjectV4,
  isZodOptionalV4,
  isZodSchema,
  isZodSchemaV3,
  isZodSchemaV4,
  mapStoredMessageToChatMessage,
  mergeConfigs,
  parseJsonMarkdown,
  parsePartialJson,
  patchConfig,
  pickRunnableConfigKeys,
  raceWithSignal,
  toJsonSchema
} from "./chunk-5MZ6E775.js";
import {
  __commonJS,
  __publicField,
  __toESM
} from "./chunk-WOOG5QLI.js";

// node_modules/base64-js/index.js
var require_base64_js = __commonJS({
  "node_modules/base64-js/index.js"(exports) {
    "use strict";
    exports.byteLength = byteLength;
    exports.toByteArray = toByteArray;
    exports.fromByteArray = fromByteArray;
    var lookup = [];
    var revLookup = [];
    var Arr = typeof Uint8Array !== "undefined" ? Uint8Array : Array;
    var code = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";
    for (i = 0, len = code.length; i < len; ++i) {
      lookup[i] = code[i];
      revLookup[code.charCodeAt(i)] = i;
    }
    var i;
    var len;
    revLookup["-".charCodeAt(0)] = 62;
    revLookup["_".charCodeAt(0)] = 63;
    function getLens(b64) {
      var len2 = b64.length;
      if (len2 % 4 > 0) {
        throw new Error("Invalid string. Length must be a multiple of 4");
      }
      var validLen = b64.indexOf("=");
      if (validLen === -1) validLen = len2;
      var placeHoldersLen = validLen === len2 ? 0 : 4 - validLen % 4;
      return [validLen, placeHoldersLen];
    }
    function byteLength(b64) {
      var lens = getLens(b64);
      var validLen = lens[0];
      var placeHoldersLen = lens[1];
      return (validLen + placeHoldersLen) * 3 / 4 - placeHoldersLen;
    }
    function _byteLength(b64, validLen, placeHoldersLen) {
      return (validLen + placeHoldersLen) * 3 / 4 - placeHoldersLen;
    }
    function toByteArray(b64) {
      var tmp;
      var lens = getLens(b64);
      var validLen = lens[0];
      var placeHoldersLen = lens[1];
      var arr = new Arr(_byteLength(b64, validLen, placeHoldersLen));
      var curByte = 0;
      var len2 = placeHoldersLen > 0 ? validLen - 4 : validLen;
      var i2;
      for (i2 = 0; i2 < len2; i2 += 4) {
        tmp = revLookup[b64.charCodeAt(i2)] << 18 | revLookup[b64.charCodeAt(i2 + 1)] << 12 | revLookup[b64.charCodeAt(i2 + 2)] << 6 | revLookup[b64.charCodeAt(i2 + 3)];
        arr[curByte++] = tmp >> 16 & 255;
        arr[curByte++] = tmp >> 8 & 255;
        arr[curByte++] = tmp & 255;
      }
      if (placeHoldersLen === 2) {
        tmp = revLookup[b64.charCodeAt(i2)] << 2 | revLookup[b64.charCodeAt(i2 + 1)] >> 4;
        arr[curByte++] = tmp & 255;
      }
      if (placeHoldersLen === 1) {
        tmp = revLookup[b64.charCodeAt(i2)] << 10 | revLookup[b64.charCodeAt(i2 + 1)] << 4 | revLookup[b64.charCodeAt(i2 + 2)] >> 2;
        arr[curByte++] = tmp >> 8 & 255;
        arr[curByte++] = tmp & 255;
      }
      return arr;
    }
    function tripletToBase64(num) {
      return lookup[num >> 18 & 63] + lookup[num >> 12 & 63] + lookup[num >> 6 & 63] + lookup[num & 63];
    }
    function encodeChunk(uint8, start, end) {
      var tmp;
      var output = [];
      for (var i2 = start; i2 < end; i2 += 3) {
        tmp = (uint8[i2] << 16 & 16711680) + (uint8[i2 + 1] << 8 & 65280) + (uint8[i2 + 2] & 255);
        output.push(tripletToBase64(tmp));
      }
      return output.join("");
    }
    function fromByteArray(uint8) {
      var tmp;
      var len2 = uint8.length;
      var extraBytes = len2 % 3;
      var parts = [];
      var maxChunkLength = 16383;
      for (var i2 = 0, len22 = len2 - extraBytes; i2 < len22; i2 += maxChunkLength) {
        parts.push(encodeChunk(uint8, i2, i2 + maxChunkLength > len22 ? len22 : i2 + maxChunkLength));
      }
      if (extraBytes === 1) {
        tmp = uint8[len2 - 1];
        parts.push(
          lookup[tmp >> 2] + lookup[tmp << 4 & 63] + "=="
        );
      } else if (extraBytes === 2) {
        tmp = (uint8[len2 - 2] << 8) + uint8[len2 - 1];
        parts.push(
          lookup[tmp >> 10] + lookup[tmp >> 4 & 63] + lookup[tmp << 2 & 63] + "="
        );
      }
      return parts.join("");
    }
  }
});

// node_modules/@langchain/groq/dist/profiles.js
var PROFILES = {
  "llama-3.1-8b-instant": {
    maxInputTokens: 131072,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: false,
    videoInputs: false,
    maxOutputTokens: 8192,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: false
  },
  "mistral-saba-24b": {
    maxInputTokens: 32768,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: false,
    videoInputs: false,
    maxOutputTokens: 32768,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: false
  },
  "llama3-8b-8192": {
    maxInputTokens: 8192,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: false,
    videoInputs: false,
    maxOutputTokens: 8192,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: false
  },
  "qwen-qwq-32b": {
    maxInputTokens: 131072,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: false,
    videoInputs: false,
    maxOutputTokens: 16384,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: false
  },
  "llama3-70b-8192": {
    maxInputTokens: 8192,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: false,
    videoInputs: false,
    maxOutputTokens: 8192,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: false
  },
  "deepseek-r1-distill-llama-70b": {
    maxInputTokens: 131072,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: false,
    videoInputs: false,
    maxOutputTokens: 8192,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: false
  },
  "llama-guard-3-8b": {
    maxInputTokens: 8192,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: false,
    videoInputs: false,
    maxOutputTokens: 8192,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: false,
    structuredOutput: false
  },
  "gemma2-9b-it": {
    maxInputTokens: 8192,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: false,
    videoInputs: false,
    maxOutputTokens: 8192,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: false
  },
  "llama-3.3-70b-versatile": {
    maxInputTokens: 131072,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: false,
    videoInputs: false,
    maxOutputTokens: 32768,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: false
  },
  "moonshotai/kimi-k2-instruct-0905": {
    maxInputTokens: 262144,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: false,
    videoInputs: false,
    maxOutputTokens: 16384,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: false
  },
  "moonshotai/kimi-k2-instruct": {
    maxInputTokens: 131072,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: false,
    videoInputs: false,
    maxOutputTokens: 16384,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: false
  },
  "openai/gpt-oss-20b": {
    maxInputTokens: 131072,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: false,
    videoInputs: false,
    maxOutputTokens: 32768,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: false
  },
  "openai/gpt-oss-120b": {
    maxInputTokens: 131072,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: false,
    videoInputs: false,
    maxOutputTokens: 32768,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: false
  },
  "qwen/qwen3-32b": {
    maxInputTokens: 131072,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: false,
    videoInputs: false,
    maxOutputTokens: 16384,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: false
  },
  "meta-llama/llama-4-scout-17b-16e-instruct": {
    maxInputTokens: 131072,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: false,
    videoInputs: false,
    maxOutputTokens: 8192,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: false
  },
  "meta-llama/llama-4-maverick-17b-128e-instruct": {
    maxInputTokens: 131072,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: false,
    videoInputs: false,
    maxOutputTokens: 8192,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: false
  },
  "meta-llama/llama-guard-4-12b": {
    maxInputTokens: 131072,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: false,
    videoInputs: false,
    maxOutputTokens: 128,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: false,
    structuredOutput: false
  }
};
var profiles_default = PROFILES;

// node_modules/@langchain/core/dist/prompt_values.js
var prompt_values_exports = {};
__export(prompt_values_exports, {
  BasePromptValue: () => BasePromptValue,
  ChatPromptValue: () => ChatPromptValue,
  ImagePromptValue: () => ImagePromptValue,
  StringPromptValue: () => StringPromptValue
});
var BasePromptValue = class extends Serializable {
};
var StringPromptValue = class extends BasePromptValue {
  constructor(value) {
    super({ value });
    __publicField(this, "lc_namespace", ["langchain_core", "prompt_values"]);
    __publicField(this, "lc_serializable", true);
    __publicField(this, "value");
    this.value = value;
  }
  static lc_name() {
    return "StringPromptValue";
  }
  toString() {
    return this.value;
  }
  toChatMessages() {
    return [new HumanMessage(this.value)];
  }
};
var ChatPromptValue = class extends BasePromptValue {
  constructor(fields) {
    if (Array.isArray(fields)) fields = { messages: fields };
    super(fields);
    __publicField(this, "lc_namespace", ["langchain_core", "prompt_values"]);
    __publicField(this, "lc_serializable", true);
    __publicField(this, "messages");
    this.messages = fields.messages;
  }
  static lc_name() {
    return "ChatPromptValue";
  }
  toString() {
    return getBufferString(this.messages);
  }
  toChatMessages() {
    return this.messages;
  }
};
var ImagePromptValue = class extends BasePromptValue {
  constructor(fields) {
    if (!("imageUrl" in fields)) fields = { imageUrl: fields };
    super(fields);
    __publicField(this, "lc_namespace", ["langchain_core", "prompt_values"]);
    __publicField(this, "lc_serializable", true);
    __publicField(this, "imageUrl");
    /** @ignore */
    __publicField(this, "value");
    this.imageUrl = fields.imageUrl;
  }
  static lc_name() {
    return "ImagePromptValue";
  }
  toString() {
    return this.imageUrl.url;
  }
  toChatMessages() {
    return [new HumanMessage({ content: [{
      type: "image_url",
      image_url: {
        detail: this.imageUrl.detail,
        url: this.imageUrl.url
      }
    }] })];
  }
};

// node_modules/@langchain/core/dist/utils/js-sha256/hash.js
var HEX_CHARS = "0123456789abcdef".split("");
var EXTRA = [
  -2147483648,
  8388608,
  32768,
  128
];
var SHIFT = [
  24,
  16,
  8,
  0
];
var K = [
  1116352408,
  1899447441,
  3049323471,
  3921009573,
  961987163,
  1508970993,
  2453635748,
  2870763221,
  3624381080,
  310598401,
  607225278,
  1426881987,
  1925078388,
  2162078206,
  2614888103,
  3248222580,
  3835390401,
  4022224774,
  264347078,
  604807628,
  770255983,
  1249150122,
  1555081692,
  1996064986,
  2554220882,
  2821834349,
  2952996808,
  3210313671,
  3336571891,
  3584528711,
  113926993,
  338241895,
  666307205,
  773529912,
  1294757372,
  1396182291,
  1695183700,
  1986661051,
  2177026350,
  2456956037,
  2730485921,
  2820302411,
  3259730800,
  3345764771,
  3516065817,
  3600352804,
  4094571909,
  275423344,
  430227734,
  506948616,
  659060556,
  883997877,
  958139571,
  1322822218,
  1537002063,
  1747873779,
  1955562222,
  2024104815,
  2227730452,
  2361852424,
  2428436474,
  2756734187,
  3204031479,
  3329325298
];
var blocks = [];
function Sha256(is224, sharedMemory) {
  if (sharedMemory) {
    blocks[0] = blocks[16] = blocks[1] = blocks[2] = blocks[3] = blocks[4] = blocks[5] = blocks[6] = blocks[7] = blocks[8] = blocks[9] = blocks[10] = blocks[11] = blocks[12] = blocks[13] = blocks[14] = blocks[15] = 0;
    this.blocks = blocks;
  } else this.blocks = [
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0
  ];
  if (is224) {
    this.h0 = 3238371032;
    this.h1 = 914150663;
    this.h2 = 812702999;
    this.h3 = 4144912697;
    this.h4 = 4290775857;
    this.h5 = 1750603025;
    this.h6 = 1694076839;
    this.h7 = 3204075428;
  } else {
    this.h0 = 1779033703;
    this.h1 = 3144134277;
    this.h2 = 1013904242;
    this.h3 = 2773480762;
    this.h4 = 1359893119;
    this.h5 = 2600822924;
    this.h6 = 528734635;
    this.h7 = 1541459225;
  }
  this.block = this.start = this.bytes = this.hBytes = 0;
  this.finalized = this.hashed = false;
  this.first = true;
  this.is224 = is224;
}
Sha256.prototype.update = function(message) {
  if (this.finalized) return;
  var notString, type = typeof message;
  if (type !== "string") {
    if (type === "object") {
      if (message === null) throw new Error(ERROR);
      else if (ARRAY_BUFFER && message.constructor === ArrayBuffer) message = new Uint8Array(message);
      else if (!Array.isArray(message)) {
        if (!ARRAY_BUFFER || !ArrayBuffer.isView(message)) throw new Error(ERROR);
      }
    } else throw new Error(ERROR);
    notString = true;
  }
  var code, index = 0, i, length = message.length, blocks$1 = this.blocks;
  while (index < length) {
    if (this.hashed) {
      this.hashed = false;
      blocks$1[0] = this.block;
      this.block = blocks$1[16] = blocks$1[1] = blocks$1[2] = blocks$1[3] = blocks$1[4] = blocks$1[5] = blocks$1[6] = blocks$1[7] = blocks$1[8] = blocks$1[9] = blocks$1[10] = blocks$1[11] = blocks$1[12] = blocks$1[13] = blocks$1[14] = blocks$1[15] = 0;
    }
    if (notString) for (i = this.start; index < length && i < 64; ++index) blocks$1[i >>> 2] |= message[index] << SHIFT[i++ & 3];
    else for (i = this.start; index < length && i < 64; ++index) {
      code = message.charCodeAt(index);
      if (code < 128) blocks$1[i >>> 2] |= code << SHIFT[i++ & 3];
      else if (code < 2048) {
        blocks$1[i >>> 2] |= (192 | code >>> 6) << SHIFT[i++ & 3];
        blocks$1[i >>> 2] |= (128 | code & 63) << SHIFT[i++ & 3];
      } else if (code < 55296 || code >= 57344) {
        blocks$1[i >>> 2] |= (224 | code >>> 12) << SHIFT[i++ & 3];
        blocks$1[i >>> 2] |= (128 | code >>> 6 & 63) << SHIFT[i++ & 3];
        blocks$1[i >>> 2] |= (128 | code & 63) << SHIFT[i++ & 3];
      } else {
        code = 65536 + ((code & 1023) << 10 | message.charCodeAt(++index) & 1023);
        blocks$1[i >>> 2] |= (240 | code >>> 18) << SHIFT[i++ & 3];
        blocks$1[i >>> 2] |= (128 | code >>> 12 & 63) << SHIFT[i++ & 3];
        blocks$1[i >>> 2] |= (128 | code >>> 6 & 63) << SHIFT[i++ & 3];
        blocks$1[i >>> 2] |= (128 | code & 63) << SHIFT[i++ & 3];
      }
    }
    this.lastByteIndex = i;
    this.bytes += i - this.start;
    if (i >= 64) {
      this.block = blocks$1[16];
      this.start = i - 64;
      this.hash();
      this.hashed = true;
    } else this.start = i;
  }
  if (this.bytes > 4294967295) {
    this.hBytes += this.bytes / 4294967296 << 0;
    this.bytes = this.bytes % 4294967296;
  }
  return this;
};
Sha256.prototype.finalize = function() {
  if (this.finalized) return;
  this.finalized = true;
  var blocks$1 = this.blocks, i = this.lastByteIndex;
  blocks$1[16] = this.block;
  blocks$1[i >>> 2] |= EXTRA[i & 3];
  this.block = blocks$1[16];
  if (i >= 56) {
    if (!this.hashed) this.hash();
    blocks$1[0] = this.block;
    blocks$1[16] = blocks$1[1] = blocks$1[2] = blocks$1[3] = blocks$1[4] = blocks$1[5] = blocks$1[6] = blocks$1[7] = blocks$1[8] = blocks$1[9] = blocks$1[10] = blocks$1[11] = blocks$1[12] = blocks$1[13] = blocks$1[14] = blocks$1[15] = 0;
  }
  blocks$1[14] = this.hBytes << 3 | this.bytes >>> 29;
  blocks$1[15] = this.bytes << 3;
  this.hash();
};
Sha256.prototype.hash = function() {
  var a = this.h0, b = this.h1, c = this.h2, d = this.h3, e = this.h4, f = this.h5, g = this.h6, h = this.h7, blocks$1 = this.blocks, j, s0, s1, maj, t1, t2, ch, ab, da, cd, bc;
  for (j = 16; j < 64; ++j) {
    t1 = blocks$1[j - 15];
    s0 = (t1 >>> 7 | t1 << 25) ^ (t1 >>> 18 | t1 << 14) ^ t1 >>> 3;
    t1 = blocks$1[j - 2];
    s1 = (t1 >>> 17 | t1 << 15) ^ (t1 >>> 19 | t1 << 13) ^ t1 >>> 10;
    blocks$1[j] = blocks$1[j - 16] + s0 + blocks$1[j - 7] + s1 << 0;
  }
  bc = b & c;
  for (j = 0; j < 64; j += 4) {
    if (this.first) {
      if (this.is224) {
        ab = 300032;
        t1 = blocks$1[0] - 1413257819;
        h = t1 - 150054599 << 0;
        d = t1 + 24177077 << 0;
      } else {
        ab = 704751109;
        t1 = blocks$1[0] - 210244248;
        h = t1 - 1521486534 << 0;
        d = t1 + 143694565 << 0;
      }
      this.first = false;
    } else {
      s0 = (a >>> 2 | a << 30) ^ (a >>> 13 | a << 19) ^ (a >>> 22 | a << 10);
      s1 = (e >>> 6 | e << 26) ^ (e >>> 11 | e << 21) ^ (e >>> 25 | e << 7);
      ab = a & b;
      maj = ab ^ a & c ^ bc;
      ch = e & f ^ ~e & g;
      t1 = h + s1 + ch + K[j] + blocks$1[j];
      t2 = s0 + maj;
      h = d + t1 << 0;
      d = t1 + t2 << 0;
    }
    s0 = (d >>> 2 | d << 30) ^ (d >>> 13 | d << 19) ^ (d >>> 22 | d << 10);
    s1 = (h >>> 6 | h << 26) ^ (h >>> 11 | h << 21) ^ (h >>> 25 | h << 7);
    da = d & a;
    maj = da ^ d & b ^ ab;
    ch = g & h ^ ~g & e;
    t1 = f + s1 + ch + K[j + 1] + blocks$1[j + 1];
    t2 = s0 + maj;
    g = c + t1 << 0;
    c = t1 + t2 << 0;
    s0 = (c >>> 2 | c << 30) ^ (c >>> 13 | c << 19) ^ (c >>> 22 | c << 10);
    s1 = (g >>> 6 | g << 26) ^ (g >>> 11 | g << 21) ^ (g >>> 25 | g << 7);
    cd = c & d;
    maj = cd ^ c & a ^ da;
    ch = f & g ^ ~f & h;
    t1 = e + s1 + ch + K[j + 2] + blocks$1[j + 2];
    t2 = s0 + maj;
    f = b + t1 << 0;
    b = t1 + t2 << 0;
    s0 = (b >>> 2 | b << 30) ^ (b >>> 13 | b << 19) ^ (b >>> 22 | b << 10);
    s1 = (f >>> 6 | f << 26) ^ (f >>> 11 | f << 21) ^ (f >>> 25 | f << 7);
    bc = b & c;
    maj = bc ^ b & d ^ cd;
    ch = f & g ^ ~f & h;
    t1 = e + s1 + ch + K[j + 3] + blocks$1[j + 3];
    t2 = s0 + maj;
    e = a + t1 << 0;
    a = t1 + t2 << 0;
    this.chromeBugWorkAround = true;
  }
  this.h0 = this.h0 + a << 0;
  this.h1 = this.h1 + b << 0;
  this.h2 = this.h2 + c << 0;
  this.h3 = this.h3 + d << 0;
  this.h4 = this.h4 + e << 0;
  this.h5 = this.h5 + f << 0;
  this.h6 = this.h6 + g << 0;
  this.h7 = this.h7 + h << 0;
};
Sha256.prototype.hex = function() {
  this.finalize();
  var h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3, h4 = this.h4, h5 = this.h5, h6 = this.h6, h7 = this.h7;
  var hex = HEX_CHARS[h0 >>> 28 & 15] + HEX_CHARS[h0 >>> 24 & 15] + HEX_CHARS[h0 >>> 20 & 15] + HEX_CHARS[h0 >>> 16 & 15] + HEX_CHARS[h0 >>> 12 & 15] + HEX_CHARS[h0 >>> 8 & 15] + HEX_CHARS[h0 >>> 4 & 15] + HEX_CHARS[h0 & 15] + HEX_CHARS[h1 >>> 28 & 15] + HEX_CHARS[h1 >>> 24 & 15] + HEX_CHARS[h1 >>> 20 & 15] + HEX_CHARS[h1 >>> 16 & 15] + HEX_CHARS[h1 >>> 12 & 15] + HEX_CHARS[h1 >>> 8 & 15] + HEX_CHARS[h1 >>> 4 & 15] + HEX_CHARS[h1 & 15] + HEX_CHARS[h2 >>> 28 & 15] + HEX_CHARS[h2 >>> 24 & 15] + HEX_CHARS[h2 >>> 20 & 15] + HEX_CHARS[h2 >>> 16 & 15] + HEX_CHARS[h2 >>> 12 & 15] + HEX_CHARS[h2 >>> 8 & 15] + HEX_CHARS[h2 >>> 4 & 15] + HEX_CHARS[h2 & 15] + HEX_CHARS[h3 >>> 28 & 15] + HEX_CHARS[h3 >>> 24 & 15] + HEX_CHARS[h3 >>> 20 & 15] + HEX_CHARS[h3 >>> 16 & 15] + HEX_CHARS[h3 >>> 12 & 15] + HEX_CHARS[h3 >>> 8 & 15] + HEX_CHARS[h3 >>> 4 & 15] + HEX_CHARS[h3 & 15] + HEX_CHARS[h4 >>> 28 & 15] + HEX_CHARS[h4 >>> 24 & 15] + HEX_CHARS[h4 >>> 20 & 15] + HEX_CHARS[h4 >>> 16 & 15] + HEX_CHARS[h4 >>> 12 & 15] + HEX_CHARS[h4 >>> 8 & 15] + HEX_CHARS[h4 >>> 4 & 15] + HEX_CHARS[h4 & 15] + HEX_CHARS[h5 >>> 28 & 15] + HEX_CHARS[h5 >>> 24 & 15] + HEX_CHARS[h5 >>> 20 & 15] + HEX_CHARS[h5 >>> 16 & 15] + HEX_CHARS[h5 >>> 12 & 15] + HEX_CHARS[h5 >>> 8 & 15] + HEX_CHARS[h5 >>> 4 & 15] + HEX_CHARS[h5 & 15] + HEX_CHARS[h6 >>> 28 & 15] + HEX_CHARS[h6 >>> 24 & 15] + HEX_CHARS[h6 >>> 20 & 15] + HEX_CHARS[h6 >>> 16 & 15] + HEX_CHARS[h6 >>> 12 & 15] + HEX_CHARS[h6 >>> 8 & 15] + HEX_CHARS[h6 >>> 4 & 15] + HEX_CHARS[h6 & 15];
  if (!this.is224) hex += HEX_CHARS[h7 >>> 28 & 15] + HEX_CHARS[h7 >>> 24 & 15] + HEX_CHARS[h7 >>> 20 & 15] + HEX_CHARS[h7 >>> 16 & 15] + HEX_CHARS[h7 >>> 12 & 15] + HEX_CHARS[h7 >>> 8 & 15] + HEX_CHARS[h7 >>> 4 & 15] + HEX_CHARS[h7 & 15];
  return hex;
};
Sha256.prototype.toString = Sha256.prototype.hex;
Sha256.prototype.digest = function() {
  this.finalize();
  var h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3, h4 = this.h4, h5 = this.h5, h6 = this.h6, h7 = this.h7;
  var arr = [
    h0 >>> 24 & 255,
    h0 >>> 16 & 255,
    h0 >>> 8 & 255,
    h0 & 255,
    h1 >>> 24 & 255,
    h1 >>> 16 & 255,
    h1 >>> 8 & 255,
    h1 & 255,
    h2 >>> 24 & 255,
    h2 >>> 16 & 255,
    h2 >>> 8 & 255,
    h2 & 255,
    h3 >>> 24 & 255,
    h3 >>> 16 & 255,
    h3 >>> 8 & 255,
    h3 & 255,
    h4 >>> 24 & 255,
    h4 >>> 16 & 255,
    h4 >>> 8 & 255,
    h4 & 255,
    h5 >>> 24 & 255,
    h5 >>> 16 & 255,
    h5 >>> 8 & 255,
    h5 & 255,
    h6 >>> 24 & 255,
    h6 >>> 16 & 255,
    h6 >>> 8 & 255,
    h6 & 255
  ];
  if (!this.is224) arr.push(h7 >>> 24 & 255, h7 >>> 16 & 255, h7 >>> 8 & 255, h7 & 255);
  return arr;
};
Sha256.prototype.array = Sha256.prototype.digest;
Sha256.prototype.arrayBuffer = function() {
  this.finalize();
  var buffer = new ArrayBuffer(this.is224 ? 28 : 32);
  var dataView = new DataView(buffer);
  dataView.setUint32(0, this.h0);
  dataView.setUint32(4, this.h1);
  dataView.setUint32(8, this.h2);
  dataView.setUint32(12, this.h3);
  dataView.setUint32(16, this.h4);
  dataView.setUint32(20, this.h5);
  dataView.setUint32(24, this.h6);
  if (!this.is224) dataView.setUint32(28, this.h7);
  return buffer;
};
var sha256 = (...strings) => {
  return new Sha256(false, true).update(strings.join("")).hex();
};

// node_modules/@langchain/core/dist/utils/hash.js
var hash_exports = {};
__export(hash_exports, { sha256: () => sha256 });

// node_modules/@langchain/core/dist/caches/index.js
var caches_exports = {};
__export(caches_exports, {
  BaseCache: () => BaseCache,
  InMemoryCache: () => InMemoryCache,
  defaultHashKeyEncoder: () => defaultHashKeyEncoder,
  deserializeStoredGeneration: () => deserializeStoredGeneration,
  serializeGeneration: () => serializeGeneration
});
var defaultHashKeyEncoder = (...strings) => sha256(strings.join("_"));
function deserializeStoredGeneration(storedGeneration) {
  if (storedGeneration.message !== void 0) return {
    text: storedGeneration.text,
    message: mapStoredMessageToChatMessage(storedGeneration.message)
  };
  else return { text: storedGeneration.text };
}
function serializeGeneration(generation) {
  const serializedValue = { text: generation.text };
  if (generation.message !== void 0) serializedValue.message = generation.message.toDict();
  return serializedValue;
}
var BaseCache = class {
  constructor() {
    __publicField(this, "keyEncoder", defaultHashKeyEncoder);
  }
  /**
  * Sets a custom key encoder function for the cache.
  * This function should take a prompt and an LLM key and return a string
  * that will be used as the cache key.
  * @param keyEncoderFn The custom key encoder function.
  */
  makeDefaultKeyEncoder(keyEncoderFn) {
    this.keyEncoder = keyEncoderFn;
  }
};
var GLOBAL_MAP = /* @__PURE__ */ new Map();
var InMemoryCache = class InMemoryCache2 extends BaseCache {
  constructor(map) {
    super();
    __publicField(this, "cache");
    this.cache = map ?? /* @__PURE__ */ new Map();
  }
  /**
  * Retrieves data from the cache using a prompt and an LLM key. If the
  * data is not found, it returns null.
  * @param prompt The prompt used to find the data.
  * @param llmKey The LLM key used to find the data.
  * @returns The data corresponding to the prompt and LLM key, or null if not found.
  */
  lookup(prompt, llmKey) {
    return Promise.resolve(this.cache.get(this.keyEncoder(prompt, llmKey)) ?? null);
  }
  /**
  * Updates the cache with new data using a prompt and an LLM key.
  * @param prompt The prompt used to store the data.
  * @param llmKey The LLM key used to store the data.
  * @param value The data to be stored.
  */
  async update(prompt, llmKey, value) {
    this.cache.set(this.keyEncoder(prompt, llmKey), value);
  }
  /**
  * Returns a global instance of InMemoryCache using a predefined global
  * map as the initial cache.
  * @returns A global instance of InMemoryCache.
  */
  static global() {
    return new InMemoryCache2(GLOBAL_MAP);
  }
};

// node_modules/js-tiktoken/dist/chunk-VL2OQCWN.js
var import_base64_js = __toESM(require_base64_js(), 1);
var __defProp = Object.defineProperty;
var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __publicField2 = (obj, key, value) => {
  __defNormalProp(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
function bytePairMerge(piece, ranks) {
  let parts = Array.from(
    { length: piece.length },
    (_, i) => ({ start: i, end: i + 1 })
  );
  while (parts.length > 1) {
    let minRank = null;
    for (let i = 0; i < parts.length - 1; i++) {
      const slice = piece.slice(parts[i].start, parts[i + 1].end);
      const rank = ranks.get(slice.join(","));
      if (rank == null)
        continue;
      if (minRank == null || rank < minRank[0]) {
        minRank = [rank, i];
      }
    }
    if (minRank != null) {
      const i = minRank[1];
      parts[i] = { start: parts[i].start, end: parts[i + 1].end };
      parts.splice(i + 1, 1);
    } else {
      break;
    }
  }
  return parts;
}
function bytePairEncode(piece, ranks) {
  if (piece.length === 1)
    return [ranks.get(piece.join(","))];
  return bytePairMerge(piece, ranks).map((p) => ranks.get(piece.slice(p.start, p.end).join(","))).filter((x) => x != null);
}
function escapeRegex(str) {
  return str.replace(/[\\^$*+?.()|[\]{}]/g, "\\$&");
}
var _Tiktoken = class {
  constructor(ranks, extendedSpecialTokens) {
    /** @internal */
    __publicField(this, "specialTokens");
    /** @internal */
    __publicField(this, "inverseSpecialTokens");
    /** @internal */
    __publicField(this, "patStr");
    /** @internal */
    __publicField(this, "textEncoder", new TextEncoder());
    /** @internal */
    __publicField(this, "textDecoder", new TextDecoder("utf-8"));
    /** @internal */
    __publicField(this, "rankMap", /* @__PURE__ */ new Map());
    /** @internal */
    __publicField(this, "textMap", /* @__PURE__ */ new Map());
    this.patStr = ranks.pat_str;
    const uncompressed = ranks.bpe_ranks.split("\n").filter(Boolean).reduce((memo, x) => {
      const [_, offsetStr, ...tokens] = x.split(" ");
      const offset = Number.parseInt(offsetStr, 10);
      tokens.forEach((token, i) => memo[token] = offset + i);
      return memo;
    }, {});
    for (const [token, rank] of Object.entries(uncompressed)) {
      const bytes = import_base64_js.default.toByteArray(token);
      this.rankMap.set(bytes.join(","), rank);
      this.textMap.set(rank, bytes);
    }
    this.specialTokens = { ...ranks.special_tokens, ...extendedSpecialTokens };
    this.inverseSpecialTokens = Object.entries(this.specialTokens).reduce((memo, [text, rank]) => {
      memo[rank] = this.textEncoder.encode(text);
      return memo;
    }, {});
  }
  encode(text, allowedSpecial = [], disallowedSpecial = "all") {
    const regexes = new RegExp(this.patStr, "ug");
    const specialRegex = _Tiktoken.specialTokenRegex(
      Object.keys(this.specialTokens)
    );
    const ret = [];
    const allowedSpecialSet = new Set(
      allowedSpecial === "all" ? Object.keys(this.specialTokens) : allowedSpecial
    );
    const disallowedSpecialSet = new Set(
      disallowedSpecial === "all" ? Object.keys(this.specialTokens).filter(
        (x) => !allowedSpecialSet.has(x)
      ) : disallowedSpecial
    );
    if (disallowedSpecialSet.size > 0) {
      const disallowedSpecialRegex = _Tiktoken.specialTokenRegex([
        ...disallowedSpecialSet
      ]);
      const specialMatch = text.match(disallowedSpecialRegex);
      if (specialMatch != null) {
        throw new Error(
          `The text contains a special token that is not allowed: ${specialMatch[0]}`
        );
      }
    }
    let start = 0;
    while (true) {
      let nextSpecial = null;
      let startFind = start;
      while (true) {
        specialRegex.lastIndex = startFind;
        nextSpecial = specialRegex.exec(text);
        if (nextSpecial == null || allowedSpecialSet.has(nextSpecial[0]))
          break;
        startFind = nextSpecial.index + 1;
      }
      const end = (nextSpecial == null ? void 0 : nextSpecial.index) ?? text.length;
      for (const match of text.substring(start, end).matchAll(regexes)) {
        const piece = this.textEncoder.encode(match[0]);
        const token2 = this.rankMap.get(piece.join(","));
        if (token2 != null) {
          ret.push(token2);
          continue;
        }
        ret.push(...bytePairEncode(piece, this.rankMap));
      }
      if (nextSpecial == null)
        break;
      let token = this.specialTokens[nextSpecial[0]];
      ret.push(token);
      start = nextSpecial.index + nextSpecial[0].length;
    }
    return ret;
  }
  decode(tokens) {
    const res = [];
    let length = 0;
    for (let i2 = 0; i2 < tokens.length; ++i2) {
      const token = tokens[i2];
      const bytes = this.textMap.get(token) ?? this.inverseSpecialTokens[token];
      if (bytes != null) {
        res.push(bytes);
        length += bytes.length;
      }
    }
    const mergedArray = new Uint8Array(length);
    let i = 0;
    for (const bytes of res) {
      mergedArray.set(bytes, i);
      i += bytes.length;
    }
    return this.textDecoder.decode(mergedArray);
  }
};
var Tiktoken = _Tiktoken;
__publicField2(Tiktoken, "specialTokenRegex", (tokens) => {
  return new RegExp(tokens.map((i) => escapeRegex(i)).join("|"), "g");
});
function getEncodingNameForModel(model) {
  switch (model) {
    case "gpt2": {
      return "gpt2";
    }
    case "code-cushman-001":
    case "code-cushman-002":
    case "code-davinci-001":
    case "code-davinci-002":
    case "cushman-codex":
    case "davinci-codex":
    case "davinci-002":
    case "text-davinci-002":
    case "text-davinci-003": {
      return "p50k_base";
    }
    case "code-davinci-edit-001":
    case "text-davinci-edit-001": {
      return "p50k_edit";
    }
    case "ada":
    case "babbage":
    case "babbage-002":
    case "code-search-ada-code-001":
    case "code-search-babbage-code-001":
    case "curie":
    case "davinci":
    case "text-ada-001":
    case "text-babbage-001":
    case "text-curie-001":
    case "text-davinci-001":
    case "text-search-ada-doc-001":
    case "text-search-babbage-doc-001":
    case "text-search-curie-doc-001":
    case "text-search-davinci-doc-001":
    case "text-similarity-ada-001":
    case "text-similarity-babbage-001":
    case "text-similarity-curie-001":
    case "text-similarity-davinci-001": {
      return "r50k_base";
    }
    case "gpt-3.5-turbo-instruct-0914":
    case "gpt-3.5-turbo-instruct":
    case "gpt-3.5-turbo-16k-0613":
    case "gpt-3.5-turbo-16k":
    case "gpt-3.5-turbo-0613":
    case "gpt-3.5-turbo-0301":
    case "gpt-3.5-turbo":
    case "gpt-4-32k-0613":
    case "gpt-4-32k-0314":
    case "gpt-4-32k":
    case "gpt-4-0613":
    case "gpt-4-0314":
    case "gpt-4":
    case "gpt-3.5-turbo-1106":
    case "gpt-35-turbo":
    case "gpt-4-1106-preview":
    case "gpt-4-vision-preview":
    case "gpt-3.5-turbo-0125":
    case "gpt-4-turbo":
    case "gpt-4-turbo-2024-04-09":
    case "gpt-4-turbo-preview":
    case "gpt-4-0125-preview":
    case "text-embedding-ada-002":
    case "text-embedding-3-small":
    case "text-embedding-3-large": {
      return "cl100k_base";
    }
    case "gpt-4o":
    case "gpt-4o-2024-05-13":
    case "gpt-4o-2024-08-06":
    case "gpt-4o-2024-11-20":
    case "gpt-4o-mini-2024-07-18":
    case "gpt-4o-mini":
    case "gpt-4o-search-preview":
    case "gpt-4o-search-preview-2025-03-11":
    case "gpt-4o-mini-search-preview":
    case "gpt-4o-mini-search-preview-2025-03-11":
    case "gpt-4o-audio-preview":
    case "gpt-4o-audio-preview-2024-12-17":
    case "gpt-4o-audio-preview-2024-10-01":
    case "gpt-4o-mini-audio-preview":
    case "gpt-4o-mini-audio-preview-2024-12-17":
    case "o1":
    case "o1-2024-12-17":
    case "o1-mini":
    case "o1-mini-2024-09-12":
    case "o1-preview":
    case "o1-preview-2024-09-12":
    case "o1-pro":
    case "o1-pro-2025-03-19":
    case "o3":
    case "o3-2025-04-16":
    case "o3-mini":
    case "o3-mini-2025-01-31":
    case "o4-mini":
    case "o4-mini-2025-04-16":
    case "chatgpt-4o-latest":
    case "gpt-4o-realtime":
    case "gpt-4o-realtime-preview-2024-10-01":
    case "gpt-4o-realtime-preview-2024-12-17":
    case "gpt-4o-mini-realtime-preview":
    case "gpt-4o-mini-realtime-preview-2024-12-17":
    case "gpt-4.1":
    case "gpt-4.1-2025-04-14":
    case "gpt-4.1-mini":
    case "gpt-4.1-mini-2025-04-14":
    case "gpt-4.1-nano":
    case "gpt-4.1-nano-2025-04-14":
    case "gpt-4.5-preview":
    case "gpt-4.5-preview-2025-02-27":
    case "gpt-5":
    case "gpt-5-2025-08-07":
    case "gpt-5-nano":
    case "gpt-5-nano-2025-08-07":
    case "gpt-5-mini":
    case "gpt-5-mini-2025-08-07":
    case "gpt-5-chat-latest": {
      return "o200k_base";
    }
    default:
      throw new Error("Unknown model");
  }
}

// node_modules/@langchain/core/dist/utils/tiktoken.js
var tiktoken_exports = {};
__export(tiktoken_exports, {
  encodingForModel: () => encodingForModel,
  getEncoding: () => getEncoding
});
var cache = {};
var caller = new AsyncCaller({});
async function getEncoding(encoding) {
  if (!(encoding in cache)) cache[encoding] = caller.fetch(`https://tiktoken.pages.dev/js/${encoding}.json`).then((res) => res.json()).then((data) => new Tiktoken(data)).catch((e) => {
    delete cache[encoding];
    throw e;
  });
  return await cache[encoding];
}
async function encodingForModel(model) {
  return getEncoding(getEncodingNameForModel(model));
}

// node_modules/@langchain/core/dist/language_models/base.js
var base_exports = {};
__export(base_exports, {
  BaseLangChain: () => BaseLangChain,
  BaseLanguageModel: () => BaseLanguageModel,
  calculateMaxTokens: () => calculateMaxTokens,
  getEmbeddingContextSize: () => getEmbeddingContextSize,
  getModelContextSize: () => getModelContextSize,
  getModelNameForTiktoken: () => getModelNameForTiktoken,
  isOpenAITool: () => isOpenAITool
});
var getModelNameForTiktoken = (modelName) => {
  if (modelName.startsWith("gpt-5")) return "gpt-5";
  if (modelName.startsWith("gpt-3.5-turbo-16k")) return "gpt-3.5-turbo-16k";
  if (modelName.startsWith("gpt-3.5-turbo-")) return "gpt-3.5-turbo";
  if (modelName.startsWith("gpt-4-32k")) return "gpt-4-32k";
  if (modelName.startsWith("gpt-4-")) return "gpt-4";
  if (modelName.startsWith("gpt-4o")) return "gpt-4o";
  return modelName;
};
var getEmbeddingContextSize = (modelName) => {
  switch (modelName) {
    case "text-embedding-ada-002":
      return 8191;
    default:
      return 2046;
  }
};
var getModelContextSize = (modelName) => {
  const normalizedName = getModelNameForTiktoken(modelName);
  switch (normalizedName) {
    case "gpt-5":
    case "gpt-5-turbo":
    case "gpt-5-turbo-preview":
      return 4e5;
    case "gpt-4o":
    case "gpt-4o-mini":
    case "gpt-4o-2024-05-13":
    case "gpt-4o-2024-08-06":
      return 128e3;
    case "gpt-4-turbo":
    case "gpt-4-turbo-preview":
    case "gpt-4-turbo-2024-04-09":
    case "gpt-4-0125-preview":
    case "gpt-4-1106-preview":
      return 128e3;
    case "gpt-4-32k":
    case "gpt-4-32k-0314":
    case "gpt-4-32k-0613":
      return 32768;
    case "gpt-4":
    case "gpt-4-0314":
    case "gpt-4-0613":
      return 8192;
    case "gpt-3.5-turbo-16k":
    case "gpt-3.5-turbo-16k-0613":
      return 16384;
    case "gpt-3.5-turbo":
    case "gpt-3.5-turbo-0301":
    case "gpt-3.5-turbo-0613":
    case "gpt-3.5-turbo-1106":
    case "gpt-3.5-turbo-0125":
      return 4096;
    case "text-davinci-003":
    case "text-davinci-002":
      return 4097;
    case "text-davinci-001":
      return 2049;
    case "text-curie-001":
    case "text-babbage-001":
    case "text-ada-001":
      return 2048;
    case "code-davinci-002":
    case "code-davinci-001":
      return 8e3;
    case "code-cushman-001":
      return 2048;
    case "claude-3-5-sonnet-20241022":
    case "claude-3-5-sonnet-20240620":
    case "claude-3-opus-20240229":
    case "claude-3-sonnet-20240229":
    case "claude-3-haiku-20240307":
    case "claude-2.1":
      return 2e5;
    case "claude-2.0":
    case "claude-instant-1.2":
      return 1e5;
    case "gemini-1.5-pro":
    case "gemini-1.5-pro-latest":
    case "gemini-1.5-flash":
    case "gemini-1.5-flash-latest":
      return 1e6;
    case "gemini-pro":
    case "gemini-pro-vision":
      return 32768;
    default:
      return 4097;
  }
};
function isOpenAITool(tool) {
  if (typeof tool !== "object" || !tool) return false;
  if ("type" in tool && tool.type === "function" && "function" in tool && typeof tool.function === "object" && tool.function && "name" in tool.function && "parameters" in tool.function) return true;
  return false;
}
var calculateMaxTokens = async ({ prompt, modelName }) => {
  let numTokens;
  try {
    numTokens = (await encodingForModel(getModelNameForTiktoken(modelName))).encode(prompt).length;
  } catch {
    console.warn("Failed to calculate number of tokens, falling back to approximate count");
    numTokens = Math.ceil(prompt.length / 4);
  }
  const maxTokens = getModelContextSize(modelName);
  return maxTokens - numTokens;
};
var getVerbosity = () => false;
var BaseLangChain = class extends Runnable {
  constructor(params) {
    super(params);
    /**
    * Whether to print out response text.
    */
    __publicField(this, "verbose");
    __publicField(this, "callbacks");
    __publicField(this, "tags");
    __publicField(this, "metadata");
    this.verbose = params.verbose ?? getVerbosity();
    this.callbacks = params.callbacks;
    this.tags = params.tags ?? [];
    this.metadata = params.metadata ?? {};
  }
  get lc_attributes() {
    return {
      callbacks: void 0,
      verbose: void 0
    };
  }
};
var BaseLanguageModel = class extends BaseLangChain {
  constructor({ callbacks, callbackManager, ...params }) {
    const { cache: cache2, ...rest } = params;
    super({
      callbacks: callbacks ?? callbackManager,
      ...rest
    });
    /**
    * The async caller should be used by subclasses to make any async calls,
    * which will thus benefit from the concurrency and retry logic.
    */
    __publicField(this, "caller");
    __publicField(this, "cache");
    __publicField(this, "_encoding");
    if (typeof cache2 === "object") this.cache = cache2;
    else if (cache2) this.cache = InMemoryCache.global();
    else this.cache = void 0;
    this.caller = new AsyncCaller(params ?? {});
  }
  /**
  * Keys that the language model accepts as call options.
  */
  get callKeys() {
    return [
      "stop",
      "timeout",
      "signal",
      "tags",
      "metadata",
      "callbacks"
    ];
  }
  /**
  * Get the number of tokens in the content.
  * @param content The content to get the number of tokens for.
  * @returns The number of tokens in the content.
  */
  async getNumTokens(content) {
    let textContent;
    if (typeof content === "string") textContent = content;
    else
      textContent = content.map((item) => {
        if (typeof item === "string") return item;
        if (item.type === "text" && "text" in item) return item.text;
        return "";
      }).join("");
    let numTokens = Math.ceil(textContent.length / 4);
    if (!this._encoding) try {
      this._encoding = await encodingForModel("modelName" in this ? getModelNameForTiktoken(this.modelName) : "gpt2");
    } catch (error) {
      console.warn("Failed to calculate number of tokens, falling back to approximate count", error);
    }
    if (this._encoding) try {
      numTokens = this._encoding.encode(textContent).length;
    } catch (error) {
      console.warn("Failed to calculate number of tokens, falling back to approximate count", error);
    }
    return numTokens;
  }
  static _convertInputToPromptValue(input) {
    if (typeof input === "string") return new StringPromptValue(input);
    else if (Array.isArray(input)) return new ChatPromptValue(input.map(coerceMessageLikeToMessage));
    else return input;
  }
  /**
  * Get the identifying parameters of the LLM.
  */
  _identifyingParams() {
    return {};
  }
  /**
  * Create a unique cache key for a specific call to a specific language model.
  * @param callOptions Call options for the model
  * @returns A unique cache key.
  */
  _getSerializedCacheKeyParametersForCall({ config, ...callOptions }) {
    const params = {
      ...this._identifyingParams(),
      ...callOptions,
      _type: this._llmType(),
      _model: this._modelType()
    };
    const filteredEntries = Object.entries(params).filter(([_, value]) => value !== void 0);
    const serializedEntries = filteredEntries.map(([key, value]) => `${key}:${JSON.stringify(value)}`).sort().join(",");
    return serializedEntries;
  }
  /**
  * @deprecated
  * Return a json-like object representing this LLM.
  */
  serialize() {
    return {
      ...this._identifyingParams(),
      _type: this._llmType(),
      _model: this._modelType()
    };
  }
  /**
  * @deprecated
  * Load an LLM from a json-like object describing it.
  */
  static async deserialize(_data) {
    throw new Error("Use .toJSON() instead");
  }
  /**
  * Return profiling information for the model.
  *
  * @returns {ModelProfile} An object describing the model's capabilities and constraints
  */
  get profile() {
    return {};
  }
};

// node_modules/@langchain/core/dist/runnables/passthrough.js
var RunnablePassthrough = class extends Runnable {
  constructor(fields) {
    super(fields);
    __publicField(this, "lc_namespace", ["langchain_core", "runnables"]);
    __publicField(this, "lc_serializable", true);
    __publicField(this, "func");
    if (fields) this.func = fields.func;
  }
  static lc_name() {
    return "RunnablePassthrough";
  }
  async invoke(input, options) {
    const config = ensureConfig(options);
    if (this.func) await this.func(input, config);
    return this._callWithConfig((input$1) => Promise.resolve(input$1), input, config);
  }
  async *transform(generator, options) {
    const config = ensureConfig(options);
    let finalOutput;
    let finalOutputSupported = true;
    for await (const chunk of this._transformStreamWithConfig(generator, (input) => input, config)) {
      yield chunk;
      if (finalOutputSupported) if (finalOutput === void 0) finalOutput = chunk;
      else try {
        finalOutput = concat(finalOutput, chunk);
      } catch {
        finalOutput = void 0;
        finalOutputSupported = false;
      }
    }
    if (this.func && finalOutput !== void 0) await this.func(finalOutput, config);
  }
  /**
  * A runnable that assigns key-value pairs to the input.
  *
  * The example below shows how you could use it with an inline function.
  *
  * @example
  * ```typescript
  * const prompt =
  *   PromptTemplate.fromTemplate(`Write a SQL query to answer the question using the following schema: {schema}
  * Question: {question}
  * SQL Query:`);
  *
  * // The `RunnablePassthrough.assign()` is used here to passthrough the input from the `.invoke()`
  * // call (in this example it's the question), along with any inputs passed to the `.assign()` method.
  * // In this case, we're passing the schema.
  * const sqlQueryGeneratorChain = RunnableSequence.from([
  *   RunnablePassthrough.assign({
  *     schema: async () => db.getTableInfo(),
  *   }),
  *   prompt,
  *   new ChatOpenAI({ model: "gpt-4o-mini" }).withConfig({ stop: ["\nSQLResult:"] }),
  *   new StringOutputParser(),
  * ]);
  * const result = await sqlQueryGeneratorChain.invoke({
  *   question: "How many employees are there?",
  * });
  * ```
  */
  static assign(mapping) {
    return new RunnableAssign(new RunnableMap({ steps: mapping }));
  }
};

// node_modules/@langchain/core/dist/language_models/utils.js
var iife = (fn) => fn();
function castStandardMessageContent(message) {
  const Cls = message.constructor;
  return new Cls({
    ...message,
    content: message.contentBlocks,
    response_metadata: {
      ...message.response_metadata,
      output_version: "v1"
    }
  });
}

// node_modules/@langchain/core/dist/language_models/chat_models.js
var chat_models_exports = {};
__export(chat_models_exports, {
  BaseChatModel: () => BaseChatModel,
  SimpleChatModel: () => SimpleChatModel
});
function _formatForTracing(messages) {
  const messagesToTrace = [];
  for (const message of messages) {
    let messageToTrace = message;
    if (Array.isArray(message.content)) for (let idx = 0; idx < message.content.length; idx++) {
      const block = message.content[idx];
      if (isURLContentBlock(block) || isBase64ContentBlock(block)) {
        if (messageToTrace === message) messageToTrace = new message.constructor({
          ...messageToTrace,
          content: [
            ...message.content.slice(0, idx),
            convertToOpenAIImageBlock(block),
            ...message.content.slice(idx + 1)
          ]
        });
      }
    }
    messagesToTrace.push(messageToTrace);
  }
  return messagesToTrace;
}
var BaseChatModel = class BaseChatModel2 extends BaseLanguageModel {
  constructor(fields) {
    super(fields);
    __publicField(this, "lc_namespace", [
      "langchain",
      "chat_models",
      this._llmType()
    ]);
    __publicField(this, "disableStreaming", false);
    __publicField(this, "outputVersion");
    this.outputVersion = iife(() => {
      const outputVersion = fields.outputVersion ?? getEnvironmentVariable("LC_OUTPUT_VERSION");
      if (outputVersion && ["v0", "v1"].includes(outputVersion)) return outputVersion;
      return "v0";
    });
  }
  get callKeys() {
    return [...super.callKeys, "outputVersion"];
  }
  _separateRunnableConfigFromCallOptionsCompat(options) {
    const [runnableConfig, callOptions] = super._separateRunnableConfigFromCallOptions(options);
    callOptions.signal = runnableConfig.signal;
    return [runnableConfig, callOptions];
  }
  /**
  * Invokes the chat model with a single input.
  * @param input The input for the language model.
  * @param options The call options.
  * @returns A Promise that resolves to a BaseMessageChunk.
  */
  async invoke(input, options) {
    const promptValue = BaseChatModel2._convertInputToPromptValue(input);
    const result = await this.generatePrompt([promptValue], options, options == null ? void 0 : options.callbacks);
    const chatGeneration = result.generations[0][0];
    return chatGeneration.message;
  }
  async *_streamResponseChunks(_messages, _options, _runManager) {
    throw new Error("Not implemented.");
  }
  async *_streamIterator(input, options) {
    var _a2;
    if (this._streamResponseChunks === BaseChatModel2.prototype._streamResponseChunks || this.disableStreaming) yield this.invoke(input, options);
    else {
      const prompt = BaseChatModel2._convertInputToPromptValue(input);
      const messages = prompt.toChatMessages();
      const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(options);
      const inheritableMetadata = {
        ...runnableConfig.metadata,
        ...this.getLsParams(callOptions)
      };
      const callbackManager_ = await CallbackManager.configure(runnableConfig.callbacks, this.callbacks, runnableConfig.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });
      const extra = {
        options: callOptions,
        invocation_params: this == null ? void 0 : this.invocationParams(callOptions),
        batch_size: 1
      };
      const outputVersion = callOptions.outputVersion ?? this.outputVersion;
      const runManagers = await (callbackManager_ == null ? void 0 : callbackManager_.handleChatModelStart(this.toJSON(), [_formatForTracing(messages)], runnableConfig.runId, void 0, extra, void 0, void 0, runnableConfig.runName));
      let generationChunk;
      let llmOutput;
      try {
        for await (const chunk of this._streamResponseChunks(messages, callOptions, runManagers == null ? void 0 : runManagers[0])) {
          if (chunk.message.id == null) {
            const runId = (_a2 = runManagers == null ? void 0 : runManagers.at(0)) == null ? void 0 : _a2.runId;
            if (runId != null) chunk.message._updateId(`run-${runId}`);
          }
          chunk.message.response_metadata = {
            ...chunk.generationInfo,
            ...chunk.message.response_metadata
          };
          if (outputVersion === "v1") yield castStandardMessageContent(chunk.message);
          else yield chunk.message;
          if (!generationChunk) generationChunk = chunk;
          else generationChunk = generationChunk.concat(chunk);
          if (isAIMessageChunk(chunk.message) && chunk.message.usage_metadata !== void 0) llmOutput = { tokenUsage: {
            promptTokens: chunk.message.usage_metadata.input_tokens,
            completionTokens: chunk.message.usage_metadata.output_tokens,
            totalTokens: chunk.message.usage_metadata.total_tokens
          } };
        }
      } catch (err) {
        await Promise.all((runManagers ?? []).map((runManager) => runManager == null ? void 0 : runManager.handleLLMError(err)));
        throw err;
      }
      await Promise.all((runManagers ?? []).map((runManager) => runManager == null ? void 0 : runManager.handleLLMEnd({
        generations: [[generationChunk]],
        llmOutput
      })));
    }
  }
  getLsParams(options) {
    const providerName = this.getName().startsWith("Chat") ? this.getName().replace("Chat", "") : this.getName();
    return {
      ls_model_type: "chat",
      ls_stop: options.stop,
      ls_provider: providerName
    };
  }
  /** @ignore */
  async _generateUncached(messages, parsedOptions, handledOptions, startedRunManagers) {
    var _a2, _b;
    const baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));
    let runManagers;
    if (startedRunManagers !== void 0 && startedRunManagers.length === baseMessages.length) runManagers = startedRunManagers;
    else {
      const inheritableMetadata = {
        ...handledOptions.metadata,
        ...this.getLsParams(parsedOptions)
      };
      const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });
      const extra = {
        options: parsedOptions,
        invocation_params: this == null ? void 0 : this.invocationParams(parsedOptions),
        batch_size: 1
      };
      runManagers = await (callbackManager_ == null ? void 0 : callbackManager_.handleChatModelStart(this.toJSON(), baseMessages.map(_formatForTracing), handledOptions.runId, void 0, extra, void 0, void 0, handledOptions.runName));
    }
    const outputVersion = parsedOptions.outputVersion ?? this.outputVersion;
    const generations = [];
    const llmOutputs = [];
    const hasStreamingHandler = !!(runManagers == null ? void 0 : runManagers[0].handlers.find(callbackHandlerPrefersStreaming));
    if (hasStreamingHandler && !this.disableStreaming && baseMessages.length === 1 && this._streamResponseChunks !== BaseChatModel2.prototype._streamResponseChunks) try {
      const stream = await this._streamResponseChunks(baseMessages[0], parsedOptions, runManagers == null ? void 0 : runManagers[0]);
      let aggregated;
      let llmOutput;
      for await (const chunk of stream) {
        if (chunk.message.id == null) {
          const runId = (_a2 = runManagers == null ? void 0 : runManagers.at(0)) == null ? void 0 : _a2.runId;
          if (runId != null) chunk.message._updateId(`run-${runId}`);
        }
        if (aggregated === void 0) aggregated = chunk;
        else aggregated = concat(aggregated, chunk);
        if (isAIMessageChunk(chunk.message) && chunk.message.usage_metadata !== void 0) llmOutput = { tokenUsage: {
          promptTokens: chunk.message.usage_metadata.input_tokens,
          completionTokens: chunk.message.usage_metadata.output_tokens,
          totalTokens: chunk.message.usage_metadata.total_tokens
        } };
      }
      if (aggregated === void 0) throw new Error("Received empty response from chat model call.");
      generations.push([aggregated]);
      await (runManagers == null ? void 0 : runManagers[0].handleLLMEnd({
        generations,
        llmOutput
      }));
    } catch (e) {
      await (runManagers == null ? void 0 : runManagers[0].handleLLMError(e));
      throw e;
    }
    else {
      const results = await Promise.allSettled(baseMessages.map(async (messageList, i) => {
        const generateResults = await this._generate(messageList, {
          ...parsedOptions,
          promptIndex: i
        }, runManagers == null ? void 0 : runManagers[i]);
        if (outputVersion === "v1") for (const generation of generateResults.generations) generation.message = castStandardMessageContent(generation.message);
        return generateResults;
      }));
      await Promise.all(results.map(async (pResult, i) => {
        var _a3, _b2, _c;
        if (pResult.status === "fulfilled") {
          const result = pResult.value;
          for (const generation of result.generations) {
            if (generation.message.id == null) {
              const runId = (_a3 = runManagers == null ? void 0 : runManagers.at(0)) == null ? void 0 : _a3.runId;
              if (runId != null) generation.message._updateId(`run-${runId}`);
            }
            generation.message.response_metadata = {
              ...generation.generationInfo,
              ...generation.message.response_metadata
            };
          }
          if (result.generations.length === 1) result.generations[0].message.response_metadata = {
            ...result.llmOutput,
            ...result.generations[0].message.response_metadata
          };
          generations[i] = result.generations;
          llmOutputs[i] = result.llmOutput;
          return (_b2 = runManagers == null ? void 0 : runManagers[i]) == null ? void 0 : _b2.handleLLMEnd({
            generations: [result.generations],
            llmOutput: result.llmOutput
          });
        } else {
          await ((_c = runManagers == null ? void 0 : runManagers[i]) == null ? void 0 : _c.handleLLMError(pResult.reason));
          return Promise.reject(pResult.reason);
        }
      }));
    }
    const output = {
      generations,
      llmOutput: llmOutputs.length ? (_b = this._combineLLMOutput) == null ? void 0 : _b.call(this, ...llmOutputs) : void 0
    };
    Object.defineProperty(output, RUN_KEY, {
      value: runManagers ? { runIds: runManagers == null ? void 0 : runManagers.map((manager) => manager.runId) } : void 0,
      configurable: true
    });
    return output;
  }
  async _generateCached({ messages, cache: cache2, llmStringKey, parsedOptions, handledOptions }) {
    const baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));
    const inheritableMetadata = {
      ...handledOptions.metadata,
      ...this.getLsParams(parsedOptions)
    };
    const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });
    const extra = {
      options: parsedOptions,
      invocation_params: this == null ? void 0 : this.invocationParams(parsedOptions),
      batch_size: 1
    };
    const runManagers = await (callbackManager_ == null ? void 0 : callbackManager_.handleChatModelStart(this.toJSON(), baseMessages.map(_formatForTracing), handledOptions.runId, void 0, extra, void 0, void 0, handledOptions.runName));
    const missingPromptIndices = [];
    const results = await Promise.allSettled(baseMessages.map(async (baseMessage, index) => {
      const prompt = BaseChatModel2._convertInputToPromptValue(baseMessage).toString();
      const result = await cache2.lookup(prompt, llmStringKey);
      if (result == null) missingPromptIndices.push(index);
      return result;
    }));
    const cachedResults = results.map((result, index) => ({
      result,
      runManager: runManagers == null ? void 0 : runManagers[index]
    })).filter(({ result }) => result.status === "fulfilled" && result.value != null || result.status === "rejected");
    const outputVersion = parsedOptions.outputVersion ?? this.outputVersion;
    const generations = [];
    await Promise.all(cachedResults.map(async ({ result: promiseResult, runManager }, i) => {
      if (promiseResult.status === "fulfilled") {
        const result = promiseResult.value;
        generations[i] = result.map((result$1) => {
          if ("message" in result$1 && isBaseMessage(result$1.message) && isAIMessage(result$1.message)) {
            result$1.message.usage_metadata = {
              input_tokens: 0,
              output_tokens: 0,
              total_tokens: 0
            };
            if (outputVersion === "v1") result$1.message = castStandardMessageContent(result$1.message);
          }
          result$1.generationInfo = {
            ...result$1.generationInfo,
            tokenUsage: {}
          };
          return result$1;
        });
        if (result.length) await (runManager == null ? void 0 : runManager.handleLLMNewToken(result[0].text));
        return runManager == null ? void 0 : runManager.handleLLMEnd({ generations: [result] }, void 0, void 0, void 0, { cached: true });
      } else {
        await (runManager == null ? void 0 : runManager.handleLLMError(promiseResult.reason, void 0, void 0, void 0, { cached: true }));
        return Promise.reject(promiseResult.reason);
      }
    }));
    const output = {
      generations,
      missingPromptIndices,
      startedRunManagers: runManagers
    };
    Object.defineProperty(output, RUN_KEY, {
      value: runManagers ? { runIds: runManagers == null ? void 0 : runManagers.map((manager) => manager.runId) } : void 0,
      configurable: true
    });
    return output;
  }
  /**
  * Generates chat based on the input messages.
  * @param messages An array of arrays of BaseMessage instances.
  * @param options The call options or an array of stop sequences.
  * @param callbacks The callbacks for the language model.
  * @returns A Promise that resolves to an LLMResult.
  */
  async generate(messages, options, callbacks) {
    let parsedOptions;
    if (Array.isArray(options)) parsedOptions = { stop: options };
    else parsedOptions = options;
    const baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));
    const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(parsedOptions);
    runnableConfig.callbacks = runnableConfig.callbacks ?? callbacks;
    if (!this.cache) return this._generateUncached(baseMessages, callOptions, runnableConfig);
    const { cache: cache2 } = this;
    const llmStringKey = this._getSerializedCacheKeyParametersForCall(callOptions);
    const { generations, missingPromptIndices, startedRunManagers } = await this._generateCached({
      messages: baseMessages,
      cache: cache2,
      llmStringKey,
      parsedOptions: callOptions,
      handledOptions: runnableConfig
    });
    let llmOutput = {};
    if (missingPromptIndices.length > 0) {
      const results = await this._generateUncached(missingPromptIndices.map((i) => baseMessages[i]), callOptions, runnableConfig, startedRunManagers !== void 0 ? missingPromptIndices.map((i) => startedRunManagers == null ? void 0 : startedRunManagers[i]) : void 0);
      await Promise.all(results.generations.map(async (generation, index) => {
        const promptIndex = missingPromptIndices[index];
        generations[promptIndex] = generation;
        const prompt = BaseChatModel2._convertInputToPromptValue(baseMessages[promptIndex]).toString();
        return cache2.update(prompt, llmStringKey, generation);
      }));
      llmOutput = results.llmOutput ?? {};
    }
    return {
      generations,
      llmOutput
    };
  }
  /**
  * Get the parameters used to invoke the model
  */
  invocationParams(_options) {
    return {};
  }
  _modelType() {
    return "base_chat_model";
  }
  /**
  * Generates a prompt based on the input prompt values.
  * @param promptValues An array of BasePromptValue instances.
  * @param options The call options or an array of stop sequences.
  * @param callbacks The callbacks for the language model.
  * @returns A Promise that resolves to an LLMResult.
  */
  async generatePrompt(promptValues, options, callbacks) {
    const promptMessages = promptValues.map((promptValue) => promptValue.toChatMessages());
    return this.generate(promptMessages, options, callbacks);
  }
  withStructuredOutput(outputSchema, config) {
    if (typeof this.bindTools !== "function") throw new Error(`Chat model must implement ".bindTools()" to use withStructuredOutput.`);
    if (config == null ? void 0 : config.strict) throw new Error(`"strict" mode is not supported for this model by default.`);
    const schema = outputSchema;
    const name = config == null ? void 0 : config.name;
    const description = getSchemaDescription(schema) ?? "A function available to call.";
    const method = config == null ? void 0 : config.method;
    const includeRaw = config == null ? void 0 : config.includeRaw;
    if (method === "jsonMode") throw new Error(`Base withStructuredOutput implementation only supports "functionCalling" as a method.`);
    let functionName = name ?? "extract";
    let tools;
    if (isInteropZodSchema(schema)) tools = [{
      type: "function",
      function: {
        name: functionName,
        description,
        parameters: toJsonSchema(schema)
      }
    }];
    else {
      if ("name" in schema) functionName = schema.name;
      tools = [{
        type: "function",
        function: {
          name: functionName,
          description,
          parameters: schema
        }
      }];
    }
    const llm = this.bindTools(tools);
    const outputParser = RunnableLambda.from((input) => {
      if (!AIMessageChunk.isInstance(input)) throw new Error("Input is not an AIMessageChunk.");
      if (!input.tool_calls || input.tool_calls.length === 0) throw new Error("No tool calls found in the response.");
      const toolCall = input.tool_calls.find((tc) => tc.name === functionName);
      if (!toolCall) throw new Error(`No tool call found with name ${functionName}.`);
      return toolCall.args;
    });
    if (!includeRaw) return llm.pipe(outputParser).withConfig({ runName: "StructuredOutput" });
    const parserAssign = RunnablePassthrough.assign({ parsed: (input, config$1) => outputParser.invoke(input.raw, config$1) });
    const parserNone = RunnablePassthrough.assign({ parsed: () => null });
    const parsedWithFallback = parserAssign.withFallbacks({ fallbacks: [parserNone] });
    return RunnableSequence.from([{ raw: llm }, parsedWithFallback]).withConfig({ runName: "StructuredOutputRunnable" });
  }
};
var SimpleChatModel = class extends BaseChatModel {
  async _generate(messages, options, runManager) {
    const text = await this._call(messages, options, runManager);
    const message = new AIMessage(text);
    if (typeof message.content !== "string") throw new Error("Cannot generate with a simple chat model when output is not a string.");
    return { generations: [{
      text: message.content,
      message
    }] };
  }
};

// node_modules/@langchain/core/dist/utils/types/index.js
var types_exports = {};
__export(types_exports, {
  extendInteropZodObject: () => extendInteropZodObject,
  getInteropZodDefaultGetter: () => getInteropZodDefaultGetter,
  getInteropZodObjectShape: () => getInteropZodObjectShape,
  getSchemaDescription: () => getSchemaDescription,
  interopParse: () => interopParse,
  interopParseAsync: () => interopParseAsync,
  interopSafeParse: () => interopSafeParse,
  interopSafeParseAsync: () => interopSafeParseAsync,
  interopZodObjectMakeFieldsOptional: () => interopZodObjectMakeFieldsOptional,
  interopZodObjectPartial: () => interopZodObjectPartial,
  interopZodObjectPassthrough: () => interopZodObjectPassthrough,
  interopZodObjectStrict: () => interopZodObjectStrict,
  interopZodTransformInputSchema: () => interopZodTransformInputSchema,
  isInteropZodError: () => isInteropZodError,
  isInteropZodLiteral: () => isInteropZodLiteral,
  isInteropZodObject: () => isInteropZodObject,
  isInteropZodSchema: () => isInteropZodSchema,
  isShapelessZodSchema: () => isShapelessZodSchema,
  isSimpleStringZodSchema: () => isSimpleStringZodSchema,
  isZodArrayV4: () => isZodArrayV4,
  isZodLiteralV3: () => isZodLiteralV3,
  isZodLiteralV4: () => isZodLiteralV4,
  isZodNullableV4: () => isZodNullableV4,
  isZodObjectV3: () => isZodObjectV3,
  isZodObjectV4: () => isZodObjectV4,
  isZodOptionalV4: () => isZodOptionalV4,
  isZodSchema: () => isZodSchema,
  isZodSchemaV3: () => isZodSchemaV3,
  isZodSchemaV4: () => isZodSchemaV4
});

// node_modules/groq-sdk/version.mjs
var VERSION = "0.19.0";

// node_modules/groq-sdk/_shims/registry.mjs
var auto = false;
var kind = void 0;
var fetch2 = void 0;
var Request2 = void 0;
var Response2 = void 0;
var Headers2 = void 0;
var FormData2 = void 0;
var Blob2 = void 0;
var File2 = void 0;
var ReadableStream2 = void 0;
var getMultipartRequestOptions = void 0;
var getDefaultAgent = void 0;
var fileFromPath = void 0;
var isFsReadStream = void 0;
function setShims(shims, options = { auto: false }) {
  if (auto) {
    throw new Error(`you must \`import 'groq-sdk/shims/${shims.kind}'\` before importing anything else from groq-sdk`);
  }
  if (kind) {
    throw new Error(`can't \`import 'groq-sdk/shims/${shims.kind}'\` after \`import 'groq-sdk/shims/${kind}'\``);
  }
  auto = options.auto;
  kind = shims.kind;
  fetch2 = shims.fetch;
  Request2 = shims.Request;
  Response2 = shims.Response;
  Headers2 = shims.Headers;
  FormData2 = shims.FormData;
  Blob2 = shims.Blob;
  File2 = shims.File;
  ReadableStream2 = shims.ReadableStream;
  getMultipartRequestOptions = shims.getMultipartRequestOptions;
  getDefaultAgent = shims.getDefaultAgent;
  fileFromPath = shims.fileFromPath;
  isFsReadStream = shims.isFsReadStream;
}

// node_modules/groq-sdk/_shims/MultipartBody.mjs
var MultipartBody = class {
  constructor(body) {
    this.body = body;
  }
  get [Symbol.toStringTag]() {
    return "MultipartBody";
  }
};

// node_modules/groq-sdk/_shims/web-runtime.mjs
function getRuntime({ manuallyImported } = {}) {
  const recommendation = manuallyImported ? `You may need to use polyfills` : `Add one of these imports before your first \`import  from 'groq-sdk'\`:
- \`import 'groq-sdk/shims/node'\` (if you're running on Node)
- \`import 'groq-sdk/shims/web'\` (otherwise)
`;
  let _fetch, _Request, _Response, _Headers;
  try {
    _fetch = fetch;
    _Request = Request;
    _Response = Response;
    _Headers = Headers;
  } catch (error) {
    throw new Error(`this environment is missing the following Web Fetch API type: ${error.message}. ${recommendation}`);
  }
  return {
    kind: "web",
    fetch: _fetch,
    Request: _Request,
    Response: _Response,
    Headers: _Headers,
    FormData: (
      // @ts-ignore
      typeof FormData !== "undefined" ? FormData : class FormData {
        // @ts-ignore
        constructor() {
          throw new Error(`file uploads aren't supported in this environment yet as 'FormData' is undefined. ${recommendation}`);
        }
      }
    ),
    Blob: typeof Blob !== "undefined" ? Blob : class Blob {
      constructor() {
        throw new Error(`file uploads aren't supported in this environment yet as 'Blob' is undefined. ${recommendation}`);
      }
    },
    File: (
      // @ts-ignore
      typeof File !== "undefined" ? File : class File {
        // @ts-ignore
        constructor() {
          throw new Error(`file uploads aren't supported in this environment yet as 'File' is undefined. ${recommendation}`);
        }
      }
    ),
    ReadableStream: (
      // @ts-ignore
      typeof ReadableStream !== "undefined" ? ReadableStream : class ReadableStream {
        // @ts-ignore
        constructor() {
          throw new Error(`streaming isn't supported in this environment yet as 'ReadableStream' is undefined. ${recommendation}`);
        }
      }
    ),
    getMultipartRequestOptions: async (form, opts) => ({
      ...opts,
      body: new MultipartBody(form)
    }),
    getDefaultAgent: (url) => void 0,
    fileFromPath: () => {
      throw new Error("The `fileFromPath` function is only supported in Node. See the README for more details: https://www.github.com/groq/groq-typescript#file-uploads");
    },
    isFsReadStream: (value) => false
  };
}

// node_modules/groq-sdk/_shims/index.mjs
var init = () => {
  if (!kind) setShims(getRuntime(), { auto: true });
};
init();

// node_modules/groq-sdk/error.mjs
var GroqError = class extends Error {
};
var APIError = class _APIError extends GroqError {
  constructor(status, error, message, headers) {
    super(`${_APIError.makeMessage(status, error, message)}`);
    this.status = status;
    this.headers = headers;
    this.error = error;
  }
  static makeMessage(status, error, message) {
    const msg = (error == null ? void 0 : error.message) ? typeof error.message === "string" ? error.message : JSON.stringify(error.message) : error ? JSON.stringify(error) : message;
    if (status && msg) {
      return `${status} ${msg}`;
    }
    if (status) {
      return `${status} status code (no body)`;
    }
    if (msg) {
      return msg;
    }
    return "(no status code or body)";
  }
  static generate(status, errorResponse, message, headers) {
    if (!status || !headers) {
      return new APIConnectionError({ message, cause: castToError(errorResponse) });
    }
    const error = errorResponse;
    if (status === 400) {
      return new BadRequestError(status, error, message, headers);
    }
    if (status === 401) {
      return new AuthenticationError(status, error, message, headers);
    }
    if (status === 403) {
      return new PermissionDeniedError(status, error, message, headers);
    }
    if (status === 404) {
      return new NotFoundError(status, error, message, headers);
    }
    if (status === 409) {
      return new ConflictError(status, error, message, headers);
    }
    if (status === 422) {
      return new UnprocessableEntityError(status, error, message, headers);
    }
    if (status === 429) {
      return new RateLimitError(status, error, message, headers);
    }
    if (status >= 500) {
      return new InternalServerError(status, error, message, headers);
    }
    return new _APIError(status, error, message, headers);
  }
};
var APIUserAbortError = class extends APIError {
  constructor({ message } = {}) {
    super(void 0, void 0, message || "Request was aborted.", void 0);
  }
};
var APIConnectionError = class extends APIError {
  constructor({ message, cause }) {
    super(void 0, void 0, message || "Connection error.", void 0);
    if (cause)
      this.cause = cause;
  }
};
var APIConnectionTimeoutError = class extends APIConnectionError {
  constructor({ message } = {}) {
    super({ message: message ?? "Request timed out." });
  }
};
var BadRequestError = class extends APIError {
};
var AuthenticationError = class extends APIError {
};
var PermissionDeniedError = class extends APIError {
};
var NotFoundError = class extends APIError {
};
var ConflictError = class extends APIError {
};
var UnprocessableEntityError = class extends APIError {
};
var RateLimitError = class extends APIError {
};
var InternalServerError = class extends APIError {
};

// node_modules/groq-sdk/lib/streaming.mjs
var Stream = class _Stream {
  constructor(iterator, controller) {
    this.iterator = iterator;
    this.controller = controller;
  }
  static fromSSEResponse(response, controller) {
    let consumed = false;
    const decoder = new SSEDecoder();
    async function* iterMessages() {
      if (!response.body) {
        controller.abort();
        throw new GroqError(`Attempted to iterate over a response with no body`);
      }
      const lineDecoder = new LineDecoder();
      const iter = readableStreamAsyncIterable(response.body);
      for await (const chunk of iter) {
        for (const line of lineDecoder.decode(chunk)) {
          const sse = decoder.decode(line);
          if (sse)
            yield sse;
        }
      }
      for (const line of lineDecoder.flush()) {
        const sse = decoder.decode(line);
        if (sse)
          yield sse;
      }
    }
    async function* iterator() {
      if (consumed) {
        throw new Error("Cannot iterate over a consumed stream, use `.tee()` to split the stream.");
      }
      consumed = true;
      let done = false;
      try {
        for await (const sse of iterMessages()) {
          if (done)
            continue;
          if (sse.data.startsWith("[DONE]")) {
            done = true;
            continue;
          }
          if (sse.event === null || sse.event === "error") {
            let data;
            try {
              data = JSON.parse(sse.data);
            } catch (e) {
              console.error(`Could not parse message into JSON:`, sse.data);
              console.error(`From chunk:`, sse.raw);
              throw e;
            }
            if (data && data.error) {
              throw new APIError(data.error.status_code, data.error, data.error.message, void 0);
            }
            yield data;
          }
        }
        done = true;
      } catch (e) {
        if (e instanceof Error && e.name === "AbortError")
          return;
        throw e;
      } finally {
        if (!done)
          controller.abort();
      }
    }
    return new _Stream(iterator, controller);
  }
  /**
   * Generates a Stream from a newline-separated ReadableStream
   * where each item is a JSON value.
   */
  static fromReadableStream(readableStream, controller) {
    let consumed = false;
    async function* iterLines() {
      const lineDecoder = new LineDecoder();
      const iter = readableStreamAsyncIterable(readableStream);
      for await (const chunk of iter) {
        for (const line of lineDecoder.decode(chunk)) {
          yield line;
        }
      }
      for (const line of lineDecoder.flush()) {
        yield line;
      }
    }
    async function* iterator() {
      if (consumed) {
        throw new Error("Cannot iterate over a consumed stream, use `.tee()` to split the stream.");
      }
      consumed = true;
      let done = false;
      try {
        for await (const line of iterLines()) {
          if (done)
            continue;
          if (line)
            yield JSON.parse(line);
        }
        done = true;
      } catch (e) {
        if (e instanceof Error && e.name === "AbortError")
          return;
        throw e;
      } finally {
        if (!done)
          controller.abort();
      }
    }
    return new _Stream(iterator, controller);
  }
  [Symbol.asyncIterator]() {
    return this.iterator();
  }
  /**
   * Splits the stream into two streams which can be
   * independently read from at different speeds.
   */
  tee() {
    const left = [];
    const right = [];
    const iterator = this.iterator();
    const teeIterator = (queue) => {
      return {
        next: () => {
          if (queue.length === 0) {
            const result = iterator.next();
            left.push(result);
            right.push(result);
          }
          return queue.shift();
        }
      };
    };
    return [
      new _Stream(() => teeIterator(left), this.controller),
      new _Stream(() => teeIterator(right), this.controller)
    ];
  }
  /**
   * Converts this stream to a newline-separated ReadableStream of
   * JSON stringified values in the stream
   * which can be turned back into a Stream with `Stream.fromReadableStream()`.
   */
  toReadableStream() {
    const self = this;
    let iter;
    const encoder = new TextEncoder();
    return new ReadableStream2({
      async start() {
        iter = self[Symbol.asyncIterator]();
      },
      async pull(ctrl) {
        try {
          const { value, done } = await iter.next();
          if (done)
            return ctrl.close();
          const bytes = encoder.encode(JSON.stringify(value) + "\n");
          ctrl.enqueue(bytes);
        } catch (err) {
          ctrl.error(err);
        }
      },
      async cancel() {
        var _a2;
        await ((_a2 = iter.return) == null ? void 0 : _a2.call(iter));
      }
    });
  }
};
var SSEDecoder = class {
  constructor() {
    this.event = null;
    this.data = [];
    this.chunks = [];
  }
  decode(line) {
    if (line.endsWith("\r")) {
      line = line.substring(0, line.length - 1);
    }
    if (!line) {
      if (!this.event && !this.data.length)
        return null;
      const sse = {
        event: this.event,
        data: this.data.join("\n"),
        raw: this.chunks
      };
      this.event = null;
      this.data = [];
      this.chunks = [];
      return sse;
    }
    this.chunks.push(line);
    if (line.startsWith(":")) {
      return null;
    }
    let [fieldname, _, value] = partition(line, ":");
    if (value.startsWith(" ")) {
      value = value.substring(1);
    }
    if (fieldname === "event") {
      this.event = value;
    } else if (fieldname === "data") {
      this.data.push(value);
    }
    return null;
  }
};
var LineDecoder = class _LineDecoder {
  constructor() {
    this.buffer = [];
    this.trailingCR = false;
  }
  decode(chunk) {
    let text = this.decodeText(chunk);
    if (this.trailingCR) {
      text = "\r" + text;
      this.trailingCR = false;
    }
    if (text.endsWith("\r")) {
      this.trailingCR = true;
      text = text.slice(0, -1);
    }
    if (!text) {
      return [];
    }
    const trailingNewline = _LineDecoder.NEWLINE_CHARS.has(text[text.length - 1] || "");
    let lines = text.split(_LineDecoder.NEWLINE_REGEXP);
    if (lines.length === 1 && !trailingNewline) {
      this.buffer.push(lines[0]);
      return [];
    }
    if (this.buffer.length > 0) {
      lines = [this.buffer.join("") + lines[0], ...lines.slice(1)];
      this.buffer = [];
    }
    if (!trailingNewline) {
      this.buffer = [lines.pop() || ""];
    }
    return lines;
  }
  decodeText(bytes) {
    if (bytes == null)
      return "";
    if (typeof bytes === "string")
      return bytes;
    if (typeof Buffer !== "undefined") {
      if (bytes instanceof Buffer) {
        return bytes.toString();
      }
      if (bytes instanceof Uint8Array) {
        return Buffer.from(bytes).toString();
      }
      throw new GroqError(`Unexpected: received non-Uint8Array (${bytes.constructor.name}) stream chunk in an environment with a global "Buffer" defined, which this library assumes to be Node. Please report this error.`);
    }
    if (typeof TextDecoder !== "undefined") {
      if (bytes instanceof Uint8Array || bytes instanceof ArrayBuffer) {
        this.textDecoder ?? (this.textDecoder = new TextDecoder("utf8"));
        return this.textDecoder.decode(bytes);
      }
      throw new GroqError(`Unexpected: received non-Uint8Array/ArrayBuffer (${bytes.constructor.name}) in a web platform. Please report this error.`);
    }
    throw new GroqError(`Unexpected: neither Buffer nor TextDecoder are available as globals. Please report this error.`);
  }
  flush() {
    if (!this.buffer.length && !this.trailingCR) {
      return [];
    }
    const lines = [this.buffer.join("")];
    this.buffer = [];
    this.trailingCR = false;
    return lines;
  }
};
LineDecoder.NEWLINE_CHARS = /* @__PURE__ */ new Set(["\n", "\r", "\v", "\f", "", "", "", "", "\u2028", "\u2029"]);
LineDecoder.NEWLINE_REGEXP = /\r\n|[\n\r\x0b\x0c\x1c\x1d\x1e\x85\u2028\u2029]/g;
function partition(str, delimiter) {
  const index = str.indexOf(delimiter);
  if (index !== -1) {
    return [str.substring(0, index), delimiter, str.substring(index + delimiter.length)];
  }
  return [str, "", ""];
}
function readableStreamAsyncIterable(stream) {
  if (stream[Symbol.asyncIterator])
    return stream;
  const reader = stream.getReader();
  return {
    async next() {
      try {
        const result = await reader.read();
        if (result == null ? void 0 : result.done)
          reader.releaseLock();
        return result;
      } catch (e) {
        reader.releaseLock();
        throw e;
      }
    },
    async return() {
      const cancelPromise = reader.cancel();
      reader.releaseLock();
      await cancelPromise;
      return { done: true, value: void 0 };
    },
    [Symbol.asyncIterator]() {
      return this;
    }
  };
}

// node_modules/groq-sdk/uploads.mjs
var isResponseLike = (value) => value != null && typeof value === "object" && typeof value.url === "string" && typeof value.blob === "function";
var isFileLike = (value) => value != null && typeof value === "object" && typeof value.name === "string" && typeof value.lastModified === "number" && isBlobLike(value);
var isBlobLike = (value) => value != null && typeof value === "object" && typeof value.size === "number" && typeof value.type === "string" && typeof value.text === "function" && typeof value.slice === "function" && typeof value.arrayBuffer === "function";
var isUploadable = (value) => {
  return isFileLike(value) || isResponseLike(value) || isFsReadStream(value);
};
async function toFile(value, name, options) {
  var _a2;
  value = await value;
  if (isFileLike(value)) {
    return value;
  }
  if (isResponseLike(value)) {
    const blob = await value.blob();
    name || (name = new URL(value.url).pathname.split(/[\\/]/).pop() ?? "unknown_file");
    const data = isBlobLike(blob) ? [await blob.arrayBuffer()] : [blob];
    return new File2(data, name, options);
  }
  const bits = await getBytes(value);
  name || (name = getName(value) ?? "unknown_file");
  if (!(options == null ? void 0 : options.type)) {
    const type = (_a2 = bits[0]) == null ? void 0 : _a2.type;
    if (typeof type === "string") {
      options = { ...options, type };
    }
  }
  return new File2(bits, name, options);
}
async function getBytes(value) {
  var _a2;
  let parts = [];
  if (typeof value === "string" || ArrayBuffer.isView(value) || // includes Uint8Array, Buffer, etc.
  value instanceof ArrayBuffer) {
    parts.push(value);
  } else if (isBlobLike(value)) {
    parts.push(await value.arrayBuffer());
  } else if (isAsyncIterableIterator(value)) {
    for await (const chunk of value) {
      parts.push(chunk);
    }
  } else {
    throw new Error(`Unexpected data type: ${typeof value}; constructor: ${(_a2 = value == null ? void 0 : value.constructor) == null ? void 0 : _a2.name}; props: ${propsForError(value)}`);
  }
  return parts;
}
function propsForError(value) {
  const props = Object.getOwnPropertyNames(value);
  return `[${props.map((p) => `"${p}"`).join(", ")}]`;
}
function getName(value) {
  var _a2;
  return getStringFromMaybeBuffer(value.name) || getStringFromMaybeBuffer(value.filename) || // For fs.ReadStream
  ((_a2 = getStringFromMaybeBuffer(value.path)) == null ? void 0 : _a2.split(/[\\/]/).pop());
}
var getStringFromMaybeBuffer = (x) => {
  if (typeof x === "string")
    return x;
  if (typeof Buffer !== "undefined" && x instanceof Buffer)
    return String(x);
  return void 0;
};
var isAsyncIterableIterator = (value) => value != null && typeof value === "object" && typeof value[Symbol.asyncIterator] === "function";
var isMultipartBody = (body) => body && typeof body === "object" && body.body && body[Symbol.toStringTag] === "MultipartBody";
var multipartFormRequestOptions = async (opts) => {
  const form = await createForm(opts.body);
  return getMultipartRequestOptions(form, opts);
};
var createForm = async (body) => {
  const form = new FormData2();
  await Promise.all(Object.entries(body || {}).map(([key, value]) => addFormValue(form, key, value)));
  return form;
};
var addFormValue = async (form, key, value) => {
  if (value === void 0)
    return;
  if (value == null) {
    throw new TypeError(`Received null for "${key}"; to pass null in FormData, you must use the string 'null'`);
  }
  if (typeof value === "string" || typeof value === "number" || typeof value === "boolean") {
    form.append(key, String(value));
  } else if (isUploadable(value)) {
    const file = await toFile(value);
    form.append(key, file);
  } else if (Array.isArray(value)) {
    await Promise.all(value.map((entry) => addFormValue(form, key + "[]", entry)));
  } else if (typeof value === "object") {
    await Promise.all(Object.entries(value).map(([name, prop]) => addFormValue(form, `${key}[${name}]`, prop)));
  } else {
    throw new TypeError(`Invalid value given to form, expected a string, number, boolean, object, Array, File or Blob but got ${value} instead`);
  }
};

// node_modules/groq-sdk/core.mjs
var __classPrivateFieldSet = function(receiver, state, value, kind2, f) {
  if (kind2 === "m") throw new TypeError("Private method is not writable");
  if (kind2 === "a" && !f) throw new TypeError("Private accessor was defined without a setter");
  if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot write private member to an object whose class did not declare it");
  return kind2 === "a" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value), value;
};
var __classPrivateFieldGet = function(receiver, state, kind2, f) {
  if (kind2 === "a" && !f) throw new TypeError("Private accessor was defined without a getter");
  if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot read private member from an object whose class did not declare it");
  return kind2 === "m" ? f : kind2 === "a" ? f.call(receiver) : f ? f.value : state.get(receiver);
};
var _AbstractPage_client;
init();
async function defaultParseResponse(props) {
  var _a2;
  const { response } = props;
  if (props.options.stream) {
    debug("response", response.status, response.url, response.headers, response.body);
    if (props.options.__streamClass) {
      return props.options.__streamClass.fromSSEResponse(response, props.controller);
    }
    return Stream.fromSSEResponse(response, props.controller);
  }
  if (response.status === 204) {
    return null;
  }
  if (props.options.__binaryResponse) {
    return response;
  }
  const contentType = response.headers.get("content-type");
  const mediaType = (_a2 = contentType == null ? void 0 : contentType.split(";")[0]) == null ? void 0 : _a2.trim();
  const isJSON = (mediaType == null ? void 0 : mediaType.includes("application/json")) || (mediaType == null ? void 0 : mediaType.endsWith("+json"));
  if (isJSON) {
    const json = await response.json();
    debug("response", response.status, response.url, response.headers, json);
    return json;
  }
  const text = await response.text();
  debug("response", response.status, response.url, response.headers, text);
  return text;
}
var APIPromise = class _APIPromise extends Promise {
  constructor(responsePromise, parseResponse = defaultParseResponse) {
    super((resolve) => {
      resolve(null);
    });
    this.responsePromise = responsePromise;
    this.parseResponse = parseResponse;
  }
  _thenUnwrap(transform) {
    return new _APIPromise(this.responsePromise, async (props) => transform(await this.parseResponse(props), props));
  }
  /**
   * Gets the raw `Response` instance instead of parsing the response
   * data.
   *
   * If you want to parse the response body but still get the `Response`
   * instance, you can use {@link withResponse()}.
   *
   *  Getting the wrong TypeScript type for `Response`?
   * Try setting `"moduleResolution": "NodeNext"` if you can,
   * or add one of these imports before your first `import  from 'groq-sdk'`:
   * - `import 'groq-sdk/shims/node'` (if you're running on Node)
   * - `import 'groq-sdk/shims/web'` (otherwise)
   */
  asResponse() {
    return this.responsePromise.then((p) => p.response);
  }
  /**
   * Gets the parsed response data and the raw `Response` instance.
   *
   * If you just want to get the raw `Response` instance without parsing it,
   * you can use {@link asResponse()}.
   *
   *
   *  Getting the wrong TypeScript type for `Response`?
   * Try setting `"moduleResolution": "NodeNext"` if you can,
   * or add one of these imports before your first `import  from 'groq-sdk'`:
   * - `import 'groq-sdk/shims/node'` (if you're running on Node)
   * - `import 'groq-sdk/shims/web'` (otherwise)
   */
  async withResponse() {
    const [data, response] = await Promise.all([this.parse(), this.asResponse()]);
    return { data, response };
  }
  parse() {
    if (!this.parsedPromise) {
      this.parsedPromise = this.responsePromise.then(this.parseResponse);
    }
    return this.parsedPromise;
  }
  then(onfulfilled, onrejected) {
    return this.parse().then(onfulfilled, onrejected);
  }
  catch(onrejected) {
    return this.parse().catch(onrejected);
  }
  finally(onfinally) {
    return this.parse().finally(onfinally);
  }
};
var APIClient = class {
  constructor({
    baseURL,
    maxRetries = 2,
    timeout = 6e4,
    // 1 minute
    httpAgent,
    fetch: overriddenFetch
  }) {
    this.baseURL = baseURL;
    this.maxRetries = validatePositiveInteger("maxRetries", maxRetries);
    this.timeout = validatePositiveInteger("timeout", timeout);
    this.httpAgent = httpAgent;
    this.fetch = overriddenFetch ?? fetch2;
  }
  authHeaders(opts) {
    return {};
  }
  /**
   * Override this to add your own default headers, for example:
   *
   *  {
   *    ...super.defaultHeaders(),
   *    Authorization: 'Bearer 123',
   *  }
   */
  defaultHeaders(opts) {
    return {
      Accept: "application/json",
      "Content-Type": "application/json",
      "User-Agent": this.getUserAgent(),
      ...getPlatformHeaders(),
      ...this.authHeaders(opts)
    };
  }
  /**
   * Override this to add your own headers validation:
   */
  validateHeaders(headers, customHeaders) {
  }
  defaultIdempotencyKey() {
    return `stainless-node-retry-${uuid4()}`;
  }
  get(path, opts) {
    return this.methodRequest("get", path, opts);
  }
  post(path, opts) {
    return this.methodRequest("post", path, opts);
  }
  patch(path, opts) {
    return this.methodRequest("patch", path, opts);
  }
  put(path, opts) {
    return this.methodRequest("put", path, opts);
  }
  delete(path, opts) {
    return this.methodRequest("delete", path, opts);
  }
  methodRequest(method, path, opts) {
    return this.request(Promise.resolve(opts).then(async (opts2) => {
      const body = opts2 && isBlobLike(opts2 == null ? void 0 : opts2.body) ? new DataView(await opts2.body.arrayBuffer()) : (opts2 == null ? void 0 : opts2.body) instanceof DataView ? opts2.body : (opts2 == null ? void 0 : opts2.body) instanceof ArrayBuffer ? new DataView(opts2.body) : opts2 && ArrayBuffer.isView(opts2 == null ? void 0 : opts2.body) ? new DataView(opts2.body.buffer) : opts2 == null ? void 0 : opts2.body;
      return { method, path, ...opts2, body };
    }));
  }
  getAPIList(path, Page, opts) {
    return this.requestAPIList(Page, { method: "get", path, ...opts });
  }
  calculateContentLength(body) {
    if (typeof body === "string") {
      if (typeof Buffer !== "undefined") {
        return Buffer.byteLength(body, "utf8").toString();
      }
      if (typeof TextEncoder !== "undefined") {
        const encoder = new TextEncoder();
        const encoded = encoder.encode(body);
        return encoded.length.toString();
      }
    } else if (ArrayBuffer.isView(body)) {
      return body.byteLength.toString();
    }
    return null;
  }
  buildRequest(options, { retryCount = 0 } = {}) {
    var _a2;
    options = { ...options };
    const { method, path, query, headers = {} } = options;
    const body = ArrayBuffer.isView(options.body) || options.__binaryRequest && typeof options.body === "string" ? options.body : isMultipartBody(options.body) ? options.body.body : options.body ? JSON.stringify(options.body, null, 2) : null;
    const contentLength = this.calculateContentLength(body);
    const url = this.buildURL(path, query);
    if ("timeout" in options)
      validatePositiveInteger("timeout", options.timeout);
    options.timeout = options.timeout ?? this.timeout;
    const httpAgent = options.httpAgent ?? this.httpAgent ?? getDefaultAgent(url);
    const minAgentTimeout = options.timeout + 1e3;
    if (typeof ((_a2 = httpAgent == null ? void 0 : httpAgent.options) == null ? void 0 : _a2.timeout) === "number" && minAgentTimeout > (httpAgent.options.timeout ?? 0)) {
      httpAgent.options.timeout = minAgentTimeout;
    }
    if (this.idempotencyHeader && method !== "get") {
      if (!options.idempotencyKey)
        options.idempotencyKey = this.defaultIdempotencyKey();
      headers[this.idempotencyHeader] = options.idempotencyKey;
    }
    const reqHeaders = this.buildHeaders({ options, headers, contentLength, retryCount });
    const req = {
      method,
      ...body && { body },
      headers: reqHeaders,
      ...httpAgent && { agent: httpAgent },
      // @ts-ignore node-fetch uses a custom AbortSignal type that is
      // not compatible with standard web types
      signal: options.signal ?? null
    };
    return { req, url, timeout: options.timeout };
  }
  buildHeaders({ options, headers, contentLength, retryCount }) {
    const reqHeaders = {};
    if (contentLength) {
      reqHeaders["content-length"] = contentLength;
    }
    const defaultHeaders = this.defaultHeaders(options);
    applyHeadersMut(reqHeaders, defaultHeaders);
    applyHeadersMut(reqHeaders, headers);
    if (isMultipartBody(options.body) && kind !== "node") {
      delete reqHeaders["content-type"];
    }
    if (getHeader(defaultHeaders, "x-stainless-retry-count") === void 0 && getHeader(headers, "x-stainless-retry-count") === void 0) {
      reqHeaders["x-stainless-retry-count"] = String(retryCount);
    }
    if (getHeader(defaultHeaders, "x-stainless-timeout") === void 0 && getHeader(headers, "x-stainless-timeout") === void 0 && options.timeout) {
      reqHeaders["x-stainless-timeout"] = String(options.timeout);
    }
    this.validateHeaders(reqHeaders, headers);
    return reqHeaders;
  }
  /**
   * Used as a callback for mutating the given `FinalRequestOptions` object.
   */
  async prepareOptions(options) {
  }
  /**
   * Used as a callback for mutating the given `RequestInit` object.
   *
   * This is useful for cases where you want to add certain headers based off of
   * the request properties, e.g. `method` or `url`.
   */
  async prepareRequest(request, { url, options }) {
  }
  parseHeaders(headers) {
    return !headers ? {} : Symbol.iterator in headers ? Object.fromEntries(Array.from(headers).map((header) => [...header])) : { ...headers };
  }
  makeStatusError(status, error, message, headers) {
    return APIError.generate(status, error, message, headers);
  }
  request(options, remainingRetries = null) {
    return new APIPromise(this.makeRequest(options, remainingRetries));
  }
  async makeRequest(optionsInput, retriesRemaining) {
    var _a2, _b;
    const options = await optionsInput;
    const maxRetries = options.maxRetries ?? this.maxRetries;
    if (retriesRemaining == null) {
      retriesRemaining = maxRetries;
    }
    await this.prepareOptions(options);
    const { req, url, timeout } = this.buildRequest(options, { retryCount: maxRetries - retriesRemaining });
    await this.prepareRequest(req, { url, options });
    debug("request", url, options, req.headers);
    if ((_a2 = options.signal) == null ? void 0 : _a2.aborted) {
      throw new APIUserAbortError();
    }
    const controller = new AbortController();
    const response = await this.fetchWithTimeout(url, req, timeout, controller).catch(castToError);
    if (response instanceof Error) {
      if ((_b = options.signal) == null ? void 0 : _b.aborted) {
        throw new APIUserAbortError();
      }
      if (retriesRemaining) {
        return this.retryRequest(options, retriesRemaining);
      }
      if (response.name === "AbortError") {
        throw new APIConnectionTimeoutError();
      }
      throw new APIConnectionError({ cause: response });
    }
    const responseHeaders = createResponseHeaders(response.headers);
    if (!response.ok) {
      if (retriesRemaining && this.shouldRetry(response)) {
        const retryMessage2 = `retrying, ${retriesRemaining} attempts remaining`;
        debug(`response (error; ${retryMessage2})`, response.status, url, responseHeaders);
        return this.retryRequest(options, retriesRemaining, responseHeaders);
      }
      const errText = await response.text().catch((e) => castToError(e).message);
      const errJSON = safeJSON(errText);
      const errMessage = errJSON ? void 0 : errText;
      const retryMessage = retriesRemaining ? `(error; no more retries left)` : `(error; not retryable)`;
      debug(`response (error; ${retryMessage})`, response.status, url, responseHeaders, errMessage);
      const err = this.makeStatusError(response.status, errJSON, errMessage, responseHeaders);
      throw err;
    }
    return { response, options, controller };
  }
  requestAPIList(Page, options) {
    const request = this.makeRequest(options, null);
    return new PagePromise(this, request, Page);
  }
  buildURL(path, query) {
    const url = isAbsoluteURL(path) ? new URL(path) : new URL(this.baseURL + (this.baseURL.endsWith("/") && path.startsWith("/") ? path.slice(1) : path));
    const defaultQuery = this.defaultQuery();
    if (!isEmptyObj(defaultQuery)) {
      query = { ...defaultQuery, ...query };
    }
    if (typeof query === "object" && query && !Array.isArray(query)) {
      url.search = this.stringifyQuery(query);
    }
    return url.toString();
  }
  stringifyQuery(query) {
    return Object.entries(query).filter(([_, value]) => typeof value !== "undefined").map(([key, value]) => {
      if (typeof value === "string" || typeof value === "number" || typeof value === "boolean") {
        return `${encodeURIComponent(key)}=${encodeURIComponent(value)}`;
      }
      if (value === null) {
        return `${encodeURIComponent(key)}=`;
      }
      throw new GroqError(`Cannot stringify type ${typeof value}; Expected string, number, boolean, or null. If you need to pass nested query parameters, you can manually encode them, e.g. { query: { 'foo[key1]': value1, 'foo[key2]': value2 } }, and please open a GitHub issue requesting better support for your use case.`);
    }).join("&");
  }
  async fetchWithTimeout(url, init2, ms, controller) {
    const { signal, ...options } = init2 || {};
    if (signal)
      signal.addEventListener("abort", () => controller.abort());
    const timeout = setTimeout(() => controller.abort(), ms);
    const fetchOptions = {
      signal: controller.signal,
      ...options
    };
    if (fetchOptions.method) {
      fetchOptions.method = fetchOptions.method.toUpperCase();
    }
    return (
      // use undefined this binding; fetch errors if bound to something else in browser/cloudflare
      this.fetch.call(void 0, url, fetchOptions).finally(() => {
        clearTimeout(timeout);
      })
    );
  }
  shouldRetry(response) {
    const shouldRetryHeader = response.headers.get("x-should-retry");
    if (shouldRetryHeader === "true")
      return true;
    if (shouldRetryHeader === "false")
      return false;
    if (response.status === 408)
      return true;
    if (response.status === 409)
      return true;
    if (response.status === 429)
      return true;
    if (response.status >= 500)
      return true;
    return false;
  }
  async retryRequest(options, retriesRemaining, responseHeaders) {
    let timeoutMillis;
    const retryAfterMillisHeader = responseHeaders == null ? void 0 : responseHeaders["retry-after-ms"];
    if (retryAfterMillisHeader) {
      const timeoutMs = parseFloat(retryAfterMillisHeader);
      if (!Number.isNaN(timeoutMs)) {
        timeoutMillis = timeoutMs;
      }
    }
    const retryAfterHeader = responseHeaders == null ? void 0 : responseHeaders["retry-after"];
    if (retryAfterHeader && !timeoutMillis) {
      const timeoutSeconds = parseFloat(retryAfterHeader);
      if (!Number.isNaN(timeoutSeconds)) {
        timeoutMillis = timeoutSeconds * 1e3;
      } else {
        timeoutMillis = Date.parse(retryAfterHeader) - Date.now();
      }
    }
    if (!(timeoutMillis && 0 <= timeoutMillis && timeoutMillis < 60 * 1e3)) {
      const maxRetries = options.maxRetries ?? this.maxRetries;
      timeoutMillis = this.calculateDefaultRetryTimeoutMillis(retriesRemaining, maxRetries);
    }
    await sleep(timeoutMillis);
    return this.makeRequest(options, retriesRemaining - 1);
  }
  calculateDefaultRetryTimeoutMillis(retriesRemaining, maxRetries) {
    const initialRetryDelay = 0.5;
    const maxRetryDelay = 8;
    const numRetries = maxRetries - retriesRemaining;
    const sleepSeconds = Math.min(initialRetryDelay * Math.pow(2, numRetries), maxRetryDelay);
    const jitter = 1 - Math.random() * 0.25;
    return sleepSeconds * jitter * 1e3;
  }
  getUserAgent() {
    return `${this.constructor.name}/JS ${VERSION}`;
  }
};
var AbstractPage = class {
  constructor(client, response, body, options) {
    _AbstractPage_client.set(this, void 0);
    __classPrivateFieldSet(this, _AbstractPage_client, client, "f");
    this.options = options;
    this.response = response;
    this.body = body;
  }
  hasNextPage() {
    const items = this.getPaginatedItems();
    if (!items.length)
      return false;
    return this.nextPageInfo() != null;
  }
  async getNextPage() {
    const nextInfo = this.nextPageInfo();
    if (!nextInfo) {
      throw new GroqError("No next page expected; please check `.hasNextPage()` before calling `.getNextPage()`.");
    }
    const nextOptions = { ...this.options };
    if ("params" in nextInfo && typeof nextOptions.query === "object") {
      nextOptions.query = { ...nextOptions.query, ...nextInfo.params };
    } else if ("url" in nextInfo) {
      const params = [...Object.entries(nextOptions.query || {}), ...nextInfo.url.searchParams.entries()];
      for (const [key, value] of params) {
        nextInfo.url.searchParams.set(key, value);
      }
      nextOptions.query = void 0;
      nextOptions.path = nextInfo.url.toString();
    }
    return await __classPrivateFieldGet(this, _AbstractPage_client, "f").requestAPIList(this.constructor, nextOptions);
  }
  async *iterPages() {
    let page = this;
    yield page;
    while (page.hasNextPage()) {
      page = await page.getNextPage();
      yield page;
    }
  }
  async *[(_AbstractPage_client = /* @__PURE__ */ new WeakMap(), Symbol.asyncIterator)]() {
    for await (const page of this.iterPages()) {
      for (const item of page.getPaginatedItems()) {
        yield item;
      }
    }
  }
};
var PagePromise = class extends APIPromise {
  constructor(client, request, Page) {
    super(request, async (props) => new Page(client, props.response, await defaultParseResponse(props), props.options));
  }
  /**
   * Allow auto-paginating iteration on an unawaited list call, eg:
   *
   *    for await (const item of client.items.list()) {
   *      console.log(item)
   *    }
   */
  async *[Symbol.asyncIterator]() {
    const page = await this;
    for await (const item of page) {
      yield item;
    }
  }
};
var createResponseHeaders = (headers) => {
  return new Proxy(Object.fromEntries(
    // @ts-ignore
    headers.entries()
  ), {
    get(target, name) {
      const key = name.toString();
      return target[key.toLowerCase()] || target[key];
    }
  });
};
var getPlatformProperties = () => {
  var _a2;
  if (typeof Deno !== "undefined" && Deno.build != null) {
    return {
      "X-Stainless-Lang": "js",
      "X-Stainless-Package-Version": VERSION,
      "X-Stainless-OS": normalizePlatform(Deno.build.os),
      "X-Stainless-Arch": normalizeArch(Deno.build.arch),
      "X-Stainless-Runtime": "deno",
      "X-Stainless-Runtime-Version": typeof Deno.version === "string" ? Deno.version : ((_a2 = Deno.version) == null ? void 0 : _a2.deno) ?? "unknown"
    };
  }
  if (typeof EdgeRuntime !== "undefined") {
    return {
      "X-Stainless-Lang": "js",
      "X-Stainless-Package-Version": VERSION,
      "X-Stainless-OS": "Unknown",
      "X-Stainless-Arch": `other:${EdgeRuntime}`,
      "X-Stainless-Runtime": "edge",
      "X-Stainless-Runtime-Version": process.version
    };
  }
  if (Object.prototype.toString.call(typeof process !== "undefined" ? process : 0) === "[object process]") {
    return {
      "X-Stainless-Lang": "js",
      "X-Stainless-Package-Version": VERSION,
      "X-Stainless-OS": normalizePlatform(process.platform),
      "X-Stainless-Arch": normalizeArch(process.arch),
      "X-Stainless-Runtime": "node",
      "X-Stainless-Runtime-Version": process.version
    };
  }
  const browserInfo = getBrowserInfo();
  if (browserInfo) {
    return {
      "X-Stainless-Lang": "js",
      "X-Stainless-Package-Version": VERSION,
      "X-Stainless-OS": "Unknown",
      "X-Stainless-Arch": "unknown",
      "X-Stainless-Runtime": `browser:${browserInfo.browser}`,
      "X-Stainless-Runtime-Version": browserInfo.version
    };
  }
  return {
    "X-Stainless-Lang": "js",
    "X-Stainless-Package-Version": VERSION,
    "X-Stainless-OS": "Unknown",
    "X-Stainless-Arch": "unknown",
    "X-Stainless-Runtime": "unknown",
    "X-Stainless-Runtime-Version": "unknown"
  };
};
function getBrowserInfo() {
  if (typeof navigator === "undefined" || !navigator) {
    return null;
  }
  const browserPatterns = [
    { key: "edge", pattern: /Edge(?:\W+(\d+)\.(\d+)(?:\.(\d+))?)?/ },
    { key: "ie", pattern: /MSIE(?:\W+(\d+)\.(\d+)(?:\.(\d+))?)?/ },
    { key: "ie", pattern: /Trident(?:.*rv\:(\d+)\.(\d+)(?:\.(\d+))?)?/ },
    { key: "chrome", pattern: /Chrome(?:\W+(\d+)\.(\d+)(?:\.(\d+))?)?/ },
    { key: "firefox", pattern: /Firefox(?:\W+(\d+)\.(\d+)(?:\.(\d+))?)?/ },
    { key: "safari", pattern: /(?:Version\W+(\d+)\.(\d+)(?:\.(\d+))?)?(?:\W+Mobile\S*)?\W+Safari/ }
  ];
  for (const { key, pattern } of browserPatterns) {
    const match = pattern.exec(navigator.userAgent);
    if (match) {
      const major = match[1] || 0;
      const minor = match[2] || 0;
      const patch = match[3] || 0;
      return { browser: key, version: `${major}.${minor}.${patch}` };
    }
  }
  return null;
}
var normalizeArch = (arch) => {
  if (arch === "x32")
    return "x32";
  if (arch === "x86_64" || arch === "x64")
    return "x64";
  if (arch === "arm")
    return "arm";
  if (arch === "aarch64" || arch === "arm64")
    return "arm64";
  if (arch)
    return `other:${arch}`;
  return "unknown";
};
var normalizePlatform = (platform) => {
  platform = platform.toLowerCase();
  if (platform.includes("ios"))
    return "iOS";
  if (platform === "android")
    return "Android";
  if (platform === "darwin")
    return "MacOS";
  if (platform === "win32")
    return "Windows";
  if (platform === "freebsd")
    return "FreeBSD";
  if (platform === "openbsd")
    return "OpenBSD";
  if (platform === "linux")
    return "Linux";
  if (platform)
    return `Other:${platform}`;
  return "Unknown";
};
var _platformHeaders;
var getPlatformHeaders = () => {
  return _platformHeaders ?? (_platformHeaders = getPlatformProperties());
};
var safeJSON = (text) => {
  try {
    return JSON.parse(text);
  } catch (err) {
    return void 0;
  }
};
var startsWithSchemeRegexp = /^[a-z][a-z0-9+.-]*:/i;
var isAbsoluteURL = (url) => {
  return startsWithSchemeRegexp.test(url);
};
var sleep = (ms) => new Promise((resolve) => setTimeout(resolve, ms));
var validatePositiveInteger = (name, n) => {
  if (typeof n !== "number" || !Number.isInteger(n)) {
    throw new GroqError(`${name} must be an integer`);
  }
  if (n < 0) {
    throw new GroqError(`${name} must be a positive integer`);
  }
  return n;
};
var castToError = (err) => {
  if (err instanceof Error)
    return err;
  if (typeof err === "object" && err !== null) {
    try {
      return new Error(JSON.stringify(err));
    } catch {
    }
  }
  return new Error(err);
};
var readEnv = (env) => {
  var _a2, _b, _c, _d, _e;
  if (typeof process !== "undefined") {
    return ((_b = (_a2 = process.env) == null ? void 0 : _a2[env]) == null ? void 0 : _b.trim()) ?? void 0;
  }
  if (typeof Deno !== "undefined") {
    return (_e = (_d = (_c = Deno.env) == null ? void 0 : _c.get) == null ? void 0 : _d.call(_c, env)) == null ? void 0 : _e.trim();
  }
  return void 0;
};
function isEmptyObj(obj) {
  if (!obj)
    return true;
  for (const _k in obj)
    return false;
  return true;
}
function hasOwn(obj, key) {
  return Object.prototype.hasOwnProperty.call(obj, key);
}
function applyHeadersMut(targetHeaders, newHeaders) {
  for (const k in newHeaders) {
    if (!hasOwn(newHeaders, k))
      continue;
    const lowerKey = k.toLowerCase();
    if (!lowerKey)
      continue;
    const val = newHeaders[k];
    if (val === null) {
      delete targetHeaders[lowerKey];
    } else if (val !== void 0) {
      targetHeaders[lowerKey] = val;
    }
  }
}
function debug(action, ...args) {
  var _a2;
  if (typeof process !== "undefined" && ((_a2 = process == null ? void 0 : process.env) == null ? void 0 : _a2["DEBUG"]) === "true") {
    console.log(`Groq:DEBUG:${action}`, ...args);
  }
}
var uuid4 = () => {
  return "xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx".replace(/[xy]/g, (c) => {
    const r = Math.random() * 16 | 0;
    const v = c === "x" ? r : r & 3 | 8;
    return v.toString(16);
  });
};
var isRunningInBrowser = () => {
  return (
    // @ts-ignore
    typeof window !== "undefined" && // @ts-ignore
    typeof window.document !== "undefined" && // @ts-ignore
    typeof navigator !== "undefined"
  );
};
var isHeadersProtocol = (headers) => {
  return typeof (headers == null ? void 0 : headers.get) === "function";
};
var getHeader = (headers, header) => {
  var _a2;
  const lowerCasedHeader = header.toLowerCase();
  if (isHeadersProtocol(headers)) {
    const intercapsHeader = ((_a2 = header[0]) == null ? void 0 : _a2.toUpperCase()) + header.substring(1).replace(/([^\w])(\w)/g, (_m, g1, g2) => g1 + g2.toUpperCase());
    for (const key of [header, lowerCasedHeader, header.toUpperCase(), intercapsHeader]) {
      const value = headers.get(key);
      if (value) {
        return value;
      }
    }
  }
  for (const [key, value] of Object.entries(headers)) {
    if (key.toLowerCase() === lowerCasedHeader) {
      if (Array.isArray(value)) {
        if (value.length <= 1)
          return value[0];
        console.warn(`Received ${value.length} entries for the ${header} header, using the first entry.`);
        return value[0];
      }
      return value;
    }
  }
  return void 0;
};

// node_modules/groq-sdk/resource.mjs
var APIResource = class {
  constructor(client) {
    this._client = client;
  }
};

// node_modules/groq-sdk/resources/audio/speech.mjs
var Speech = class extends APIResource {
  /**
   * Generates audio from the input text.
   */
  create(body, options) {
    return this._client.post("/openai/v1/audio/speech", {
      body,
      ...options,
      headers: { Accept: "application/octet-stream", ...options == null ? void 0 : options.headers },
      __binaryResponse: true
    });
  }
};

// node_modules/groq-sdk/resources/audio/transcriptions.mjs
var Transcriptions = class extends APIResource {
  /**
   * Transcribes audio into the input language.
   */
  create(body, options) {
    return this._client.post("/openai/v1/audio/transcriptions", multipartFormRequestOptions({ body, ...options }));
  }
};

// node_modules/groq-sdk/resources/audio/translations.mjs
var Translations = class extends APIResource {
  /**
   * Translates audio into English.
   */
  create(body, options) {
    return this._client.post("/openai/v1/audio/translations", multipartFormRequestOptions({ body, ...options }));
  }
};

// node_modules/groq-sdk/resources/audio/audio.mjs
var Audio = class extends APIResource {
  constructor() {
    super(...arguments);
    this.speech = new Speech(this._client);
    this.transcriptions = new Transcriptions(this._client);
    this.translations = new Translations(this._client);
  }
};
Audio.Speech = Speech;
Audio.Transcriptions = Transcriptions;
Audio.Translations = Translations;

// node_modules/groq-sdk/resources/batches.mjs
var Batches = class extends APIResource {
  /**
   * Creates and executes a batch from an uploaded file of requests
   */
  create(body, options) {
    return this._client.post("/openai/v1/batches", { body, ...options });
  }
  /**
   * Retrieves a batch.
   */
  retrieve(batchId, options) {
    return this._client.get(`/openai/v1/batches/${batchId}`, options);
  }
  /**
   * List your organization's batches.
   */
  list(options) {
    return this._client.get("/openai/v1/batches", options);
  }
  /**
   * Cancels a batch.
   */
  cancel(batchId, options) {
    return this._client.post(`/openai/v1/batches/${batchId}/cancel`, options);
  }
};

// node_modules/groq-sdk/resources/chat/completions.mjs
var Completions = class extends APIResource {
  create(body, options) {
    return this._client.post("/openai/v1/chat/completions", {
      body,
      ...options,
      stream: body.stream ?? false
    });
  }
};

// node_modules/groq-sdk/resources/chat/chat.mjs
var Chat = class extends APIResource {
  constructor() {
    super(...arguments);
    this.completions = new Completions(this._client);
  }
};
Chat.Completions = Completions;

// node_modules/groq-sdk/resources/completions.mjs
var Completions2 = class extends APIResource {
};

// node_modules/groq-sdk/resources/embeddings.mjs
var Embeddings = class extends APIResource {
  /**
   * Creates an embedding vector representing the input text.
   */
  create(body, options) {
    return this._client.post("/openai/v1/embeddings", { body, ...options });
  }
};

// node_modules/groq-sdk/resources/files.mjs
var Files = class extends APIResource {
  /**
   * Upload a file that can be used across various endpoints.
   *
   * The Batch API only supports `.jsonl` files up to 100 MB in size. The input also
   * has a specific required [format](/docs/batch).
   *
   * Please contact us if you need to increase these storage limits.
   */
  create(body, options) {
    return this._client.post("/openai/v1/files", multipartFormRequestOptions({ body, ...options }));
  }
  /**
   * Returns a list of files.
   */
  list(options) {
    return this._client.get("/openai/v1/files", options);
  }
  /**
   * Delete a file.
   */
  delete(fileId, options) {
    return this._client.delete(`/openai/v1/files/${fileId}`, options);
  }
  /**
   * Returns the contents of the specified file.
   */
  content(fileId, options) {
    return this._client.get(`/openai/v1/files/${fileId}/content`, options);
  }
  /**
   * Returns information about a file.
   */
  info(fileId, options) {
    return this._client.get(`/openai/v1/files/${fileId}`, options);
  }
};

// node_modules/groq-sdk/resources/models.mjs
var Models = class extends APIResource {
  /**
   * Get a specific model
   */
  retrieve(model, options) {
    return this._client.get(`/openai/v1/models/${model}`, options);
  }
  /**
   * get all available models
   */
  list(options) {
    return this._client.get("/openai/v1/models", options);
  }
  /**
   * Delete a model
   */
  delete(model, options) {
    return this._client.delete(`/openai/v1/models/${model}`, options);
  }
};

// node_modules/groq-sdk/index.mjs
var _a;
var Groq = class extends APIClient {
  /**
   * API Client for interfacing with the Groq API.
   *
   * @param {string | undefined} [opts.apiKey=process.env['GROQ_API_KEY'] ?? undefined]
   * @param {string} [opts.baseURL=process.env['GROQ_BASE_URL'] ?? https://api.groq.com] - Override the default base URL for the API.
   * @param {number} [opts.timeout=1 minute] - The maximum amount of time (in milliseconds) the client will wait for a response before timing out.
   * @param {number} [opts.httpAgent] - An HTTP agent used to manage HTTP(s) connections.
   * @param {Core.Fetch} [opts.fetch] - Specify a custom `fetch` function implementation.
   * @param {number} [opts.maxRetries=2] - The maximum number of times the client will retry a request.
   * @param {Core.Headers} opts.defaultHeaders - Default headers to include with every request to the API.
   * @param {Core.DefaultQuery} opts.defaultQuery - Default query parameters to include with every request to the API.
   * @param {boolean} [opts.dangerouslyAllowBrowser=false] - By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.
   */
  constructor({ baseURL = readEnv("GROQ_BASE_URL"), apiKey = readEnv("GROQ_API_KEY"), ...opts } = {}) {
    if (apiKey === void 0) {
      throw new GroqError("The GROQ_API_KEY environment variable is missing or empty; either provide it, or instantiate the Groq client with an apiKey option, like new Groq({ apiKey: 'My API Key' }).");
    }
    const options = {
      apiKey,
      ...opts,
      baseURL: baseURL || `https://api.groq.com`
    };
    if (!options.dangerouslyAllowBrowser && isRunningInBrowser()) {
      throw new GroqError("It looks like you're running in a browser-like environment.\n\nThis is disabled by default, as it risks exposing your secret API credentials to attackers.\nIf you understand the risks and have appropriate mitigations in place,\nyou can set the `dangerouslyAllowBrowser` option to `true`, e.g.,\n\nnew Groq({ apiKey, dangerouslyAllowBrowser: true })");
    }
    super({
      baseURL: options.baseURL,
      timeout: options.timeout ?? 6e4,
      httpAgent: options.httpAgent,
      maxRetries: options.maxRetries,
      fetch: options.fetch
    });
    this.completions = new Completions2(this);
    this.chat = new Chat(this);
    this.embeddings = new Embeddings(this);
    this.audio = new Audio(this);
    this.models = new Models(this);
    this.batches = new Batches(this);
    this.files = new Files(this);
    this._options = options;
    this.apiKey = apiKey;
  }
  defaultQuery() {
    return this._options.defaultQuery;
  }
  defaultHeaders(opts) {
    return {
      ...super.defaultHeaders(opts),
      ...this._options.defaultHeaders
    };
  }
  authHeaders(opts) {
    return { Authorization: `Bearer ${this.apiKey}` };
  }
};
_a = Groq;
Groq.Groq = _a;
Groq.DEFAULT_TIMEOUT = 6e4;
Groq.GroqError = GroqError;
Groq.APIError = APIError;
Groq.APIConnectionError = APIConnectionError;
Groq.APIConnectionTimeoutError = APIConnectionTimeoutError;
Groq.APIUserAbortError = APIUserAbortError;
Groq.NotFoundError = NotFoundError;
Groq.ConflictError = ConflictError;
Groq.RateLimitError = RateLimitError;
Groq.BadRequestError = BadRequestError;
Groq.AuthenticationError = AuthenticationError;
Groq.InternalServerError = InternalServerError;
Groq.PermissionDeniedError = PermissionDeniedError;
Groq.UnprocessableEntityError = UnprocessableEntityError;
Groq.toFile = toFile;
Groq.fileFromPath = fileFromPath;
Groq.Completions = Completions2;
Groq.Chat = Chat;
Groq.Embeddings = Embeddings;
Groq.Audio = Audio;
Groq.Models = Models;
Groq.Batches = Batches;
Groq.Files = Files;
var groq_sdk_default = Groq;

// node_modules/@langchain/core/dist/runnables/router.js
var RouterRunnable = class extends Runnable {
  constructor(fields) {
    super(fields);
    __publicField(this, "lc_namespace", ["langchain_core", "runnables"]);
    __publicField(this, "lc_serializable", true);
    __publicField(this, "runnables");
    this.runnables = fields.runnables;
  }
  static lc_name() {
    return "RouterRunnable";
  }
  async invoke(input, options) {
    const { key, input: actualInput } = input;
    const runnable = this.runnables[key];
    if (runnable === void 0) throw new Error(`No runnable associated with key "${key}".`);
    return runnable.invoke(actualInput, ensureConfig(options));
  }
  async batch(inputs, options, batchOptions) {
    var _a2;
    const keys = inputs.map((input) => input.key);
    const actualInputs = inputs.map((input) => input.input);
    const missingKey = keys.find((key) => this.runnables[key] === void 0);
    if (missingKey !== void 0) throw new Error(`One or more keys do not have a corresponding runnable.`);
    const runnables = keys.map((key) => this.runnables[key]);
    const optionsList = this._getOptionsList(options ?? {}, inputs.length);
    const maxConcurrency = ((_a2 = optionsList[0]) == null ? void 0 : _a2.maxConcurrency) ?? (batchOptions == null ? void 0 : batchOptions.maxConcurrency);
    const batchSize = maxConcurrency && maxConcurrency > 0 ? maxConcurrency : inputs.length;
    const batchResults = [];
    for (let i = 0; i < actualInputs.length; i += batchSize) {
      const batchPromises = actualInputs.slice(i, i + batchSize).map((actualInput, i$1) => runnables[i$1].invoke(actualInput, optionsList[i$1]));
      const batchResult = await Promise.all(batchPromises);
      batchResults.push(batchResult);
    }
    return batchResults.flat();
  }
  async stream(input, options) {
    const { key, input: actualInput } = input;
    const runnable = this.runnables[key];
    if (runnable === void 0) throw new Error(`No runnable associated with key "${key}".`);
    return runnable.stream(actualInput, options);
  }
};

// node_modules/@langchain/core/dist/runnables/branch.js
var RunnableBranch = class extends Runnable {
  constructor(fields) {
    super(fields);
    __publicField(this, "lc_namespace", ["langchain_core", "runnables"]);
    __publicField(this, "lc_serializable", true);
    __publicField(this, "default");
    __publicField(this, "branches");
    this.branches = fields.branches;
    this.default = fields.default;
  }
  static lc_name() {
    return "RunnableBranch";
  }
  /**
  * Convenience method for instantiating a RunnableBranch from
  * RunnableLikes (objects, functions, or Runnables).
  *
  * Each item in the input except for the last one should be a
  * tuple with two items. The first is a "condition" RunnableLike that
  * returns "true" if the second RunnableLike in the tuple should run.
  *
  * The final item in the input should be a RunnableLike that acts as a
  * default branch if no other branches match.
  *
  * @example
  * ```ts
  * import { RunnableBranch } from "@langchain/core/runnables";
  *
  * const branch = RunnableBranch.from([
  *   [(x: number) => x > 0, (x: number) => x + 1],
  *   [(x: number) => x < 0, (x: number) => x - 1],
  *   (x: number) => x
  * ]);
  * ```
  * @param branches An array where the every item except the last is a tuple of [condition, runnable]
  *   pairs. The last item is a default runnable which is invoked if no other condition matches.
  * @returns A new RunnableBranch.
  */
  static from(branches) {
    if (branches.length < 1) throw new Error("RunnableBranch requires at least one branch");
    const branchLikes = branches.slice(0, -1);
    const coercedBranches = branchLikes.map(([condition, runnable]) => [_coerceToRunnable(condition), _coerceToRunnable(runnable)]);
    const defaultBranch = _coerceToRunnable(branches[branches.length - 1]);
    return new this({
      branches: coercedBranches,
      default: defaultBranch
    });
  }
  async _invoke(input, config, runManager) {
    let result;
    for (let i = 0; i < this.branches.length; i += 1) {
      const [condition, branchRunnable] = this.branches[i];
      const conditionValue = await condition.invoke(input, patchConfig(config, { callbacks: runManager == null ? void 0 : runManager.getChild(`condition:${i + 1}`) }));
      if (conditionValue) {
        result = await branchRunnable.invoke(input, patchConfig(config, { callbacks: runManager == null ? void 0 : runManager.getChild(`branch:${i + 1}`) }));
        break;
      }
    }
    if (!result) result = await this.default.invoke(input, patchConfig(config, { callbacks: runManager == null ? void 0 : runManager.getChild("branch:default") }));
    return result;
  }
  async invoke(input, config = {}) {
    return this._callWithConfig(this._invoke, input, config);
  }
  async *_streamIterator(input, config) {
    const callbackManager_ = await getCallbackManagerForConfig(config);
    const runManager = await (callbackManager_ == null ? void 0 : callbackManager_.handleChainStart(this.toJSON(), _coerceToDict(input, "input"), config == null ? void 0 : config.runId, void 0, void 0, void 0, config == null ? void 0 : config.runName));
    let finalOutput;
    let finalOutputSupported = true;
    let stream;
    try {
      for (let i = 0; i < this.branches.length; i += 1) {
        const [condition, branchRunnable] = this.branches[i];
        const conditionValue = await condition.invoke(input, patchConfig(config, { callbacks: runManager == null ? void 0 : runManager.getChild(`condition:${i + 1}`) }));
        if (conditionValue) {
          stream = await branchRunnable.stream(input, patchConfig(config, { callbacks: runManager == null ? void 0 : runManager.getChild(`branch:${i + 1}`) }));
          for await (const chunk of stream) {
            yield chunk;
            if (finalOutputSupported) if (finalOutput === void 0) finalOutput = chunk;
            else try {
              finalOutput = concat(finalOutput, chunk);
            } catch {
              finalOutput = void 0;
              finalOutputSupported = false;
            }
          }
          break;
        }
      }
      if (stream === void 0) {
        stream = await this.default.stream(input, patchConfig(config, { callbacks: runManager == null ? void 0 : runManager.getChild("branch:default") }));
        for await (const chunk of stream) {
          yield chunk;
          if (finalOutputSupported) if (finalOutput === void 0) finalOutput = chunk;
          else try {
            finalOutput = concat(finalOutput, chunk);
          } catch {
            finalOutput = void 0;
            finalOutputSupported = false;
          }
        }
      }
    } catch (e) {
      await (runManager == null ? void 0 : runManager.handleChainError(e));
      throw e;
    }
    await (runManager == null ? void 0 : runManager.handleChainEnd(finalOutput ?? {}));
  }
};

// node_modules/@langchain/core/dist/runnables/history.js
var RunnableWithMessageHistory = class extends RunnableBinding {
  constructor(fields) {
    let historyChain = RunnableLambda.from((input, options) => this._enterHistory(input, options ?? {})).withConfig({ runName: "loadHistory" });
    const messagesKey = fields.historyMessagesKey ?? fields.inputMessagesKey;
    if (messagesKey) historyChain = RunnablePassthrough.assign({ [messagesKey]: historyChain }).withConfig({ runName: "insertHistory" });
    const bound = historyChain.pipe(fields.runnable.withListeners({ onEnd: (run, config$1) => this._exitHistory(run, config$1 ?? {}) })).withConfig({ runName: "RunnableWithMessageHistory" });
    const config = fields.config ?? {};
    super({
      ...fields,
      config,
      bound
    });
    __publicField(this, "runnable");
    __publicField(this, "inputMessagesKey");
    __publicField(this, "outputMessagesKey");
    __publicField(this, "historyMessagesKey");
    __publicField(this, "getMessageHistory");
    this.runnable = fields.runnable;
    this.getMessageHistory = fields.getMessageHistory;
    this.inputMessagesKey = fields.inputMessagesKey;
    this.outputMessagesKey = fields.outputMessagesKey;
    this.historyMessagesKey = fields.historyMessagesKey;
  }
  _getInputMessages(inputValue) {
    let parsedInputValue;
    if (typeof inputValue === "object" && !Array.isArray(inputValue) && !isBaseMessage(inputValue)) {
      let key;
      if (this.inputMessagesKey) key = this.inputMessagesKey;
      else if (Object.keys(inputValue).length === 1) key = Object.keys(inputValue)[0];
      else key = "input";
      if (Array.isArray(inputValue[key]) && Array.isArray(inputValue[key][0])) parsedInputValue = inputValue[key][0];
      else parsedInputValue = inputValue[key];
    } else parsedInputValue = inputValue;
    if (typeof parsedInputValue === "string") return [new HumanMessage(parsedInputValue)];
    else if (Array.isArray(parsedInputValue)) return parsedInputValue;
    else if (isBaseMessage(parsedInputValue)) return [parsedInputValue];
    else throw new Error(`Expected a string, BaseMessage, or array of BaseMessages.
Got ${JSON.stringify(parsedInputValue, null, 2)}`);
  }
  _getOutputMessages(outputValue) {
    let parsedOutputValue;
    if (!Array.isArray(outputValue) && !isBaseMessage(outputValue) && typeof outputValue !== "string") {
      let key;
      if (this.outputMessagesKey !== void 0) key = this.outputMessagesKey;
      else if (Object.keys(outputValue).length === 1) key = Object.keys(outputValue)[0];
      else key = "output";
      if (outputValue.generations !== void 0) parsedOutputValue = outputValue.generations[0][0].message;
      else parsedOutputValue = outputValue[key];
    } else parsedOutputValue = outputValue;
    if (typeof parsedOutputValue === "string") return [new AIMessage(parsedOutputValue)];
    else if (Array.isArray(parsedOutputValue)) return parsedOutputValue;
    else if (isBaseMessage(parsedOutputValue)) return [parsedOutputValue];
    else throw new Error(`Expected a string, BaseMessage, or array of BaseMessages. Received: ${JSON.stringify(parsedOutputValue, null, 2)}`);
  }
  async _enterHistory(input, kwargs) {
    var _a2;
    const history = (_a2 = kwargs == null ? void 0 : kwargs.configurable) == null ? void 0 : _a2.messageHistory;
    const messages = await history.getMessages();
    if (this.historyMessagesKey === void 0) return messages.concat(this._getInputMessages(input));
    return messages;
  }
  async _exitHistory(run, config) {
    var _a2;
    const history = (_a2 = config.configurable) == null ? void 0 : _a2.messageHistory;
    let inputs;
    if (Array.isArray(run.inputs) && Array.isArray(run.inputs[0])) inputs = run.inputs[0];
    else inputs = run.inputs;
    let inputMessages = this._getInputMessages(inputs);
    if (this.historyMessagesKey === void 0) {
      const existingMessages = await history.getMessages();
      inputMessages = inputMessages.slice(existingMessages.length);
    }
    const outputValue = run.outputs;
    if (!outputValue) throw new Error(`Output values from 'Run' undefined. Run: ${JSON.stringify(run, null, 2)}`);
    const outputMessages = this._getOutputMessages(outputValue);
    await history.addMessages([...inputMessages, ...outputMessages]);
  }
  async _mergeConfig(...configs) {
    const config = await super._mergeConfig(...configs);
    if (!config.configurable || !config.configurable.sessionId) {
      const exampleInput = { [this.inputMessagesKey ?? "input"]: "foo" };
      const exampleConfig = { configurable: { sessionId: "123" } };
      throw new Error(`sessionId is required. Pass it in as part of the config argument to .invoke() or .stream()
eg. chain.invoke(${JSON.stringify(exampleInput)}, ${JSON.stringify(exampleConfig)})`);
    }
    const { sessionId } = config.configurable;
    config.configurable.messageHistory = await this.getMessageHistory(sessionId);
    return config;
  }
};

// node_modules/@langchain/core/dist/runnables/index.js
var runnables_exports = {};
__export(runnables_exports, {
  RouterRunnable: () => RouterRunnable,
  Runnable: () => Runnable,
  RunnableAssign: () => RunnableAssign,
  RunnableBinding: () => RunnableBinding,
  RunnableBranch: () => RunnableBranch,
  RunnableEach: () => RunnableEach,
  RunnableLambda: () => RunnableLambda,
  RunnableMap: () => RunnableMap,
  RunnableParallel: () => RunnableParallel,
  RunnablePassthrough: () => RunnablePassthrough,
  RunnablePick: () => RunnablePick,
  RunnableRetry: () => RunnableRetry,
  RunnableSequence: () => RunnableSequence,
  RunnableToolLike: () => RunnableToolLike,
  RunnableWithFallbacks: () => RunnableWithFallbacks,
  RunnableWithMessageHistory: () => RunnableWithMessageHistory,
  _coerceToRunnable: () => _coerceToRunnable,
  ensureConfig: () => ensureConfig,
  getCallbackManagerForConfig: () => getCallbackManagerForConfig,
  mergeConfigs: () => mergeConfigs,
  patchConfig: () => patchConfig,
  pickRunnableConfigKeys: () => pickRunnableConfigKeys,
  raceWithSignal: () => raceWithSignal
});

// node_modules/@langchain/core/dist/output_parsers/base.js
var BaseLLMOutputParser = class extends Runnable {
  /**
  * Parses the result of an LLM call with a given prompt. By default, it
  * simply calls `parseResult`.
  * @param generations The generations from an LLM call.
  * @param _prompt The prompt used in the LLM call.
  * @param callbacks Optional callbacks.
  * @returns A promise of the parsed output.
  */
  parseResultWithPrompt(generations, _prompt, callbacks) {
    return this.parseResult(generations, callbacks);
  }
  _baseMessageToString(message) {
    return typeof message.content === "string" ? message.content : this._baseMessageContentToString(message.content);
  }
  _baseMessageContentToString(content) {
    return JSON.stringify(content);
  }
  /**
  * Calls the parser with a given input and optional configuration options.
  * If the input is a string, it creates a generation with the input as
  * text and calls `parseResult`. If the input is a `BaseMessage`, it
  * creates a generation with the input as a message and the content of the
  * input as text, and then calls `parseResult`.
  * @param input The input to the parser, which can be a string or a `BaseMessage`.
  * @param options Optional configuration options.
  * @returns A promise of the parsed output.
  */
  async invoke(input, options) {
    if (typeof input === "string") return this._callWithConfig(async (input$1, options$1) => this.parseResult([{ text: input$1 }], options$1 == null ? void 0 : options$1.callbacks), input, {
      ...options,
      runType: "parser"
    });
    else return this._callWithConfig(async (input$1, options$1) => this.parseResult([{
      message: input$1,
      text: this._baseMessageToString(input$1)
    }], options$1 == null ? void 0 : options$1.callbacks), input, {
      ...options,
      runType: "parser"
    });
  }
};
var BaseOutputParser = class extends BaseLLMOutputParser {
  parseResult(generations, callbacks) {
    return this.parse(generations[0].text, callbacks);
  }
  async parseWithPrompt(text, _prompt, callbacks) {
    return this.parse(text, callbacks);
  }
  /**
  * Return the string type key uniquely identifying this class of parser
  */
  _type() {
    throw new Error("_type not implemented");
  }
};
var OutputParserException = class extends Error {
  constructor(message, llmOutput, observation, sendToLLM = false) {
    super(message);
    __publicField(this, "llmOutput");
    __publicField(this, "observation");
    __publicField(this, "sendToLLM");
    this.llmOutput = llmOutput;
    this.observation = observation;
    this.sendToLLM = sendToLLM;
    if (sendToLLM) {
      if (observation === void 0 || llmOutput === void 0) throw new Error("Arguments 'observation' & 'llmOutput' are required if 'sendToLlm' is true");
    }
    addLangChainErrorFields(this, "OUTPUT_PARSING_FAILURE");
  }
};

// node_modules/@langchain/core/dist/output_parsers/transform.js
var BaseTransformOutputParser = class extends BaseOutputParser {
  async *_transform(inputGenerator) {
    for await (const chunk of inputGenerator) if (typeof chunk === "string") yield this.parseResult([{ text: chunk }]);
    else yield this.parseResult([{
      message: chunk,
      text: this._baseMessageToString(chunk)
    }]);
  }
  /**
  * Transforms an asynchronous generator of input into an asynchronous
  * generator of parsed output.
  * @param inputGenerator An asynchronous generator of input.
  * @param options A configuration object.
  * @returns An asynchronous generator of parsed output.
  */
  async *transform(inputGenerator, options) {
    yield* this._transformStreamWithConfig(inputGenerator, this._transform.bind(this), {
      ...options,
      runType: "parser"
    });
  }
};
var BaseCumulativeTransformOutputParser = class extends BaseTransformOutputParser {
  constructor(fields) {
    super(fields);
    __publicField(this, "diff", false);
    this.diff = (fields == null ? void 0 : fields.diff) ?? this.diff;
  }
  async *_transform(inputGenerator) {
    let prevParsed;
    let accGen;
    for await (const chunk of inputGenerator) {
      if (typeof chunk !== "string" && typeof chunk.content !== "string") throw new Error("Cannot handle non-string output.");
      let chunkGen;
      if (isBaseMessageChunk(chunk)) {
        if (typeof chunk.content !== "string") throw new Error("Cannot handle non-string message output.");
        chunkGen = new ChatGenerationChunk({
          message: chunk,
          text: chunk.content
        });
      } else if (isBaseMessage(chunk)) {
        if (typeof chunk.content !== "string") throw new Error("Cannot handle non-string message output.");
        chunkGen = new ChatGenerationChunk({
          message: convertToChunk(chunk),
          text: chunk.content
        });
      } else chunkGen = new GenerationChunk({ text: chunk });
      if (accGen === void 0) accGen = chunkGen;
      else accGen = accGen.concat(chunkGen);
      const parsed = await this.parsePartialResult([accGen]);
      if (parsed !== void 0 && parsed !== null && !deepCompareStrict(parsed, prevParsed)) {
        if (this.diff) yield this._diff(prevParsed, parsed);
        else yield parsed;
        prevParsed = parsed;
      }
    }
  }
  getFormatInstructions() {
    return "";
  }
};

// node_modules/@langchain/core/dist/output_parsers/bytes.js
var BytesOutputParser = class extends BaseTransformOutputParser {
  constructor() {
    super(...arguments);
    __publicField(this, "lc_namespace", [
      "langchain_core",
      "output_parsers",
      "bytes"
    ]);
    __publicField(this, "lc_serializable", true);
    __publicField(this, "textEncoder", new TextEncoder());
  }
  static lc_name() {
    return "BytesOutputParser";
  }
  parse(text) {
    return Promise.resolve(this.textEncoder.encode(text));
  }
  getFormatInstructions() {
    return "";
  }
};

// node_modules/@langchain/core/dist/output_parsers/list.js
var ListOutputParser = class extends BaseTransformOutputParser {
  constructor() {
    super(...arguments);
    __publicField(this, "re");
  }
  async *_transform(inputGenerator) {
    let buffer = "";
    for await (const input of inputGenerator) {
      if (typeof input === "string") buffer += input;
      else buffer += input.content;
      if (!this.re) {
        const parts = await this.parse(buffer);
        if (parts.length > 1) {
          for (const part of parts.slice(0, -1)) yield [part];
          buffer = parts[parts.length - 1];
        }
      } else {
        const matches = [...buffer.matchAll(this.re)];
        if (matches.length > 1) {
          let doneIdx = 0;
          for (const match of matches.slice(0, -1)) {
            yield [match[1]];
            doneIdx += (match.index ?? 0) + match[0].length;
          }
          buffer = buffer.slice(doneIdx);
        }
      }
    }
    for (const part of await this.parse(buffer)) yield [part];
  }
};
var CommaSeparatedListOutputParser = class extends ListOutputParser {
  constructor() {
    super(...arguments);
    __publicField(this, "lc_namespace", [
      "langchain_core",
      "output_parsers",
      "list"
    ]);
    __publicField(this, "lc_serializable", true);
  }
  static lc_name() {
    return "CommaSeparatedListOutputParser";
  }
  /**
  * Parses the given text into an array of strings, using a comma as the
  * separator. If the parsing fails, throws an OutputParserException.
  * @param text The text to parse.
  * @returns An array of strings obtained by splitting the input text at each comma.
  */
  async parse(text) {
    try {
      return text.trim().split(",").map((s) => s.trim());
    } catch {
      throw new OutputParserException(`Could not parse output: ${text}`, text);
    }
  }
  /**
  * Provides instructions on the expected format of the response for the
  * CommaSeparatedListOutputParser.
  * @returns A string containing instructions on the expected format of the response.
  */
  getFormatInstructions() {
    return `Your response should be a list of comma separated values, eg: \`foo, bar, baz\``;
  }
};
var CustomListOutputParser = class extends ListOutputParser {
  constructor({ length, separator }) {
    super(...arguments);
    __publicField(this, "lc_namespace", [
      "langchain_core",
      "output_parsers",
      "list"
    ]);
    __publicField(this, "length");
    __publicField(this, "separator");
    this.length = length;
    this.separator = separator || ",";
  }
  /**
  * Parses the given text into an array of strings, using the specified
  * separator. If the parsing fails or the number of items in the list
  * doesn't match the expected length, throws an OutputParserException.
  * @param text The text to parse.
  * @returns An array of strings obtained by splitting the input text at each occurrence of the specified separator.
  */
  async parse(text) {
    try {
      const items = text.trim().split(this.separator).map((s) => s.trim());
      if (this.length !== void 0 && items.length !== this.length) throw new OutputParserException(`Incorrect number of items. Expected ${this.length}, got ${items.length}.`);
      return items;
    } catch (e) {
      if (Object.getPrototypeOf(e) === OutputParserException.prototype) throw e;
      throw new OutputParserException(`Could not parse output: ${text}`);
    }
  }
  /**
  * Provides instructions on the expected format of the response for the
  * CustomListOutputParser, including the number of items and the
  * separator.
  * @returns A string containing instructions on the expected format of the response.
  */
  getFormatInstructions() {
    return `Your response should be a list of ${this.length === void 0 ? "" : `${this.length} `}items separated by "${this.separator}" (eg: \`foo${this.separator} bar${this.separator} baz\`)`;
  }
};
var NumberedListOutputParser = class extends ListOutputParser {
  constructor() {
    super(...arguments);
    __publicField(this, "lc_namespace", [
      "langchain_core",
      "output_parsers",
      "list"
    ]);
    __publicField(this, "lc_serializable", true);
    __publicField(this, "re", /\d+\.\s([^\n]+)/g);
  }
  static lc_name() {
    return "NumberedListOutputParser";
  }
  getFormatInstructions() {
    return `Your response should be a numbered list with each item on a new line. For example: 

1. foo

2. bar

3. baz`;
  }
  async parse(text) {
    return [...text.matchAll(this.re) ?? []].map((m) => m[1]);
  }
};
var MarkdownListOutputParser = class extends ListOutputParser {
  constructor() {
    super(...arguments);
    __publicField(this, "lc_namespace", [
      "langchain_core",
      "output_parsers",
      "list"
    ]);
    __publicField(this, "lc_serializable", true);
    __publicField(this, "re", /^\s*[-*]\s([^\n]+)$/gm);
  }
  static lc_name() {
    return "NumberedListOutputParser";
  }
  getFormatInstructions() {
    return `Your response should be a numbered list with each item on a new line. For example: 

1. foo

2. bar

3. baz`;
  }
  async parse(text) {
    return [...text.matchAll(this.re) ?? []].map((m) => m[1]);
  }
};

// node_modules/@langchain/core/dist/output_parsers/string.js
var StringOutputParser = class extends BaseTransformOutputParser {
  constructor() {
    super(...arguments);
    __publicField(this, "lc_namespace", [
      "langchain_core",
      "output_parsers",
      "string"
    ]);
    __publicField(this, "lc_serializable", true);
  }
  static lc_name() {
    return "StrOutputParser";
  }
  /**
  * Parses a string output from an LLM call. This method is meant to be
  * implemented by subclasses to define how a string output from an LLM
  * should be parsed.
  * @param text The string output from an LLM call.
  * @param callbacks Optional callbacks.
  * @returns A promise of the parsed output.
  */
  parse(text) {
    return Promise.resolve(text);
  }
  getFormatInstructions() {
    return "";
  }
  _textContentToString(content) {
    return content.text;
  }
  _imageUrlContentToString(_content) {
    throw new Error(`Cannot coerce a multimodal "image_url" message part into a string.`);
  }
  _messageContentToString(content) {
    switch (content.type) {
      case "text":
      case "text_delta":
        if ("text" in content) return this._textContentToString(content);
        break;
      case "image_url":
        if ("image_url" in content) return this._imageUrlContentToString(content);
        break;
      default:
        throw new Error(`Cannot coerce "${content.type}" message part into a string.`);
    }
    throw new Error(`Invalid content type: ${content.type}`);
  }
  _baseMessageContentToString(content) {
    return content.reduce((acc, item) => acc + this._messageContentToString(item), "");
  }
};

// node_modules/@langchain/core/dist/output_parsers/structured.js
var StructuredOutputParser = class extends BaseOutputParser {
  constructor(schema) {
    super(schema);
    __publicField(this, "lc_namespace", [
      "langchain",
      "output_parsers",
      "structured"
    ]);
    this.schema = schema;
  }
  static lc_name() {
    return "StructuredOutputParser";
  }
  toJSON() {
    return this.toJSONNotImplemented();
  }
  /**
  * Creates a new StructuredOutputParser from a Zod schema.
  * @param schema The Zod schema which the output should match
  * @returns A new instance of StructuredOutputParser.
  */
  static fromZodSchema(schema) {
    return new this(schema);
  }
  /**
  * Creates a new StructuredOutputParser from a set of names and
  * descriptions.
  * @param schemas An object where each key is a name and each value is a description
  * @returns A new instance of StructuredOutputParser.
  */
  static fromNamesAndDescriptions(schemas) {
    const zodSchema = external_exports.object(Object.fromEntries(Object.entries(schemas).map(([name, description]) => [name, external_exports.string().describe(description)])));
    return new this(zodSchema);
  }
  /**
  * Returns a markdown code snippet with a JSON object formatted according
  * to the schema.
  * @param options Optional. The options for formatting the instructions
  * @returns A markdown code snippet with a JSON object formatted according to the schema.
  */
  getFormatInstructions() {
    return `You must format your output as a JSON value that adheres to a given "JSON Schema" instance.

"JSON Schema" is a declarative language that allows you to annotate and validate JSON documents.

For example, the example "JSON Schema" instance {{"properties": {{"foo": {{"description": "a list of test words", "type": "array", "items": {{"type": "string"}}}}}}, "required": ["foo"]}}
would match an object with one required property, "foo". The "type" property specifies "foo" must be an "array", and the "description" property semantically describes it as "a list of test words". The items within "foo" must be strings.
Thus, the object {{"foo": ["bar", "baz"]}} is a well-formatted instance of this example "JSON Schema". The object {{"properties": {{"foo": ["bar", "baz"]}}}} is not well-formatted.

Your output will be parsed and type-checked according to the provided schema instance, so make sure all fields in your output match the schema exactly and there are no trailing commas!

Here is the JSON Schema instance your output must adhere to. Include the enclosing markdown codeblock:
\`\`\`json
${JSON.stringify(toJsonSchema(this.schema))}
\`\`\`
`;
  }
  /**
  * Parses the given text according to the schema.
  * @param text The text to parse
  * @returns The parsed output.
  */
  async parse(text) {
    var _a2, _b;
    try {
      const trimmedText = text.trim();
      const json = ((_a2 = trimmedText.match(/^```(?:json)?\s*([\s\S]*?)```/)) == null ? void 0 : _a2[1]) || ((_b = trimmedText.match(/```json\s*([\s\S]*?)```/)) == null ? void 0 : _b[1]) || trimmedText;
      const escapedJson = json.replace(/"([^"\\]*(\\.[^"\\]*)*)"/g, (_match, capturedGroup) => {
        const escapedInsideQuotes = capturedGroup.replace(/\n/g, "\\n");
        return `"${escapedInsideQuotes}"`;
      }).replace(/\n/g, "");
      return await interopParseAsync(this.schema, JSON.parse(escapedJson));
    } catch (e) {
      throw new OutputParserException(`Failed to parse. Text: "${text}". Error: ${e}`, text);
    }
  }
};
var JsonMarkdownStructuredOutputParser = class extends StructuredOutputParser {
  static lc_name() {
    return "JsonMarkdownStructuredOutputParser";
  }
  getFormatInstructions(options) {
    const interpolationDepth = (options == null ? void 0 : options.interpolationDepth) ?? 1;
    if (interpolationDepth < 1) throw new Error("f string interpolation depth must be at least 1");
    return `Return a markdown code snippet with a JSON object formatted to look like:
\`\`\`json
${this._schemaToInstruction(toJsonSchema(this.schema)).replaceAll("{", "{".repeat(interpolationDepth)).replaceAll("}", "}".repeat(interpolationDepth))}
\`\`\``;
  }
  _schemaToInstruction(schemaInput, indent = 2) {
    const schema = schemaInput;
    if ("type" in schema) {
      let nullable = false;
      let type;
      if (Array.isArray(schema.type)) {
        const nullIdx = schema.type.findIndex((type$1) => type$1 === "null");
        if (nullIdx !== -1) {
          nullable = true;
          schema.type.splice(nullIdx, 1);
        }
        type = schema.type.join(" | ");
      } else type = schema.type;
      if (schema.type === "object" && schema.properties) {
        const description$1 = schema.description ? ` // ${schema.description}` : "";
        const properties = Object.entries(schema.properties).map(([key, value]) => {
          var _a2;
          const isOptional = ((_a2 = schema.required) == null ? void 0 : _a2.includes(key)) ? "" : " (optional)";
          return `${" ".repeat(indent)}"${key}": ${this._schemaToInstruction(value, indent + 2)}${isOptional}`;
        }).join("\n");
        return `{
${properties}
${" ".repeat(indent - 2)}}${description$1}`;
      }
      if (schema.type === "array" && schema.items) {
        const description$1 = schema.description ? ` // ${schema.description}` : "";
        return `array[
${" ".repeat(indent)}${this._schemaToInstruction(schema.items, indent + 2)}
${" ".repeat(indent - 2)}] ${description$1}`;
      }
      const isNullable = nullable ? " (nullable)" : "";
      const description = schema.description ? ` // ${schema.description}` : "";
      return `${type}${description}${isNullable}`;
    }
    if ("anyOf" in schema) return schema.anyOf.map((s) => this._schemaToInstruction(s, indent)).join(`
${" ".repeat(indent - 2)}`);
    throw new Error("unsupported schema type");
  }
  static fromZodSchema(schema) {
    return new this(schema);
  }
  static fromNamesAndDescriptions(schemas) {
    const zodSchema = external_exports.object(Object.fromEntries(Object.entries(schemas).map(([name, description]) => [name, external_exports.string().describe(description)])));
    return new this(zodSchema);
  }
};
var AsymmetricStructuredOutputParser = class extends BaseOutputParser {
  constructor({ inputSchema }) {
    super(...arguments);
    __publicField(this, "structuredInputParser");
    this.structuredInputParser = new JsonMarkdownStructuredOutputParser(inputSchema);
  }
  async parse(text) {
    let parsedInput;
    try {
      parsedInput = await this.structuredInputParser.parse(text);
    } catch (e) {
      throw new OutputParserException(`Failed to parse. Text: "${text}". Error: ${e}`, text);
    }
    return this.outputProcessor(parsedInput);
  }
  getFormatInstructions() {
    return this.structuredInputParser.getFormatInstructions();
  }
};

// node_modules/@langchain/core/dist/utils/json_patch.js
var json_patch_exports = {};
__export(json_patch_exports, {
  applyPatch: () => applyPatch,
  compare: () => compare
});

// node_modules/@langchain/core/dist/output_parsers/json.js
var JsonOutputParser = class extends BaseCumulativeTransformOutputParser {
  constructor() {
    super(...arguments);
    __publicField(this, "lc_namespace", ["langchain_core", "output_parsers"]);
    __publicField(this, "lc_serializable", true);
  }
  static lc_name() {
    return "JsonOutputParser";
  }
  /** @internal */
  _concatOutputChunks(first, second) {
    if (this.diff) return super._concatOutputChunks(first, second);
    return second;
  }
  _diff(prev, next) {
    if (!next) return void 0;
    if (!prev) return [{
      op: "replace",
      path: "",
      value: next
    }];
    return compare(prev, next);
  }
  async parsePartialResult(generations) {
    return parseJsonMarkdown(generations[0].text);
  }
  async parse(text) {
    return parseJsonMarkdown(text, JSON.parse);
  }
  getFormatInstructions() {
    return "";
  }
  /**
  * Extracts text content from a message for JSON parsing.
  * Uses the message's `.text` accessor which properly handles both
  * string content and ContentBlock[] arrays (extracting text from text blocks).
  * @param message The message to extract text from
  * @returns The text content of the message
  */
  _baseMessageToString(message) {
    return message.text;
  }
};

// node_modules/@langchain/core/dist/utils/sax-js/sax.js
var initializeSax = function() {
  const sax$1 = {};
  sax$1.parser = function(strict, opt) {
    return new SAXParser(strict, opt);
  };
  sax$1.SAXParser = SAXParser;
  sax$1.SAXStream = SAXStream;
  sax$1.createStream = createStream;
  sax$1.MAX_BUFFER_LENGTH = 64 * 1024;
  const buffers = [
    "comment",
    "sgmlDecl",
    "textNode",
    "tagName",
    "doctype",
    "procInstName",
    "procInstBody",
    "entity",
    "attribName",
    "attribValue",
    "cdata",
    "script"
  ];
  sax$1.EVENTS = [
    "text",
    "processinginstruction",
    "sgmldeclaration",
    "doctype",
    "comment",
    "opentagstart",
    "attribute",
    "opentag",
    "closetag",
    "opencdata",
    "cdata",
    "closecdata",
    "error",
    "end",
    "ready",
    "script",
    "opennamespace",
    "closenamespace"
  ];
  function SAXParser(strict, opt) {
    if (!(this instanceof SAXParser)) return new SAXParser(strict, opt);
    var parser = this;
    clearBuffers(parser);
    parser.q = parser.c = "";
    parser.bufferCheckPosition = sax$1.MAX_BUFFER_LENGTH;
    parser.opt = opt || {};
    parser.opt.lowercase = parser.opt.lowercase || parser.opt.lowercasetags;
    parser.looseCase = parser.opt.lowercase ? "toLowerCase" : "toUpperCase";
    parser.tags = [];
    parser.closed = parser.closedRoot = parser.sawRoot = false;
    parser.tag = parser.error = null;
    parser.strict = !!strict;
    parser.noscript = !!(strict || parser.opt.noscript);
    parser.state = S.BEGIN;
    parser.strictEntities = parser.opt.strictEntities;
    parser.ENTITIES = parser.strictEntities ? Object.create(sax$1.XML_ENTITIES) : Object.create(sax$1.ENTITIES);
    parser.attribList = [];
    if (parser.opt.xmlns) parser.ns = Object.create(rootNS);
    parser.trackPosition = parser.opt.position !== false;
    if (parser.trackPosition) parser.position = parser.line = parser.column = 0;
    emit(parser, "onready");
  }
  if (!Object.create) Object.create = function(o) {
    function F() {
    }
    F.prototype = o;
    var newf = new F();
    return newf;
  };
  if (!Object.keys) Object.keys = function(o) {
    var a = [];
    for (var i in o) if (o.hasOwnProperty(i)) a.push(i);
    return a;
  };
  function checkBufferLength(parser) {
    var maxAllowed = Math.max(sax$1.MAX_BUFFER_LENGTH, 10);
    var maxActual = 0;
    for (var i = 0, l = buffers.length; i < l; i++) {
      var len = parser[buffers[i]].length;
      if (len > maxAllowed) switch (buffers[i]) {
        case "textNode":
          closeText(parser);
          break;
        case "cdata":
          emitNode(parser, "oncdata", parser.cdata);
          parser.cdata = "";
          break;
        case "script":
          emitNode(parser, "onscript", parser.script);
          parser.script = "";
          break;
        default:
          error(parser, "Max buffer length exceeded: " + buffers[i]);
      }
      maxActual = Math.max(maxActual, len);
    }
    var m = sax$1.MAX_BUFFER_LENGTH - maxActual;
    parser.bufferCheckPosition = m + parser.position;
  }
  function clearBuffers(parser) {
    for (var i = 0, l = buffers.length; i < l; i++) parser[buffers[i]] = "";
  }
  function flushBuffers(parser) {
    closeText(parser);
    if (parser.cdata !== "") {
      emitNode(parser, "oncdata", parser.cdata);
      parser.cdata = "";
    }
    if (parser.script !== "") {
      emitNode(parser, "onscript", parser.script);
      parser.script = "";
    }
  }
  SAXParser.prototype = {
    end: function() {
      end(this);
    },
    write,
    resume: function() {
      this.error = null;
      return this;
    },
    close: function() {
      return this.write(null);
    },
    flush: function() {
      flushBuffers(this);
    }
  };
  var Stream2 = ReadableStream;
  if (!Stream2) Stream2 = function() {
  };
  var streamWraps = sax$1.EVENTS.filter(function(ev) {
    return ev !== "error" && ev !== "end";
  });
  function createStream(strict, opt) {
    return new SAXStream(strict, opt);
  }
  function SAXStream(strict, opt) {
    if (!(this instanceof SAXStream)) return new SAXStream(strict, opt);
    Stream2.apply(this);
    this._parser = new SAXParser(strict, opt);
    this.writable = true;
    this.readable = true;
    var me = this;
    this._parser.onend = function() {
      me.emit("end");
    };
    this._parser.onerror = function(er) {
      me.emit("error", er);
      me._parser.error = null;
    };
    this._decoder = null;
    streamWraps.forEach(function(ev) {
      Object.defineProperty(me, "on" + ev, {
        get: function() {
          return me._parser["on" + ev];
        },
        set: function(h) {
          if (!h) {
            me.removeAllListeners(ev);
            me._parser["on" + ev] = h;
            return h;
          }
          me.on(ev, h);
        },
        enumerable: true,
        configurable: false
      });
    });
  }
  SAXStream.prototype = Object.create(Stream2.prototype, { constructor: { value: SAXStream } });
  SAXStream.prototype.write = function(data) {
    this._parser.write(data.toString());
    this.emit("data", data);
    return true;
  };
  SAXStream.prototype.end = function(chunk) {
    if (chunk && chunk.length) this.write(chunk);
    this._parser.end();
    return true;
  };
  SAXStream.prototype.on = function(ev, handler) {
    var me = this;
    if (!me._parser["on" + ev] && streamWraps.indexOf(ev) !== -1) me._parser["on" + ev] = function() {
      var args = arguments.length === 1 ? [arguments[0]] : Array.apply(null, arguments);
      args.splice(0, 0, ev);
      me.emit.apply(me, args);
    };
    return Stream2.prototype.on.call(me, ev, handler);
  };
  var CDATA = "[CDATA[";
  var DOCTYPE = "DOCTYPE";
  var XML_NAMESPACE = "http://www.w3.org/XML/1998/namespace";
  var XMLNS_NAMESPACE = "http://www.w3.org/2000/xmlns/";
  var rootNS = {
    xml: XML_NAMESPACE,
    xmlns: XMLNS_NAMESPACE
  };
  var nameStart = /[:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD]/;
  var nameBody = /[:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\u00B7\u0300-\u036F\u203F-\u2040.\d-]/;
  var entityStart = /[#:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD]/;
  var entityBody = /[#:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\u00B7\u0300-\u036F\u203F-\u2040.\d-]/;
  function isWhitespace(c) {
    return c === " " || c === "\n" || c === "\r" || c === "	";
  }
  function isQuote(c) {
    return c === '"' || c === "'";
  }
  function isAttribEnd(c) {
    return c === ">" || isWhitespace(c);
  }
  function isMatch(regex, c) {
    return regex.test(c);
  }
  function notMatch(regex, c) {
    return !isMatch(regex, c);
  }
  var S = 0;
  sax$1.STATE = {
    BEGIN: S++,
    BEGIN_WHITESPACE: S++,
    TEXT: S++,
    TEXT_ENTITY: S++,
    OPEN_WAKA: S++,
    SGML_DECL: S++,
    SGML_DECL_QUOTED: S++,
    DOCTYPE: S++,
    DOCTYPE_QUOTED: S++,
    DOCTYPE_DTD: S++,
    DOCTYPE_DTD_QUOTED: S++,
    COMMENT_STARTING: S++,
    COMMENT: S++,
    COMMENT_ENDING: S++,
    COMMENT_ENDED: S++,
    CDATA: S++,
    CDATA_ENDING: S++,
    CDATA_ENDING_2: S++,
    PROC_INST: S++,
    PROC_INST_BODY: S++,
    PROC_INST_ENDING: S++,
    OPEN_TAG: S++,
    OPEN_TAG_SLASH: S++,
    ATTRIB: S++,
    ATTRIB_NAME: S++,
    ATTRIB_NAME_SAW_WHITE: S++,
    ATTRIB_VALUE: S++,
    ATTRIB_VALUE_QUOTED: S++,
    ATTRIB_VALUE_CLOSED: S++,
    ATTRIB_VALUE_UNQUOTED: S++,
    ATTRIB_VALUE_ENTITY_Q: S++,
    ATTRIB_VALUE_ENTITY_U: S++,
    CLOSE_TAG: S++,
    CLOSE_TAG_SAW_WHITE: S++,
    SCRIPT: S++,
    SCRIPT_ENDING: S++
  };
  sax$1.XML_ENTITIES = {
    amp: "&",
    gt: ">",
    lt: "<",
    quot: '"',
    apos: "'"
  };
  sax$1.ENTITIES = {
    amp: "&",
    gt: ">",
    lt: "<",
    quot: '"',
    apos: "'",
    AElig: 198,
    Aacute: 193,
    Acirc: 194,
    Agrave: 192,
    Aring: 197,
    Atilde: 195,
    Auml: 196,
    Ccedil: 199,
    ETH: 208,
    Eacute: 201,
    Ecirc: 202,
    Egrave: 200,
    Euml: 203,
    Iacute: 205,
    Icirc: 206,
    Igrave: 204,
    Iuml: 207,
    Ntilde: 209,
    Oacute: 211,
    Ocirc: 212,
    Ograve: 210,
    Oslash: 216,
    Otilde: 213,
    Ouml: 214,
    THORN: 222,
    Uacute: 218,
    Ucirc: 219,
    Ugrave: 217,
    Uuml: 220,
    Yacute: 221,
    aacute: 225,
    acirc: 226,
    aelig: 230,
    agrave: 224,
    aring: 229,
    atilde: 227,
    auml: 228,
    ccedil: 231,
    eacute: 233,
    ecirc: 234,
    egrave: 232,
    eth: 240,
    euml: 235,
    iacute: 237,
    icirc: 238,
    igrave: 236,
    iuml: 239,
    ntilde: 241,
    oacute: 243,
    ocirc: 244,
    ograve: 242,
    oslash: 248,
    otilde: 245,
    ouml: 246,
    szlig: 223,
    thorn: 254,
    uacute: 250,
    ucirc: 251,
    ugrave: 249,
    uuml: 252,
    yacute: 253,
    yuml: 255,
    copy: 169,
    reg: 174,
    nbsp: 160,
    iexcl: 161,
    cent: 162,
    pound: 163,
    curren: 164,
    yen: 165,
    brvbar: 166,
    sect: 167,
    uml: 168,
    ordf: 170,
    laquo: 171,
    not: 172,
    shy: 173,
    macr: 175,
    deg: 176,
    plusmn: 177,
    sup1: 185,
    sup2: 178,
    sup3: 179,
    acute: 180,
    micro: 181,
    para: 182,
    middot: 183,
    cedil: 184,
    ordm: 186,
    raquo: 187,
    frac14: 188,
    frac12: 189,
    frac34: 190,
    iquest: 191,
    times: 215,
    divide: 247,
    OElig: 338,
    oelig: 339,
    Scaron: 352,
    scaron: 353,
    Yuml: 376,
    fnof: 402,
    circ: 710,
    tilde: 732,
    Alpha: 913,
    Beta: 914,
    Gamma: 915,
    Delta: 916,
    Epsilon: 917,
    Zeta: 918,
    Eta: 919,
    Theta: 920,
    Iota: 921,
    Kappa: 922,
    Lambda: 923,
    Mu: 924,
    Nu: 925,
    Xi: 926,
    Omicron: 927,
    Pi: 928,
    Rho: 929,
    Sigma: 931,
    Tau: 932,
    Upsilon: 933,
    Phi: 934,
    Chi: 935,
    Psi: 936,
    Omega: 937,
    alpha: 945,
    beta: 946,
    gamma: 947,
    delta: 948,
    epsilon: 949,
    zeta: 950,
    eta: 951,
    theta: 952,
    iota: 953,
    kappa: 954,
    lambda: 955,
    mu: 956,
    nu: 957,
    xi: 958,
    omicron: 959,
    pi: 960,
    rho: 961,
    sigmaf: 962,
    sigma: 963,
    tau: 964,
    upsilon: 965,
    phi: 966,
    chi: 967,
    psi: 968,
    omega: 969,
    thetasym: 977,
    upsih: 978,
    piv: 982,
    ensp: 8194,
    emsp: 8195,
    thinsp: 8201,
    zwnj: 8204,
    zwj: 8205,
    lrm: 8206,
    rlm: 8207,
    ndash: 8211,
    mdash: 8212,
    lsquo: 8216,
    rsquo: 8217,
    sbquo: 8218,
    ldquo: 8220,
    rdquo: 8221,
    bdquo: 8222,
    dagger: 8224,
    Dagger: 8225,
    bull: 8226,
    hellip: 8230,
    permil: 8240,
    prime: 8242,
    Prime: 8243,
    lsaquo: 8249,
    rsaquo: 8250,
    oline: 8254,
    frasl: 8260,
    euro: 8364,
    image: 8465,
    weierp: 8472,
    real: 8476,
    trade: 8482,
    alefsym: 8501,
    larr: 8592,
    uarr: 8593,
    rarr: 8594,
    darr: 8595,
    harr: 8596,
    crarr: 8629,
    lArr: 8656,
    uArr: 8657,
    rArr: 8658,
    dArr: 8659,
    hArr: 8660,
    forall: 8704,
    part: 8706,
    exist: 8707,
    empty: 8709,
    nabla: 8711,
    isin: 8712,
    notin: 8713,
    ni: 8715,
    prod: 8719,
    sum: 8721,
    minus: 8722,
    lowast: 8727,
    radic: 8730,
    prop: 8733,
    infin: 8734,
    ang: 8736,
    and: 8743,
    or: 8744,
    cap: 8745,
    cup: 8746,
    int: 8747,
    there4: 8756,
    sim: 8764,
    cong: 8773,
    asymp: 8776,
    ne: 8800,
    equiv: 8801,
    le: 8804,
    ge: 8805,
    sub: 8834,
    sup: 8835,
    nsub: 8836,
    sube: 8838,
    supe: 8839,
    oplus: 8853,
    otimes: 8855,
    perp: 8869,
    sdot: 8901,
    lceil: 8968,
    rceil: 8969,
    lfloor: 8970,
    rfloor: 8971,
    lang: 9001,
    rang: 9002,
    loz: 9674,
    spades: 9824,
    clubs: 9827,
    hearts: 9829,
    diams: 9830
  };
  Object.keys(sax$1.ENTITIES).forEach(function(key) {
    var e = sax$1.ENTITIES[key];
    var s$1 = typeof e === "number" ? String.fromCharCode(e) : e;
    sax$1.ENTITIES[key] = s$1;
  });
  for (var s in sax$1.STATE) sax$1.STATE[sax$1.STATE[s]] = s;
  S = sax$1.STATE;
  function emit(parser, event, data) {
    parser[event] && parser[event](data);
  }
  function emitNode(parser, nodeType, data) {
    if (parser.textNode) closeText(parser);
    emit(parser, nodeType, data);
  }
  function closeText(parser) {
    parser.textNode = textopts(parser.opt, parser.textNode);
    if (parser.textNode) emit(parser, "ontext", parser.textNode);
    parser.textNode = "";
  }
  function textopts(opt, text) {
    if (opt.trim) text = text.trim();
    if (opt.normalize) text = text.replace(/\s+/g, " ");
    return text;
  }
  function error(parser, er) {
    closeText(parser);
    if (parser.trackPosition) er += "\nLine: " + parser.line + "\nColumn: " + parser.column + "\nChar: " + parser.c;
    er = new Error(er);
    parser.error = er;
    emit(parser, "onerror", er);
    return parser;
  }
  function end(parser) {
    if (parser.sawRoot && !parser.closedRoot) strictFail(parser, "Unclosed root tag");
    if (parser.state !== S.BEGIN && parser.state !== S.BEGIN_WHITESPACE && parser.state !== S.TEXT) error(parser, "Unexpected end");
    closeText(parser);
    parser.c = "";
    parser.closed = true;
    emit(parser, "onend");
    SAXParser.call(parser, parser.strict, parser.opt);
    return parser;
  }
  function strictFail(parser, message) {
    if (typeof parser !== "object" || !(parser instanceof SAXParser)) throw new Error("bad call to strictFail");
    if (parser.strict) error(parser, message);
  }
  function newTag(parser) {
    if (!parser.strict) parser.tagName = parser.tagName[parser.looseCase]();
    var parent = parser.tags[parser.tags.length - 1] || parser;
    var tag = parser.tag = {
      name: parser.tagName,
      attributes: {}
    };
    if (parser.opt.xmlns) tag.ns = parent.ns;
    parser.attribList.length = 0;
    emitNode(parser, "onopentagstart", tag);
  }
  function qname(name, attribute) {
    var i = name.indexOf(":");
    var qualName = i < 0 ? ["", name] : name.split(":");
    var prefix = qualName[0];
    var local = qualName[1];
    if (attribute && name === "xmlns") {
      prefix = "xmlns";
      local = "";
    }
    return {
      prefix,
      local
    };
  }
  function attrib(parser) {
    if (!parser.strict) parser.attribName = parser.attribName[parser.looseCase]();
    if (parser.attribList.indexOf(parser.attribName) !== -1 || parser.tag.attributes.hasOwnProperty(parser.attribName)) {
      parser.attribName = parser.attribValue = "";
      return;
    }
    if (parser.opt.xmlns) {
      var qn = qname(parser.attribName, true);
      var prefix = qn.prefix;
      var local = qn.local;
      if (prefix === "xmlns") if (local === "xml" && parser.attribValue !== XML_NAMESPACE) strictFail(parser, "xml: prefix must be bound to " + XML_NAMESPACE + "\nActual: " + parser.attribValue);
      else if (local === "xmlns" && parser.attribValue !== XMLNS_NAMESPACE) strictFail(parser, "xmlns: prefix must be bound to " + XMLNS_NAMESPACE + "\nActual: " + parser.attribValue);
      else {
        var tag = parser.tag;
        var parent = parser.tags[parser.tags.length - 1] || parser;
        if (tag.ns === parent.ns) tag.ns = Object.create(parent.ns);
        tag.ns[local] = parser.attribValue;
      }
      parser.attribList.push([parser.attribName, parser.attribValue]);
    } else {
      parser.tag.attributes[parser.attribName] = parser.attribValue;
      emitNode(parser, "onattribute", {
        name: parser.attribName,
        value: parser.attribValue
      });
    }
    parser.attribName = parser.attribValue = "";
  }
  function openTag(parser, selfClosing) {
    if (parser.opt.xmlns) {
      var tag = parser.tag;
      var qn = qname(parser.tagName);
      tag.prefix = qn.prefix;
      tag.local = qn.local;
      tag.uri = tag.ns[qn.prefix] || "";
      if (tag.prefix && !tag.uri) {
        strictFail(parser, "Unbound namespace prefix: " + JSON.stringify(parser.tagName));
        tag.uri = qn.prefix;
      }
      var parent = parser.tags[parser.tags.length - 1] || parser;
      if (tag.ns && parent.ns !== tag.ns) Object.keys(tag.ns).forEach(function(p) {
        emitNode(parser, "onopennamespace", {
          prefix: p,
          uri: tag.ns[p]
        });
      });
      for (var i = 0, l = parser.attribList.length; i < l; i++) {
        var nv = parser.attribList[i];
        var name = nv[0];
        var value = nv[1];
        var qualName = qname(name, true);
        var prefix = qualName.prefix;
        var local = qualName.local;
        var uri = prefix === "" ? "" : tag.ns[prefix] || "";
        var a = {
          name,
          value,
          prefix,
          local,
          uri
        };
        if (prefix && prefix !== "xmlns" && !uri) {
          strictFail(parser, "Unbound namespace prefix: " + JSON.stringify(prefix));
          a.uri = prefix;
        }
        parser.tag.attributes[name] = a;
        emitNode(parser, "onattribute", a);
      }
      parser.attribList.length = 0;
    }
    parser.tag.isSelfClosing = !!selfClosing;
    parser.sawRoot = true;
    parser.tags.push(parser.tag);
    emitNode(parser, "onopentag", parser.tag);
    if (!selfClosing) {
      if (!parser.noscript && parser.tagName.toLowerCase() === "script") parser.state = S.SCRIPT;
      else parser.state = S.TEXT;
      parser.tag = null;
      parser.tagName = "";
    }
    parser.attribName = parser.attribValue = "";
    parser.attribList.length = 0;
  }
  function closeTag(parser) {
    if (!parser.tagName) {
      strictFail(parser, "Weird empty close tag.");
      parser.textNode += "</>";
      parser.state = S.TEXT;
      return;
    }
    if (parser.script) {
      if (parser.tagName !== "script") {
        parser.script += "</" + parser.tagName + ">";
        parser.tagName = "";
        parser.state = S.SCRIPT;
        return;
      }
      emitNode(parser, "onscript", parser.script);
      parser.script = "";
    }
    var t = parser.tags.length;
    var tagName = parser.tagName;
    if (!parser.strict) tagName = tagName[parser.looseCase]();
    var closeTo = tagName;
    while (t--) {
      var close = parser.tags[t];
      if (close.name !== closeTo) strictFail(parser, "Unexpected close tag");
      else break;
    }
    if (t < 0) {
      strictFail(parser, "Unmatched closing tag: " + parser.tagName);
      parser.textNode += "</" + parser.tagName + ">";
      parser.state = S.TEXT;
      return;
    }
    parser.tagName = tagName;
    var s$1 = parser.tags.length;
    while (s$1-- > t) {
      var tag = parser.tag = parser.tags.pop();
      parser.tagName = parser.tag.name;
      emitNode(parser, "onclosetag", parser.tagName);
      var x = {};
      for (var i in tag.ns) x[i] = tag.ns[i];
      var parent = parser.tags[parser.tags.length - 1] || parser;
      if (parser.opt.xmlns && tag.ns !== parent.ns) Object.keys(tag.ns).forEach(function(p) {
        var n = tag.ns[p];
        emitNode(parser, "onclosenamespace", {
          prefix: p,
          uri: n
        });
      });
    }
    if (t === 0) parser.closedRoot = true;
    parser.tagName = parser.attribValue = parser.attribName = "";
    parser.attribList.length = 0;
    parser.state = S.TEXT;
  }
  function parseEntity(parser) {
    var entity = parser.entity;
    var entityLC = entity.toLowerCase();
    var num;
    var numStr = "";
    if (parser.ENTITIES[entity]) return parser.ENTITIES[entity];
    if (parser.ENTITIES[entityLC]) return parser.ENTITIES[entityLC];
    entity = entityLC;
    if (entity.charAt(0) === "#") if (entity.charAt(1) === "x") {
      entity = entity.slice(2);
      num = parseInt(entity, 16);
      numStr = num.toString(16);
    } else {
      entity = entity.slice(1);
      num = parseInt(entity, 10);
      numStr = num.toString(10);
    }
    entity = entity.replace(/^0+/, "");
    if (isNaN(num) || numStr.toLowerCase() !== entity) {
      strictFail(parser, "Invalid character entity");
      return "&" + parser.entity + ";";
    }
    return String.fromCodePoint(num);
  }
  function beginWhiteSpace(parser, c) {
    if (c === "<") {
      parser.state = S.OPEN_WAKA;
      parser.startTagPosition = parser.position;
    } else if (!isWhitespace(c)) {
      strictFail(parser, "Non-whitespace before first tag.");
      parser.textNode = c;
      parser.state = S.TEXT;
    }
  }
  function charAt(chunk, i) {
    var result = "";
    if (i < chunk.length) result = chunk.charAt(i);
    return result;
  }
  function write(chunk) {
    var parser = this;
    if (this.error) throw this.error;
    if (parser.closed) return error(parser, "Cannot write after close. Assign an onready handler.");
    if (chunk === null) return end(parser);
    if (typeof chunk === "object") chunk = chunk.toString();
    var i = 0;
    var c = "";
    while (true) {
      c = charAt(chunk, i++);
      parser.c = c;
      if (!c) break;
      if (parser.trackPosition) {
        parser.position++;
        if (c === "\n") {
          parser.line++;
          parser.column = 0;
        } else parser.column++;
      }
      switch (parser.state) {
        case S.BEGIN:
          parser.state = S.BEGIN_WHITESPACE;
          if (c === "\uFEFF") continue;
          beginWhiteSpace(parser, c);
          continue;
        case S.BEGIN_WHITESPACE:
          beginWhiteSpace(parser, c);
          continue;
        case S.TEXT:
          if (parser.sawRoot && !parser.closedRoot) {
            var starti = i - 1;
            while (c && c !== "<" && c !== "&") {
              c = charAt(chunk, i++);
              if (c && parser.trackPosition) {
                parser.position++;
                if (c === "\n") {
                  parser.line++;
                  parser.column = 0;
                } else parser.column++;
              }
            }
            parser.textNode += chunk.substring(starti, i - 1);
          }
          if (c === "<" && !(parser.sawRoot && parser.closedRoot && !parser.strict)) {
            parser.state = S.OPEN_WAKA;
            parser.startTagPosition = parser.position;
          } else {
            if (!isWhitespace(c) && (!parser.sawRoot || parser.closedRoot)) strictFail(parser, "Text data outside of root node.");
            if (c === "&") parser.state = S.TEXT_ENTITY;
            else parser.textNode += c;
          }
          continue;
        case S.SCRIPT:
          if (c === "<") parser.state = S.SCRIPT_ENDING;
          else parser.script += c;
          continue;
        case S.SCRIPT_ENDING:
          if (c === "/") parser.state = S.CLOSE_TAG;
          else {
            parser.script += "<" + c;
            parser.state = S.SCRIPT;
          }
          continue;
        case S.OPEN_WAKA:
          if (c === "!") {
            parser.state = S.SGML_DECL;
            parser.sgmlDecl = "";
          } else if (isWhitespace(c)) {
          } else if (isMatch(nameStart, c)) {
            parser.state = S.OPEN_TAG;
            parser.tagName = c;
          } else if (c === "/") {
            parser.state = S.CLOSE_TAG;
            parser.tagName = "";
          } else if (c === "?") {
            parser.state = S.PROC_INST;
            parser.procInstName = parser.procInstBody = "";
          } else {
            strictFail(parser, "Unencoded <");
            if (parser.startTagPosition + 1 < parser.position) {
              var pad = parser.position - parser.startTagPosition;
              c = new Array(pad).join(" ") + c;
            }
            parser.textNode += "<" + c;
            parser.state = S.TEXT;
          }
          continue;
        case S.SGML_DECL:
          if ((parser.sgmlDecl + c).toUpperCase() === CDATA) {
            emitNode(parser, "onopencdata");
            parser.state = S.CDATA;
            parser.sgmlDecl = "";
            parser.cdata = "";
          } else if (parser.sgmlDecl + c === "--") {
            parser.state = S.COMMENT;
            parser.comment = "";
            parser.sgmlDecl = "";
          } else if ((parser.sgmlDecl + c).toUpperCase() === DOCTYPE) {
            parser.state = S.DOCTYPE;
            if (parser.doctype || parser.sawRoot) strictFail(parser, "Inappropriately located doctype declaration");
            parser.doctype = "";
            parser.sgmlDecl = "";
          } else if (c === ">") {
            emitNode(parser, "onsgmldeclaration", parser.sgmlDecl);
            parser.sgmlDecl = "";
            parser.state = S.TEXT;
          } else if (isQuote(c)) {
            parser.state = S.SGML_DECL_QUOTED;
            parser.sgmlDecl += c;
          } else parser.sgmlDecl += c;
          continue;
        case S.SGML_DECL_QUOTED:
          if (c === parser.q) {
            parser.state = S.SGML_DECL;
            parser.q = "";
          }
          parser.sgmlDecl += c;
          continue;
        case S.DOCTYPE:
          if (c === ">") {
            parser.state = S.TEXT;
            emitNode(parser, "ondoctype", parser.doctype);
            parser.doctype = true;
          } else {
            parser.doctype += c;
            if (c === "[") parser.state = S.DOCTYPE_DTD;
            else if (isQuote(c)) {
              parser.state = S.DOCTYPE_QUOTED;
              parser.q = c;
            }
          }
          continue;
        case S.DOCTYPE_QUOTED:
          parser.doctype += c;
          if (c === parser.q) {
            parser.q = "";
            parser.state = S.DOCTYPE;
          }
          continue;
        case S.DOCTYPE_DTD:
          parser.doctype += c;
          if (c === "]") parser.state = S.DOCTYPE;
          else if (isQuote(c)) {
            parser.state = S.DOCTYPE_DTD_QUOTED;
            parser.q = c;
          }
          continue;
        case S.DOCTYPE_DTD_QUOTED:
          parser.doctype += c;
          if (c === parser.q) {
            parser.state = S.DOCTYPE_DTD;
            parser.q = "";
          }
          continue;
        case S.COMMENT:
          if (c === "-") parser.state = S.COMMENT_ENDING;
          else parser.comment += c;
          continue;
        case S.COMMENT_ENDING:
          if (c === "-") {
            parser.state = S.COMMENT_ENDED;
            parser.comment = textopts(parser.opt, parser.comment);
            if (parser.comment) emitNode(parser, "oncomment", parser.comment);
            parser.comment = "";
          } else {
            parser.comment += "-" + c;
            parser.state = S.COMMENT;
          }
          continue;
        case S.COMMENT_ENDED:
          if (c !== ">") {
            strictFail(parser, "Malformed comment");
            parser.comment += "--" + c;
            parser.state = S.COMMENT;
          } else parser.state = S.TEXT;
          continue;
        case S.CDATA:
          if (c === "]") parser.state = S.CDATA_ENDING;
          else parser.cdata += c;
          continue;
        case S.CDATA_ENDING:
          if (c === "]") parser.state = S.CDATA_ENDING_2;
          else {
            parser.cdata += "]" + c;
            parser.state = S.CDATA;
          }
          continue;
        case S.CDATA_ENDING_2:
          if (c === ">") {
            if (parser.cdata) emitNode(parser, "oncdata", parser.cdata);
            emitNode(parser, "onclosecdata");
            parser.cdata = "";
            parser.state = S.TEXT;
          } else if (c === "]") parser.cdata += "]";
          else {
            parser.cdata += "]]" + c;
            parser.state = S.CDATA;
          }
          continue;
        case S.PROC_INST:
          if (c === "?") parser.state = S.PROC_INST_ENDING;
          else if (isWhitespace(c)) parser.state = S.PROC_INST_BODY;
          else parser.procInstName += c;
          continue;
        case S.PROC_INST_BODY:
          if (!parser.procInstBody && isWhitespace(c)) continue;
          else if (c === "?") parser.state = S.PROC_INST_ENDING;
          else parser.procInstBody += c;
          continue;
        case S.PROC_INST_ENDING:
          if (c === ">") {
            emitNode(parser, "onprocessinginstruction", {
              name: parser.procInstName,
              body: parser.procInstBody
            });
            parser.procInstName = parser.procInstBody = "";
            parser.state = S.TEXT;
          } else {
            parser.procInstBody += "?" + c;
            parser.state = S.PROC_INST_BODY;
          }
          continue;
        case S.OPEN_TAG:
          if (isMatch(nameBody, c)) parser.tagName += c;
          else {
            newTag(parser);
            if (c === ">") openTag(parser);
            else if (c === "/") parser.state = S.OPEN_TAG_SLASH;
            else {
              if (!isWhitespace(c)) strictFail(parser, "Invalid character in tag name");
              parser.state = S.ATTRIB;
            }
          }
          continue;
        case S.OPEN_TAG_SLASH:
          if (c === ">") {
            openTag(parser, true);
            closeTag(parser);
          } else {
            strictFail(parser, "Forward-slash in opening tag not followed by >");
            parser.state = S.ATTRIB;
          }
          continue;
        case S.ATTRIB:
          if (isWhitespace(c)) continue;
          else if (c === ">") openTag(parser);
          else if (c === "/") parser.state = S.OPEN_TAG_SLASH;
          else if (isMatch(nameStart, c)) {
            parser.attribName = c;
            parser.attribValue = "";
            parser.state = S.ATTRIB_NAME;
          } else strictFail(parser, "Invalid attribute name");
          continue;
        case S.ATTRIB_NAME:
          if (c === "=") parser.state = S.ATTRIB_VALUE;
          else if (c === ">") {
            strictFail(parser, "Attribute without value");
            parser.attribValue = parser.attribName;
            attrib(parser);
            openTag(parser);
          } else if (isWhitespace(c)) parser.state = S.ATTRIB_NAME_SAW_WHITE;
          else if (isMatch(nameBody, c)) parser.attribName += c;
          else strictFail(parser, "Invalid attribute name");
          continue;
        case S.ATTRIB_NAME_SAW_WHITE:
          if (c === "=") parser.state = S.ATTRIB_VALUE;
          else if (isWhitespace(c)) continue;
          else {
            strictFail(parser, "Attribute without value");
            parser.tag.attributes[parser.attribName] = "";
            parser.attribValue = "";
            emitNode(parser, "onattribute", {
              name: parser.attribName,
              value: ""
            });
            parser.attribName = "";
            if (c === ">") openTag(parser);
            else if (isMatch(nameStart, c)) {
              parser.attribName = c;
              parser.state = S.ATTRIB_NAME;
            } else {
              strictFail(parser, "Invalid attribute name");
              parser.state = S.ATTRIB;
            }
          }
          continue;
        case S.ATTRIB_VALUE:
          if (isWhitespace(c)) continue;
          else if (isQuote(c)) {
            parser.q = c;
            parser.state = S.ATTRIB_VALUE_QUOTED;
          } else {
            strictFail(parser, "Unquoted attribute value");
            parser.state = S.ATTRIB_VALUE_UNQUOTED;
            parser.attribValue = c;
          }
          continue;
        case S.ATTRIB_VALUE_QUOTED:
          if (c !== parser.q) {
            if (c === "&") parser.state = S.ATTRIB_VALUE_ENTITY_Q;
            else parser.attribValue += c;
            continue;
          }
          attrib(parser);
          parser.q = "";
          parser.state = S.ATTRIB_VALUE_CLOSED;
          continue;
        case S.ATTRIB_VALUE_CLOSED:
          if (isWhitespace(c)) parser.state = S.ATTRIB;
          else if (c === ">") openTag(parser);
          else if (c === "/") parser.state = S.OPEN_TAG_SLASH;
          else if (isMatch(nameStart, c)) {
            strictFail(parser, "No whitespace between attributes");
            parser.attribName = c;
            parser.attribValue = "";
            parser.state = S.ATTRIB_NAME;
          } else strictFail(parser, "Invalid attribute name");
          continue;
        case S.ATTRIB_VALUE_UNQUOTED:
          if (!isAttribEnd(c)) {
            if (c === "&") parser.state = S.ATTRIB_VALUE_ENTITY_U;
            else parser.attribValue += c;
            continue;
          }
          attrib(parser);
          if (c === ">") openTag(parser);
          else parser.state = S.ATTRIB;
          continue;
        case S.CLOSE_TAG:
          if (!parser.tagName) if (isWhitespace(c)) continue;
          else if (notMatch(nameStart, c)) if (parser.script) {
            parser.script += "</" + c;
            parser.state = S.SCRIPT;
          } else strictFail(parser, "Invalid tagname in closing tag.");
          else parser.tagName = c;
          else if (c === ">") closeTag(parser);
          else if (isMatch(nameBody, c)) parser.tagName += c;
          else if (parser.script) {
            parser.script += "</" + parser.tagName;
            parser.tagName = "";
            parser.state = S.SCRIPT;
          } else {
            if (!isWhitespace(c)) strictFail(parser, "Invalid tagname in closing tag");
            parser.state = S.CLOSE_TAG_SAW_WHITE;
          }
          continue;
        case S.CLOSE_TAG_SAW_WHITE:
          if (isWhitespace(c)) continue;
          if (c === ">") closeTag(parser);
          else strictFail(parser, "Invalid characters in closing tag");
          continue;
        case S.TEXT_ENTITY:
        case S.ATTRIB_VALUE_ENTITY_Q:
        case S.ATTRIB_VALUE_ENTITY_U:
          var returnState;
          var buffer;
          switch (parser.state) {
            case S.TEXT_ENTITY:
              returnState = S.TEXT;
              buffer = "textNode";
              break;
            case S.ATTRIB_VALUE_ENTITY_Q:
              returnState = S.ATTRIB_VALUE_QUOTED;
              buffer = "attribValue";
              break;
            case S.ATTRIB_VALUE_ENTITY_U:
              returnState = S.ATTRIB_VALUE_UNQUOTED;
              buffer = "attribValue";
              break;
          }
          if (c === ";") if (parser.opt.unparsedEntities) {
            var parsedEntity = parseEntity(parser);
            parser.entity = "";
            parser.state = returnState;
            parser.write(parsedEntity);
          } else {
            parser[buffer] += parseEntity(parser);
            parser.entity = "";
            parser.state = returnState;
          }
          else if (isMatch(parser.entity.length ? entityBody : entityStart, c)) parser.entity += c;
          else {
            strictFail(parser, "Invalid character in entity name");
            parser[buffer] += "&" + parser.entity + c;
            parser.entity = "";
            parser.state = returnState;
          }
          continue;
        default:
          throw new Error(parser, "Unknown state: " + parser.state);
      }
    }
    if (parser.position >= parser.bufferCheckPosition) checkBufferLength(parser);
    return parser;
  }
  if (!String.fromCodePoint) (function() {
    var stringFromCharCode = String.fromCharCode;
    var floor = Math.floor;
    var fromCodePoint = function() {
      var MAX_SIZE = 16384;
      var codeUnits = [];
      var highSurrogate;
      var lowSurrogate;
      var index = -1;
      var length = arguments.length;
      if (!length) return "";
      var result = "";
      while (++index < length) {
        var codePoint = Number(arguments[index]);
        if (!isFinite(codePoint) || codePoint < 0 || codePoint > 1114111 || floor(codePoint) !== codePoint) throw RangeError("Invalid code point: " + codePoint);
        if (codePoint <= 65535) codeUnits.push(codePoint);
        else {
          codePoint -= 65536;
          highSurrogate = (codePoint >> 10) + 55296;
          lowSurrogate = codePoint % 1024 + 56320;
          codeUnits.push(highSurrogate, lowSurrogate);
        }
        if (index + 1 === length || codeUnits.length > MAX_SIZE) {
          result += stringFromCharCode.apply(null, codeUnits);
          codeUnits.length = 0;
        }
      }
      return result;
    };
    if (Object.defineProperty) Object.defineProperty(String, "fromCodePoint", {
      value: fromCodePoint,
      configurable: true,
      writable: true
    });
    else String.fromCodePoint = fromCodePoint;
  })();
  return sax$1;
};
var sax = initializeSax();

// node_modules/@langchain/core/dist/output_parsers/xml.js
var XML_FORMAT_INSTRUCTIONS = `The output should be formatted as a XML file.
1. Output should conform to the tags below. 
2. If tags are not given, make them on your own.
3. Remember to always open and close all the tags.

As an example, for the tags ["foo", "bar", "baz"]:
1. String "<foo>
   <bar>
      <baz></baz>
   </bar>
</foo>" is a well-formatted instance of the schema. 
2. String "<foo>
   <bar>
   </foo>" is a badly-formatted instance.
3. String "<foo>
   <tag>
   </tag>
</foo>" is a badly-formatted instance.

Here are the output tags:
\`\`\`
{tags}
\`\`\``;
var XMLOutputParser = class extends BaseCumulativeTransformOutputParser {
  constructor(fields) {
    super(fields);
    __publicField(this, "tags");
    __publicField(this, "lc_namespace", ["langchain_core", "output_parsers"]);
    __publicField(this, "lc_serializable", true);
    this.tags = fields == null ? void 0 : fields.tags;
  }
  static lc_name() {
    return "XMLOutputParser";
  }
  _diff(prev, next) {
    if (!next) return void 0;
    if (!prev) return [{
      op: "replace",
      path: "",
      value: next
    }];
    return compare(prev, next);
  }
  async parsePartialResult(generations) {
    return parseXMLMarkdown(generations[0].text);
  }
  async parse(text) {
    return parseXMLMarkdown(text);
  }
  getFormatInstructions() {
    var _a2;
    const withTags = !!(this.tags && this.tags.length > 0);
    return withTags ? XML_FORMAT_INSTRUCTIONS.replace("{tags}", ((_a2 = this.tags) == null ? void 0 : _a2.join(", ")) ?? "") : XML_FORMAT_INSTRUCTIONS;
  }
};
var strip = (text) => text.split("\n").map((line) => line.replace(/^\s+/, "")).join("\n").trim();
var parseParsedResult = (input) => {
  if (Object.keys(input).length === 0) return {};
  const result = {};
  if (input.children.length > 0) {
    result[input.name] = input.children.map(parseParsedResult);
    return result;
  } else {
    result[input.name] = input.text ?? void 0;
    return result;
  }
};
function parseXMLMarkdown(s) {
  const cleanedString = strip(s);
  const parser = sax.parser(true);
  let parsedResult = {};
  const elementStack = [];
  parser.onopentag = (node) => {
    const element = {
      name: node.name,
      attributes: node.attributes,
      children: [],
      text: "",
      isSelfClosing: node.isSelfClosing
    };
    if (elementStack.length > 0) {
      const parentElement = elementStack[elementStack.length - 1];
      parentElement.children.push(element);
    } else parsedResult = element;
    if (!node.isSelfClosing) elementStack.push(element);
  };
  parser.onclosetag = () => {
    if (elementStack.length > 0) {
      const lastElement = elementStack.pop();
      if (elementStack.length === 0 && lastElement) parsedResult = lastElement;
    }
  };
  parser.ontext = (text) => {
    if (elementStack.length > 0) {
      const currentElement = elementStack[elementStack.length - 1];
      currentElement.text += text;
    }
  };
  parser.onattribute = (attr) => {
    if (elementStack.length > 0) {
      const currentElement = elementStack[elementStack.length - 1];
      currentElement.attributes[attr.name] = attr.value;
    }
  };
  const match = /```(xml)?(.*)```/s.exec(cleanedString);
  const xmlString = match ? match[2] : cleanedString;
  parser.write(xmlString).close();
  if (parsedResult && parsedResult.name === "?xml") parsedResult = parsedResult.children[0];
  return parseParsedResult(parsedResult);
}

// node_modules/@langchain/core/dist/output_parsers/index.js
var output_parsers_exports = {};
__export(output_parsers_exports, {
  AsymmetricStructuredOutputParser: () => AsymmetricStructuredOutputParser,
  BaseCumulativeTransformOutputParser: () => BaseCumulativeTransformOutputParser,
  BaseLLMOutputParser: () => BaseLLMOutputParser,
  BaseOutputParser: () => BaseOutputParser,
  BaseTransformOutputParser: () => BaseTransformOutputParser,
  BytesOutputParser: () => BytesOutputParser,
  CommaSeparatedListOutputParser: () => CommaSeparatedListOutputParser,
  CustomListOutputParser: () => CustomListOutputParser,
  JsonMarkdownStructuredOutputParser: () => JsonMarkdownStructuredOutputParser,
  JsonOutputParser: () => JsonOutputParser,
  ListOutputParser: () => ListOutputParser,
  MarkdownListOutputParser: () => MarkdownListOutputParser,
  NumberedListOutputParser: () => NumberedListOutputParser,
  OutputParserException: () => OutputParserException,
  StringOutputParser: () => StringOutputParser,
  StructuredOutputParser: () => StructuredOutputParser,
  XMLOutputParser: () => XMLOutputParser,
  XML_FORMAT_INSTRUCTIONS: () => XML_FORMAT_INSTRUCTIONS,
  parseJsonMarkdown: () => parseJsonMarkdown,
  parsePartialJson: () => parsePartialJson,
  parseXMLMarkdown: () => parseXMLMarkdown
});

// node_modules/@langchain/core/dist/output_parsers/openai_tools/json_output_tools_parsers.js
function parseToolCall(rawToolCall, options) {
  if (rawToolCall.function === void 0) return void 0;
  let functionArgs;
  if (options == null ? void 0 : options.partial) try {
    functionArgs = parsePartialJson(rawToolCall.function.arguments ?? "{}");
  } catch {
    return void 0;
  }
  else try {
    functionArgs = JSON.parse(rawToolCall.function.arguments);
  } catch (e) {
    throw new OutputParserException([
      `Function "${rawToolCall.function.name}" arguments:`,
      ``,
      rawToolCall.function.arguments,
      ``,
      `are not valid JSON.`,
      `Error: ${e.message}`
    ].join("\n"));
  }
  const parsedToolCall = {
    name: rawToolCall.function.name,
    args: functionArgs,
    type: "tool_call"
  };
  if (options == null ? void 0 : options.returnId) parsedToolCall.id = rawToolCall.id;
  return parsedToolCall;
}
function convertLangChainToolCallToOpenAI(toolCall) {
  if (toolCall.id === void 0) throw new Error(`All OpenAI tool calls must have an "id" field.`);
  return {
    id: toolCall.id,
    type: "function",
    function: {
      name: toolCall.name,
      arguments: JSON.stringify(toolCall.args)
    }
  };
}
function makeInvalidToolCall(rawToolCall, errorMsg) {
  var _a2, _b;
  return {
    name: (_a2 = rawToolCall.function) == null ? void 0 : _a2.name,
    args: (_b = rawToolCall.function) == null ? void 0 : _b.arguments,
    id: rawToolCall.id,
    error: errorMsg,
    type: "invalid_tool_call"
  };
}
var JsonOutputToolsParser = class extends BaseCumulativeTransformOutputParser {
  constructor(fields) {
    super(fields);
    __publicField(this, "returnId", false);
    __publicField(this, "lc_namespace", [
      "langchain",
      "output_parsers",
      "openai_tools"
    ]);
    __publicField(this, "lc_serializable", true);
    this.returnId = (fields == null ? void 0 : fields.returnId) ?? this.returnId;
  }
  static lc_name() {
    return "JsonOutputToolsParser";
  }
  _diff() {
    throw new Error("Not supported.");
  }
  async parse() {
    throw new Error("Not implemented.");
  }
  async parseResult(generations) {
    const result = await this.parsePartialResult(generations, false);
    return result;
  }
  /**
  * Parses the output and returns a JSON object. If `argsOnly` is true,
  * only the arguments of the function call are returned.
  * @param generations The output of the LLM to parse.
  * @returns A JSON object representation of the function call or its arguments.
  */
  async parsePartialResult(generations, partial = true) {
    var _a2;
    const message = generations[0].message;
    let toolCalls;
    if (isAIMessage(message) && ((_a2 = message.tool_calls) == null ? void 0 : _a2.length)) toolCalls = message.tool_calls.map((toolCall) => {
      const { id, ...rest } = toolCall;
      if (!this.returnId) return rest;
      return {
        id,
        ...rest
      };
    });
    else if (message.additional_kwargs.tool_calls !== void 0) {
      const rawToolCalls = JSON.parse(JSON.stringify(message.additional_kwargs.tool_calls));
      toolCalls = rawToolCalls.map((rawToolCall) => {
        return parseToolCall(rawToolCall, {
          returnId: this.returnId,
          partial
        });
      });
    }
    if (!toolCalls) return [];
    const parsedToolCalls = [];
    for (const toolCall of toolCalls) if (toolCall !== void 0) {
      const backwardsCompatibleToolCall = {
        type: toolCall.name,
        args: toolCall.args,
        id: toolCall.id
      };
      parsedToolCalls.push(backwardsCompatibleToolCall);
    }
    return parsedToolCalls;
  }
};
var JsonOutputKeyToolsParser = class extends JsonOutputToolsParser {
  constructor(params) {
    super(params);
    __publicField(this, "lc_namespace", [
      "langchain",
      "output_parsers",
      "openai_tools"
    ]);
    __publicField(this, "lc_serializable", true);
    __publicField(this, "returnId", false);
    /** The type of tool calls to return. */
    __publicField(this, "keyName");
    /** Whether to return only the first tool call. */
    __publicField(this, "returnSingle", false);
    __publicField(this, "zodSchema");
    this.keyName = params.keyName;
    this.returnSingle = params.returnSingle ?? this.returnSingle;
    this.zodSchema = params.zodSchema;
  }
  static lc_name() {
    return "JsonOutputKeyToolsParser";
  }
  async _validateResult(result) {
    var _a2;
    if (this.zodSchema === void 0) return result;
    const zodParsedResult = await interopSafeParseAsync(this.zodSchema, result);
    if (zodParsedResult.success) return zodParsedResult.data;
    else throw new OutputParserException(`Failed to parse. Text: "${JSON.stringify(result, null, 2)}". Error: ${JSON.stringify((_a2 = zodParsedResult.error) == null ? void 0 : _a2.issues)}`, JSON.stringify(result, null, 2));
  }
  async parsePartialResult(generations) {
    const results = await super.parsePartialResult(generations);
    const matchingResults = results.filter((result) => result.type === this.keyName);
    let returnedValues = matchingResults;
    if (!matchingResults.length) return void 0;
    if (!this.returnId) returnedValues = matchingResults.map((result) => result.args);
    if (this.returnSingle) return returnedValues[0];
    return returnedValues;
  }
  async parseResult(generations) {
    const results = await super.parsePartialResult(generations, false);
    const matchingResults = results.filter((result) => result.type === this.keyName);
    let returnedValues = matchingResults;
    if (!matchingResults.length) return void 0;
    if (!this.returnId) returnedValues = matchingResults.map((result) => result.args);
    if (this.returnSingle) return this._validateResult(returnedValues[0]);
    const toolCallResults = await Promise.all(returnedValues.map((value) => this._validateResult(value)));
    return toolCallResults;
  }
};

// node_modules/@langchain/core/dist/output_parsers/openai_tools/index.js
var openai_tools_exports = {};
__export(openai_tools_exports, {
  JsonOutputKeyToolsParser: () => JsonOutputKeyToolsParser,
  JsonOutputToolsParser: () => JsonOutputToolsParser,
  convertLangChainToolCallToOpenAI: () => convertLangChainToolCallToOpenAI,
  makeInvalidToolCall: () => makeInvalidToolCall,
  parseToolCall: () => parseToolCall
});

// node_modules/@langchain/core/dist/tools/types.js
function isStructuredTool(tool) {
  return tool !== void 0 && Array.isArray(tool.lc_namespace);
}
function isRunnableToolLike(tool) {
  return tool !== void 0 && Runnable.isRunnable(tool) && "lc_name" in tool.constructor && typeof tool.constructor.lc_name === "function" && tool.constructor.lc_name() === "RunnableToolLike";
}
function isStructuredToolParams(tool) {
  return !!tool && typeof tool === "object" && "name" in tool && "schema" in tool && (isInteropZodSchema(tool.schema) || tool.schema != null && typeof tool.schema === "object" && "type" in tool.schema && typeof tool.schema.type === "string" && [
    "null",
    "boolean",
    "object",
    "array",
    "number",
    "string"
  ].includes(tool.schema.type));
}
function isLangChainTool(tool) {
  return isStructuredToolParams(tool) || isRunnableToolLike(tool) || isStructuredTool(tool);
}

// node_modules/@langchain/core/dist/utils/function_calling.js
var function_calling_exports = {};
__export(function_calling_exports, {
  convertToOpenAIFunction: () => convertToOpenAIFunction,
  convertToOpenAITool: () => convertToOpenAITool,
  isLangChainTool: () => isLangChainTool,
  isRunnableToolLike: () => isRunnableToolLike,
  isStructuredTool: () => isStructuredTool,
  isStructuredToolParams: () => isStructuredToolParams
});
function convertToOpenAIFunction(tool, fields) {
  const fieldsCopy = typeof fields === "number" ? void 0 : fields;
  return {
    name: tool.name,
    description: tool.description,
    parameters: toJsonSchema(tool.schema),
    ...(fieldsCopy == null ? void 0 : fieldsCopy.strict) !== void 0 ? { strict: fieldsCopy.strict } : {}
  };
}
function convertToOpenAITool(tool, fields) {
  const fieldsCopy = typeof fields === "number" ? void 0 : fields;
  let toolDef;
  if (isLangChainTool(tool)) toolDef = {
    type: "function",
    function: convertToOpenAIFunction(tool)
  };
  else toolDef = tool;
  if ((fieldsCopy == null ? void 0 : fieldsCopy.strict) !== void 0) toolDef.function.strict = fieldsCopy.strict;
  return toolDef;
}

// node_modules/@langchain/groq/dist/chat_models.js
var CREATE_PARAMS_BASE_CALL_KEYS = [
  "frequency_penalty",
  "function_call",
  "functions",
  "logit_bias",
  "logprobs",
  "max_completion_tokens",
  "max_tokens",
  "n",
  "parallel_tool_calls",
  "presence_penalty",
  "reasoning_format",
  "response_format",
  "seed",
  "service_tier",
  "stop",
  "temperature",
  "tool_choice",
  "top_logprobs",
  "top_p"
];
var ADDED_CALL_KEYS = [
  "headers",
  "promptIndex",
  "stream_options",
  "tools"
];
var ALL_CALL_KEYS = [...CREATE_PARAMS_BASE_CALL_KEYS, ...ADDED_CALL_KEYS];
function extractGenericMessageCustomRole(message) {
  if (message.role !== "system" && message.role !== "assistant" && message.role !== "user" && message.role !== "function") throw new Error(`Unsupported message role: ${message.role}. Expected "system", "assistant", "user", or "function"`);
  return message.role;
}
function messageToGroqRole(message) {
  switch (message.type) {
    case "system":
      return "system";
    case "ai":
      return "assistant";
    case "human":
      return "user";
    case "function":
      return "function";
    case "tool":
      return "tool";
    case "generic":
      if (!ChatMessage.isInstance(message)) throw new Error("Invalid generic chat message");
      return extractGenericMessageCustomRole(message);
    default:
      throw new Error(`Unknown message type: ${message.type}`);
  }
}
function convertMessagesToGroqParams(messages) {
  return messages.map((message) => {
    var _a2;
    const completionParam = {
      role: messageToGroqRole(message),
      content: message.content,
      name: message.name,
      function_call: message.additional_kwargs.function_call,
      tool_calls: message.additional_kwargs.tool_calls,
      tool_call_id: message.tool_call_id
    };
    if (isAIMessage(message) && !!((_a2 = message.tool_calls) == null ? void 0 : _a2.length)) completionParam.tool_calls = message.tool_calls.map(convertLangChainToolCallToOpenAI);
    else {
      if (message.additional_kwargs.tool_calls != null) completionParam.tool_calls = message.additional_kwargs.tool_calls;
      if (message.tool_call_id != null) completionParam.tool_call_id = message.tool_call_id;
    }
    return completionParam;
  });
}
function groqResponseToChatMessage(message, usageMetadata, responseMetadata) {
  const rawToolCalls = message.tool_calls;
  const enrichedMetadata = {
    ...responseMetadata,
    model_provider: "groq"
  };
  switch (message.role) {
    case "assistant": {
      const toolCalls = [];
      const invalidToolCalls = [];
      for (const rawToolCall of rawToolCalls ?? []) try {
        toolCalls.push(parseToolCall(rawToolCall, { returnId: true }));
      } catch (e) {
        invalidToolCalls.push(makeInvalidToolCall(rawToolCall, e.message));
      }
      return new AIMessage({
        content: message.content || "",
        additional_kwargs: { tool_calls: rawToolCalls },
        tool_calls: toolCalls,
        invalid_tool_calls: invalidToolCalls,
        usage_metadata: usageMetadata,
        response_metadata: enrichedMetadata
      });
    }
    default:
      return new ChatMessage(message.content || "", message.role ?? "unknown");
  }
}
function _convertDeltaToMessageChunk(delta, defaultRole, rawResponse, lastMessageId) {
  var _a2, _b;
  const role = delta.role ?? defaultRole;
  const content = delta.content ?? "";
  let additional_kwargs;
  if (delta.function_call) additional_kwargs = { function_call: delta.function_call };
  else if (delta.tool_calls) additional_kwargs = { tool_calls: delta.tool_calls };
  else additional_kwargs = {};
  if (delta.audio) additional_kwargs.audio = {
    ...delta.audio,
    index: rawResponse.choices[0].index
  };
  let usage;
  let groqMessageId = lastMessageId;
  let timing;
  const xGroq = rawResponse.x_groq;
  if (xGroq == null ? void 0 : xGroq.usage) {
    usage = {
      input_tokens: xGroq.usage.prompt_tokens,
      output_tokens: xGroq.usage.completion_tokens,
      total_tokens: xGroq.usage.total_tokens
    };
    timing = {
      completion_time: xGroq.usage.completion_time,
      prompt_time: xGroq.usage.prompt_time,
      queue_time: xGroq.usage.queue_time,
      total_time: xGroq.usage.total_time
    };
  }
  if (xGroq == null ? void 0 : xGroq.id) groqMessageId = xGroq.id;
  const response_metadata = {
    usage,
    timing,
    model_provider: "groq"
  };
  if (role === "user") return new HumanMessageChunk({
    content,
    response_metadata
  });
  else if (role === "assistant") {
    const toolCallChunks = [];
    if (Array.isArray(delta.tool_calls)) for (const rawToolCall of delta.tool_calls) toolCallChunks.push({
      name: (_a2 = rawToolCall.function) == null ? void 0 : _a2.name,
      args: (_b = rawToolCall.function) == null ? void 0 : _b.arguments,
      id: rawToolCall.id,
      index: rawToolCall.index,
      type: "tool_call_chunk"
    });
    return new AIMessageChunk({
      content,
      tool_call_chunks: toolCallChunks,
      additional_kwargs,
      id: groqMessageId,
      response_metadata
    });
  } else if (role === "system") return new SystemMessageChunk({
    content,
    response_metadata
  });
  else if (role === "developer") return new SystemMessageChunk({
    content,
    response_metadata,
    additional_kwargs: { __openai_role__: "developer" }
  });
  else if (role === "function") return new FunctionMessageChunk({
    content,
    additional_kwargs,
    name: delta.name,
    response_metadata
  });
  else if (role === "tool") return new ToolMessageChunk({
    content,
    additional_kwargs,
    tool_call_id: delta.tool_call_id,
    response_metadata
  });
  else return new ChatMessageChunk({
    content,
    role,
    response_metadata
  });
}
var ChatGroq = class extends BaseChatModel {
  constructor(fields) {
    super(fields);
    __publicField(this, "lc_namespace", [
      "langchain",
      "chat_models",
      "groq"
    ]);
    __publicField(this, "client");
    __publicField(this, "model");
    __publicField(this, "temperature", 0.7);
    __publicField(this, "stop");
    __publicField(this, "stopSequences");
    __publicField(this, "maxTokens");
    __publicField(this, "streaming", false);
    __publicField(this, "apiKey");
    __publicField(this, "streamUsage", true);
    __publicField(this, "topP");
    __publicField(this, "frequencyPenalty");
    __publicField(this, "presencePenalty");
    __publicField(this, "logprobs");
    __publicField(this, "n");
    __publicField(this, "logitBias");
    __publicField(this, "user");
    __publicField(this, "reasoningFormat");
    __publicField(this, "serviceTier");
    __publicField(this, "topLogprobs");
    __publicField(this, "lc_serializable", true);
    const apiKey = fields.apiKey || getEnvironmentVariable("GROQ_API_KEY");
    if (!apiKey) throw new Error(`Groq API key not found. Please set the GROQ_API_KEY environment variable or provide the key into "apiKey"`);
    const defaultHeaders = {
      "User-Agent": "langchainjs",
      ...fields.defaultHeaders ?? {}
    };
    this.client = new groq_sdk_default({
      apiKey,
      dangerouslyAllowBrowser: true,
      baseURL: fields.baseUrl,
      timeout: fields.timeout,
      httpAgent: fields.httpAgent,
      fetch: fields.fetch,
      maxRetries: 0,
      defaultHeaders,
      defaultQuery: fields.defaultQuery
    });
    this.apiKey = apiKey;
    this.temperature = fields.temperature ?? this.temperature;
    this.model = fields.model;
    this.streaming = fields.streaming ?? this.streaming;
    this.stop = fields.stopSequences ?? (typeof fields.stop === "string" ? [fields.stop] : fields.stop) ?? [];
    this.stopSequences = this.stop;
    this.maxTokens = fields.maxTokens;
    this.topP = fields.topP;
    this.frequencyPenalty = fields.frequencyPenalty;
    this.presencePenalty = fields.presencePenalty;
    this.logprobs = fields.logprobs;
    this.n = fields.n;
    this.logitBias = fields.logitBias;
    this.user = fields.user;
  }
  get lc_serialized_keys() {
    return [
      "client",
      "model",
      "temperature",
      "stop",
      "stopSequences",
      "maxTokens",
      "streaming",
      "apiKey",
      "streamUsage",
      "topP",
      "frequencyPenalty",
      "presencePenalty",
      "logprobs",
      "n",
      "logitBias",
      "user",
      "reasoningFormat",
      "serviceTier",
      "topLogprobs"
    ];
  }
  static lc_name() {
    return "ChatGroq";
  }
  _llmType() {
    return "groq";
  }
  get lc_secrets() {
    return { apiKey: "GROQ_API_KEY" };
  }
  get callKeys() {
    return [...super.callKeys, ...ALL_CALL_KEYS];
  }
  getLsParams(options) {
    const params = this.invocationParams(options);
    return {
      ls_provider: "groq",
      ls_model_name: this.model,
      ls_model_type: "chat",
      ls_temperature: params.temperature ?? this.temperature,
      ls_max_tokens: params.max_tokens ?? this.maxTokens,
      ls_stop: options.stop
    };
  }
  async completionWithRetry(request, options) {
    return this.caller.call(async () => this.client.chat.completions.create(request, options));
  }
  invocationParams(options, extra) {
    var _a2;
    const params = super.invocationParams(options);
    let streamOptionsConfig = {};
    if ((options == null ? void 0 : options.stream_options) !== void 0) streamOptionsConfig = { stream_options: options.stream_options };
    else if (this.streamUsage && this.streaming || (extra == null ? void 0 : extra.streaming)) streamOptionsConfig = { stream_options: { include_usage: true } };
    const toReturn = {
      model: this.model,
      frequency_penalty: this.frequencyPenalty,
      function_call: options == null ? void 0 : options.function_call,
      functions: options == null ? void 0 : options.functions,
      logit_bias: this.logitBias,
      logprobs: this.logprobs,
      n: this.n,
      parallel_tool_calls: options == null ? void 0 : options.parallel_tool_calls,
      presence_penalty: this.presencePenalty,
      reasoning_format: this.reasoningFormat,
      response_format: options == null ? void 0 : options.response_format,
      seed: options == null ? void 0 : options.seed,
      service_tier: this.serviceTier,
      stop: (options == null ? void 0 : options.stop) ?? this.stopSequences,
      temperature: (options == null ? void 0 : options.temperature) ?? this.temperature,
      tool_choice: _formatToGroqToolChoice(options == null ? void 0 : options.tool_choice),
      tools: ((_a2 = options == null ? void 0 : options.tools) == null ? void 0 : _a2.length) ? options.tools.map((tool) => convertToOpenAITool(tool)) : void 0,
      top_logprobs: this.topLogprobs,
      top_p: this.topP,
      user: this.user,
      stream: this.streaming,
      ...params,
      ...streamOptionsConfig
    };
    toReturn.max_completion_tokens = (options == null ? void 0 : options.max_completion_tokens) ?? (options == null ? void 0 : options.max_tokens) ?? this.maxTokens;
    if (toReturn.max_completion_tokens === -1) delete toReturn.max_completion_tokens;
    return toReturn;
  }
  bindTools(tools, kwargs) {
    return this.withConfig({
      tools: tools.map((tool) => convertToOpenAITool(tool)),
      ...kwargs
    });
  }
  async *_streamResponseChunks(messages, options, runManager) {
    var _a2, _b;
    const params = this.invocationParams(options, { streaming: true });
    const messagesMapped = convertMessagesToGroqParams(messages);
    const response = await this.completionWithRetry({
      ...params,
      messages: messagesMapped,
      stream: true
    }, {
      signal: options == null ? void 0 : options.signal,
      headers: options == null ? void 0 : options.headers
    });
    let role;
    let lastMessageId;
    let responseMetadata;
    for await (const data of response) {
      responseMetadata = data;
      const choice = data == null ? void 0 : data.choices[0];
      if (!choice) continue;
      if ((_a2 = choice.delta) == null ? void 0 : _a2.role) role = choice.delta.role;
      const chunk = _convertDeltaToMessageChunk(choice.delta, role, data, lastMessageId);
      const newTokenIndices = {
        prompt: options.promptIndex ?? 0,
        completion: choice.index ?? 0
      };
      if (typeof chunk.content !== "string") {
        console.log("[WARNING]: Received non-string content from OpenAI. This is currently not supported.");
        continue;
      }
      const generationInfo = { ...newTokenIndices };
      if (choice.finish_reason != null) {
        generationInfo.finish_reason = choice.finish_reason;
        generationInfo.system_fingerprint = data.system_fingerprint;
        generationInfo.model_name = data.model;
      }
      const generationChunk = new ChatGenerationChunk({
        message: chunk,
        text: chunk.content,
        generationInfo
      });
      yield generationChunk;
      await (runManager == null ? void 0 : runManager.handleLLMNewToken(generationChunk.text ?? "", newTokenIndices, void 0, void 0, void 0, { chunk: generationChunk }));
    }
    if (responseMetadata) {
      if ("choices" in responseMetadata) delete responseMetadata.choices;
      yield new ChatGenerationChunk({
        message: new AIMessageChunk({
          content: "",
          response_metadata: responseMetadata
        }),
        text: ""
      });
    }
    if ((_b = options.signal) == null ? void 0 : _b.aborted) throw new Error("AbortError");
  }
  async _generate(messages, options, runManager) {
    var _a2;
    if (this.streaming) {
      const tokenUsage = {};
      const stream = this._streamResponseChunks(messages, options, runManager);
      const finalChunks = {};
      for await (const chunk of stream) {
        const index = ((_a2 = chunk.generationInfo) == null ? void 0 : _a2.completion) ?? 0;
        if (finalChunks[index] === void 0) finalChunks[index] = chunk;
        else finalChunks[index] = finalChunks[index].concat(chunk);
      }
      const generations = Object.entries(finalChunks).sort(([aKey], [bKey]) => parseInt(aKey, 10) - parseInt(bKey, 10)).map(([_, value]) => value);
      return {
        generations,
        llmOutput: { estimatedTokenUsage: tokenUsage }
      };
    } else return this._generateNonStreaming(messages, options, runManager);
  }
  async _generateNonStreaming(messages, options, _runManager) {
    var _a2;
    const tokenUsage = {};
    const params = this.invocationParams(options);
    const messagesMapped = convertMessagesToGroqParams(messages);
    const data = await this.completionWithRetry({
      ...params,
      stream: false,
      messages: messagesMapped
    }, {
      signal: options == null ? void 0 : options.signal,
      headers: options == null ? void 0 : options.headers
    });
    if ("usage" in data && data.usage) {
      const { completion_tokens: completionTokens, prompt_tokens: promptTokens, total_tokens: totalTokens } = data.usage;
      if (completionTokens) tokenUsage.completionTokens = (tokenUsage.completionTokens ?? 0) + completionTokens;
      if (promptTokens) tokenUsage.promptTokens = (tokenUsage.promptTokens ?? 0) + promptTokens;
      if (totalTokens) tokenUsage.totalTokens = (tokenUsage.totalTokens ?? 0) + totalTokens;
    }
    const generations = [];
    if ("choices" in data && data.choices) for (const part of data.choices) {
      const text = ((_a2 = part.message) == null ? void 0 : _a2.content) ?? "";
      let usageMetadata;
      if (tokenUsage.totalTokens !== void 0) usageMetadata = {
        input_tokens: tokenUsage.promptTokens ?? 0,
        output_tokens: tokenUsage.completionTokens ?? 0,
        total_tokens: tokenUsage.totalTokens
      };
      const { choices: _choices, ...metadata } = data;
      const generation = {
        text,
        message: groqResponseToChatMessage(part.message ?? { role: "assistant" }, usageMetadata, metadata)
      };
      generation.generationInfo = {
        ...part.finish_reason ? { finish_reason: part.finish_reason } : {},
        ...part.logprobs ? { logprobs: part.logprobs } : {}
      };
      generations.push(generation);
    }
    return {
      generations,
      llmOutput: { tokenUsage }
    };
  }
  /**
  * Return profiling information for the model.
  *
  * Provides information about the model's capabilities and constraints,
  * including token limits, multimodal support, and advanced features like
  * tool calling and structured output.
  *
  * @returns {ModelProfile} An object describing the model's capabilities and constraints
  *
  * @example
  * ```typescript
  * const model = new ChatGroq({ model: "llama-3.1-8b-instant" });
  * const profile = model.profile;
  * console.log(profile.maxInputTokens); // 128000
  * console.log(profile.imageInputs); // true
  * ```
  */
  get profile() {
    return profiles_default[this.model] ?? {};
  }
  withStructuredOutput(outputSchema, config) {
    const schema = outputSchema;
    const name = config == null ? void 0 : config.name;
    const method = config == null ? void 0 : config.method;
    const includeRaw = config == null ? void 0 : config.includeRaw;
    let functionName = name ?? "extract";
    let outputParser;
    let llm;
    if (method === "jsonMode") {
      let outputSchema$1;
      if (isInteropZodSchema(schema)) {
        outputParser = StructuredOutputParser.fromZodSchema(schema);
        outputSchema$1 = toJsonSchema(schema);
      } else outputParser = new JsonOutputParser();
      llm = this.withConfig({
        response_format: { type: "json_object" },
        ls_structured_output_format: {
          kwargs: { method: "jsonMode" },
          schema: outputSchema$1
        }
      });
    } else if (isInteropZodSchema(schema)) {
      const asJsonSchema = toJsonSchema(schema);
      llm = this.bindTools([{
        type: "function",
        function: {
          name: functionName,
          description: asJsonSchema.description,
          parameters: asJsonSchema
        }
      }]).withConfig({
        tool_choice: {
          type: "function",
          function: { name: functionName }
        },
        ls_structured_output_format: {
          kwargs: { method: "functionCalling" },
          schema: asJsonSchema
        }
      });
      outputParser = new JsonOutputKeyToolsParser({
        returnSingle: true,
        keyName: functionName,
        zodSchema: schema
      });
    } else {
      let openAIFunctionDefinition;
      if (typeof schema.name === "string" && typeof schema.parameters === "object" && schema.parameters != null) {
        openAIFunctionDefinition = schema;
        functionName = schema.name;
      } else {
        functionName = schema.title ?? functionName;
        openAIFunctionDefinition = {
          name: functionName,
          description: schema.description ?? "",
          parameters: schema
        };
      }
      llm = this.bindTools([{
        type: "function",
        function: openAIFunctionDefinition
      }]).withConfig({
        tool_choice: {
          type: "function",
          function: { name: functionName }
        },
        ls_structured_output_format: {
          kwargs: { method: "functionCalling" },
          schema
        }
      });
      outputParser = new JsonOutputKeyToolsParser({
        returnSingle: true,
        keyName: functionName
      });
    }
    if (!includeRaw) return llm.pipe(outputParser).withConfig({ runName: "ChatGroqStructuredOutput" });
    const parserAssign = RunnablePassthrough.assign({ parsed: (input, config$1) => outputParser.invoke(input.raw, config$1) });
    const parserNone = RunnablePassthrough.assign({ parsed: () => null });
    const parsedWithFallback = parserAssign.withFallbacks({ fallbacks: [parserNone] });
    return RunnableSequence.from([{ raw: llm }, parsedWithFallback]).withConfig({ runName: "ChatGroqStructuredOutput" });
  }
};
function _formatToGroqToolChoice(toolChoice) {
  if (!toolChoice) return void 0;
  else if (toolChoice === "any" || toolChoice === "required") return "required";
  else if (toolChoice === "auto") return "auto";
  else if (toolChoice === "none") return "none";
  else if (typeof toolChoice === "string") return {
    type: "function",
    function: { name: toolChoice }
  };
  else return toolChoice;
}
export {
  ChatGroq,
  messageToGroqRole
};
/*! Bundled license information:

@langchain/core/dist/utils/sax-js/sax.js:
  (*! http://mths.be/fromcodepoint v0.1.0 by @mathias *)
*/
//# sourceMappingURL=@langchain_groq.js.map
